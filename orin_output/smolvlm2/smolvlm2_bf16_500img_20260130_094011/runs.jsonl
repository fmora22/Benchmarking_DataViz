{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4586.238, "latencies_ms": [4586.238], "images_per_second": 0.218, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image depicts a spacious, well-lit living room with a dining area, featuring a large flat-screen TV, a fireplace, and a kitchen area with a countertop and cabinets.", "error": null, "sys_before": {"cpu_percent": 10.2, "ram_used_mb": 13859.8, "ram_available_mb": 48981.1, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13864.4, "ram_available_mb": 48976.5, "ram_percent": 22.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 74.684}, "power_stats": {"power_gpu_soc_mean_watts": 21.304, "power_cpu_cv_mean_watts": 1.845, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 74.684}, "timestamp": "2026-01-30T09:41:19.998456"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10676.043, "latencies_ms": [10676.043], "images_per_second": 0.094, "prompt_tokens": 1113, "response_tokens_est": 128, "n_tiles": 1, "output_text": " television: 1, dining table: 1, chairs: 4, vase: 1, flowers: 2, television stand: 1, window: 1, wall: 1, floor: 1, rug: 1, fireplace: 1, ceiling: 1, light: 1, wall art: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1,", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13864.4, "ram_available_mb": 48976.5, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 13867.5, "ram_available_mb": 48973.4, "ram_percent": 22.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 68.211}, "power_stats": {"power_gpu_soc_mean_watts": 15.268, "power_cpu_cv_mean_watts": 2.123, "power_sys_5v0_mean_watts": 7.389, "gpu_utilization_percent_mean": 68.211}, "timestamp": "2026-01-30T09:41:32.704006"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5948.27, "latencies_ms": [5948.27], "images_per_second": 0.168, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The dining table is located in the center of the room, with the woman standing near it. The television is on the left side of the room, while the fireplace is on the right side. The woman is standing near the dining table, which is in the center of the room.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13867.5, "ram_available_mb": 48973.4, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 13874.8, "ram_available_mb": 48966.1, "ram_percent": 22.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 70.92}, "power_stats": {"power_gpu_soc_mean_watts": 18.087, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 7.62, "gpu_utilization_percent_mean": 70.92}, "timestamp": "2026-01-30T09:41:40.694441"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3281.193, "latencies_ms": [3281.193], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman is standing in a living room with a dining table and chairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13875.0, "ram_available_mb": 48965.9, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13874.7, "ram_available_mb": 48966.2, "ram_percent": 22.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 81.538}, "power_stats": {"power_gpu_soc_mean_watts": 22.967, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 7.893, "gpu_utilization_percent_mean": 81.538}, "timestamp": "2026-01-30T09:41:46.008604"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4693.174, "latencies_ms": [4693.174], "images_per_second": 0.213, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The room is bathed in warm yellow light, with hardwood floors and a large window letting in natural light. The walls are painted a bright yellow, and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 13874.7, "ram_available_mb": 48966.2, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 13875.2, "ram_available_mb": 48965.7, "ram_percent": 22.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 73.462}, "power_stats": {"power_gpu_soc_mean_watts": 19.811, "power_cpu_cv_mean_watts": 1.901, "power_sys_5v0_mean_watts": 7.681, "gpu_utilization_percent_mean": 73.462}, "timestamp": "2026-01-30T09:41:52.734534"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4796.527, "latencies_ms": [4796.527], "images_per_second": 0.208, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image features a large brown bear with a thick coat of fur, standing on a grassy field and looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 13875.2, "ram_available_mb": 48965.7, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 14574.9, "ram_available_mb": 48266.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.35}, "power_stats": {"power_gpu_soc_mean_watts": 21.81, "power_cpu_cv_mean_watts": 1.843, "power_sys_5v0_mean_watts": 7.9, "gpu_utilization_percent_mean": 79.35}, "timestamp": "2026-01-30T09:41:59.579815"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6558.716, "latencies_ms": [6558.716], "images_per_second": 0.152, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bear: 1\n2. grass: 1\n3. fur: 1\n4. nose: 1\n5. eyes: 1\n6. mouth: 1\n7. ears: 1\n8. fur texture: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14574.9, "ram_available_mb": 48266.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14589.8, "ram_available_mb": 48251.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.075, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 7.884, "gpu_utilization_percent_mean": 71.8}, "timestamp": "2026-01-30T09:42:08.156264"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5003.844, "latencies_ms": [5003.844], "images_per_second": 0.2, "prompt_tokens": 1450, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The bear is in the foreground, with the grass in the background. The bear is facing the camera, with its head turned slightly to the left.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14589.8, "ram_available_mb": 48251.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14619.7, "ram_available_mb": 48221.2, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.833}, "power_stats": {"power_gpu_soc_mean_watts": 22.176, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 80.833}, "timestamp": "2026-01-30T09:42:15.185732"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3572.329, "latencies_ms": [3572.329], "images_per_second": 0.28, "prompt_tokens": 1444, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A large brown bear is sitting on a grassy field.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14619.7, "ram_available_mb": 48221.2, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14618.3, "ram_available_mb": 48222.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.367}, "power_stats": {"power_gpu_soc_mean_watts": 25.382, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.282, "gpu_utilization_percent_mean": 86.367}, "timestamp": "2026-01-30T09:42:20.790725"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3735.109, "latencies_ms": [3735.109], "images_per_second": 0.268, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The bear has a brown fur, and the grass is green.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14618.3, "ram_available_mb": 48222.6, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 14618.1, "ram_available_mb": 48222.8, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.452}, "power_stats": {"power_gpu_soc_mean_watts": 25.118, "power_cpu_cv_mean_watts": 1.215, "power_sys_5v0_mean_watts": 8.246, "gpu_utilization_percent_mean": 84.452}, "timestamp": "2026-01-30T09:42:26.543824"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5811.576, "latencies_ms": [5811.576], "images_per_second": 0.172, "prompt_tokens": 1432, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a blue comforter on the bed, a wooden dresser with a mirror, a bookshelf filled with books, and a window that offers a view of a lush green tree outside.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 14618.1, "ram_available_mb": 48222.8, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 16.3, "ram_used_mb": 14678.9, "ram_available_mb": 48162.0, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.306}, "power_stats": {"power_gpu_soc_mean_watts": 21.15, "power_cpu_cv_mean_watts": 2.936, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 78.306}, "timestamp": "2026-01-30T09:42:34.395716"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7019.413, "latencies_ms": [7019.413], "images_per_second": 0.142, "prompt_tokens": 1446, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. bed: 1\n2. dresser: 1\n3. mirror: 1\n4. bookshelf: 1\n5. books: 100\n6. potted plant: 4\n7. window: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14678.9, "ram_available_mb": 48162.0, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 14691.6, "ram_available_mb": 48149.3, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.831}, "power_stats": {"power_gpu_soc_mean_watts": 19.889, "power_cpu_cv_mean_watts": 2.065, "power_sys_5v0_mean_watts": 7.886, "gpu_utilization_percent_mean": 74.831}, "timestamp": "2026-01-30T09:42:43.438992"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6772.961, "latencies_ms": [6772.961], "images_per_second": 0.148, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the window on the right side. The bookshelf is positioned in the background, while the dresser is situated near the bed. The plants are placed in the foreground, with the window being the closest object to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14691.6, "ram_available_mb": 48149.3, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14703.4, "ram_available_mb": 48137.5, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.193}, "power_stats": {"power_gpu_soc_mean_watts": 19.994, "power_cpu_cv_mean_watts": 2.052, "power_sys_5v0_mean_watts": 7.891, "gpu_utilization_percent_mean": 74.193}, "timestamp": "2026-01-30T09:42:52.236514"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5623.748, "latencies_ms": [5623.748], "images_per_second": 0.178, "prompt_tokens": 1444, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The bedroom is furnished with a bed, a dresser, a bookshelf, and a window. The room is decorated with a blue comforter, a mirror, and a plant.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14703.4, "ram_available_mb": 48137.5, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14715.3, "ram_available_mb": 48125.6, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.362}, "power_stats": {"power_gpu_soc_mean_watts": 21.103, "power_cpu_cv_mean_watts": 1.918, "power_sys_5v0_mean_watts": 7.894, "gpu_utilization_percent_mean": 76.362}, "timestamp": "2026-01-30T09:42:59.916039"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4742.409, "latencies_ms": [4742.409], "images_per_second": 0.211, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The room is bathed in natural light from a window, the walls are adorned with floral wallpaper, and the floor is carpeted.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14715.3, "ram_available_mb": 48125.6, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14723.4, "ram_available_mb": 48117.5, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.641}, "power_stats": {"power_gpu_soc_mean_watts": 22.782, "power_cpu_cv_mean_watts": 1.993, "power_sys_5v0_mean_watts": 8.079, "gpu_utilization_percent_mean": 78.641}, "timestamp": "2026-01-30T09:43:06.670629"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3261.315, "latencies_ms": [3261.315], "images_per_second": 0.307, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A stop sign is on a pole in front of a parking lot.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14723.4, "ram_available_mb": 48117.5, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14730.8, "ram_available_mb": 48110.1, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.593}, "power_stats": {"power_gpu_soc_mean_watts": 22.38, "power_cpu_cv_mean_watts": 1.825, "power_sys_5v0_mean_watts": 7.878, "gpu_utilization_percent_mean": 83.593}, "timestamp": "2026-01-30T09:43:11.982241"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2564.576, "latencies_ms": [2564.576], "images_per_second": 0.39, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " stop sign: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14730.8, "ram_available_mb": 48110.1, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 14737.5, "ram_available_mb": 48103.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.286}, "power_stats": {"power_gpu_soc_mean_watts": 24.136, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 87.286}, "timestamp": "2026-01-30T09:43:16.567580"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5355.28, "latencies_ms": [5355.28], "images_per_second": 0.187, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The stop sign is in the foreground, to the left of the street. The street is in the middle of the image, with the stop sign on the right side. The background includes trees and buildings, with the sky visible above.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14737.5, "ram_available_mb": 48103.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 14737.9, "ram_available_mb": 48103.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.111}, "power_stats": {"power_gpu_soc_mean_watts": 18.835, "power_cpu_cv_mean_watts": 1.79, "power_sys_5v0_mean_watts": 7.668, "gpu_utilization_percent_mean": 72.111}, "timestamp": "2026-01-30T09:43:23.968880"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3159.097, "latencies_ms": [3159.097], "images_per_second": 0.317, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A stop sign is on a pole in front of a parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14737.9, "ram_available_mb": 48103.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14738.2, "ram_available_mb": 48102.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.577}, "power_stats": {"power_gpu_soc_mean_watts": 22.638, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 7.933, "gpu_utilization_percent_mean": 81.577}, "timestamp": "2026-01-30T09:43:29.173064"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3168.772, "latencies_ms": [3168.772], "images_per_second": 0.316, "prompt_tokens": 1110, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The stop sign is red and white, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14738.2, "ram_available_mb": 48102.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14738.5, "ram_available_mb": 48102.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.577}, "power_stats": {"power_gpu_soc_mean_watts": 23.165, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 7.94, "gpu_utilization_percent_mean": 82.577}, "timestamp": "2026-01-30T09:43:34.404115"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3246.599, "latencies_ms": [3246.599], "images_per_second": 0.308, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Three teddy bears of different sizes and colors are huddled together on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14738.5, "ram_available_mb": 48102.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14739.7, "ram_available_mb": 48101.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.926}, "power_stats": {"power_gpu_soc_mean_watts": 23.183, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 77.926}, "timestamp": "2026-01-30T09:43:39.721005"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2555.762, "latencies_ms": [2555.762], "images_per_second": 0.391, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " teddy bear: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14739.7, "ram_available_mb": 48101.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14740.4, "ram_available_mb": 48100.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.238}, "power_stats": {"power_gpu_soc_mean_watts": 24.329, "power_cpu_cv_mean_watts": 1.183, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 85.238}, "timestamp": "2026-01-30T09:43:44.292910"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6886.21, "latencies_ms": [6886.21], "images_per_second": 0.145, "prompt_tokens": 1118, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The teddy bears are positioned in a close group, with the largest bear in the center and the smallest bear on the left. The largest bear is in the foreground, while the smallest bear is in the background. The teddy bears are arranged in a way that suggests they are huddled together, with the smallest bear resting its head on the largest bear's back.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14740.4, "ram_available_mb": 48100.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.724}, "power_stats": {"power_gpu_soc_mean_watts": 17.203, "power_cpu_cv_mean_watts": 2.079, "power_sys_5v0_mean_watts": 7.628, "gpu_utilization_percent_mean": 68.724}, "timestamp": "2026-01-30T09:43:53.209061"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2993.914, "latencies_ms": [2993.914], "images_per_second": 0.334, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " Three teddy bears are huddled together on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14707.4, "ram_available_mb": 48133.5, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.042}, "power_stats": {"power_gpu_soc_mean_watts": 23.239, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 84.042}, "timestamp": "2026-01-30T09:43:58.233794"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3409.621, "latencies_ms": [3409.621], "images_per_second": 0.293, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The teddy bears are brown and beige, and they are sitting on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 50.0, "ram_used_mb": 14649.9, "ram_available_mb": 48191.0, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.611, "power_cpu_cv_mean_watts": 1.631, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 77.286}, "timestamp": "2026-01-30T09:44:03.703835"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3578.357, "latencies_ms": [3578.357], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman wearing a red jacket and black pants is skiing down a snowy hill with ski poles in her hands.", "error": null, "sys_before": {"cpu_percent": 17.4, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 14624.0, "ram_available_mb": 48216.9, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.483}, "power_stats": {"power_gpu_soc_mean_watts": 22.329, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.943, "gpu_utilization_percent_mean": 74.483}, "timestamp": "2026-01-30T09:44:09.310386"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6859.142, "latencies_ms": [6859.142], "images_per_second": 0.146, "prompt_tokens": 1113, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. Ski pole: 2\n2. Ski: 2\n3. Ski pole: 2\n4. Ski pole: 2\n5. Ski pole: 2\n6. Ski pole: 2\n7. Ski pole: 2\n8. Ski pole: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14624.0, "ram_available_mb": 48216.9, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14623.6, "ram_available_mb": 48217.3, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.983}, "power_stats": {"power_gpu_soc_mean_watts": 17.723, "power_cpu_cv_mean_watts": 2.093, "power_sys_5v0_mean_watts": 7.673, "gpu_utilization_percent_mean": 70.983}, "timestamp": "2026-01-30T09:44:18.218138"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4989.098, "latencies_ms": [4989.098], "images_per_second": 0.2, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the ski slope stretching out into the background. The skier is to the left of the image, with the ski poles extending towards the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14623.6, "ram_available_mb": 48217.3, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 14622.8, "ram_available_mb": 48218.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.415}, "power_stats": {"power_gpu_soc_mean_watts": 19.516, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.806, "gpu_utilization_percent_mean": 72.415}, "timestamp": "2026-01-30T09:44:25.218344"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3386.793, "latencies_ms": [3386.793], "images_per_second": 0.295, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman wearing a red jacket and black pants is skiing down a snowy hill.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14622.8, "ram_available_mb": 48218.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14621.9, "ram_available_mb": 48219.0, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.224, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 7.895, "gpu_utilization_percent_mean": 83.071}, "timestamp": "2026-01-30T09:44:30.639979"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3538.287, "latencies_ms": [3538.287], "images_per_second": 0.283, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a red jacket and black pants, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14621.9, "ram_available_mb": 48219.0, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14621.4, "ram_available_mb": 48219.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.329, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 7.919, "gpu_utilization_percent_mean": 79.207}, "timestamp": "2026-01-30T09:44:36.213674"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4451.345, "latencies_ms": [4451.345], "images_per_second": 0.225, "prompt_tokens": 1100, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image depicts a kitchen with a white refrigerator, a white stove, and a white dishwasher, all set against a backdrop of wooden cabinets and a beige tiled floor.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14621.4, "ram_available_mb": 48219.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14621.0, "ram_available_mb": 48219.9, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.162}, "power_stats": {"power_gpu_soc_mean_watts": 20.577, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 73.162}, "timestamp": "2026-01-30T09:44:42.714320"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6717.866, "latencies_ms": [6717.866], "images_per_second": 0.149, "prompt_tokens": 1114, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. white refrigerator: 1\n2. white stove: 1\n3. white oven: 1\n4. white cabinet: 2\n5. white cabinet door: 1\n6. white cabinet handle: 1\n7. white cabinet drawer: 1\n8. white cabinet knob: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14621.0, "ram_available_mb": 48219.9, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14620.5, "ram_available_mb": 48220.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.107}, "power_stats": {"power_gpu_soc_mean_watts": 17.652, "power_cpu_cv_mean_watts": 2.024, "power_sys_5v0_mean_watts": 7.666, "gpu_utilization_percent_mean": 71.107}, "timestamp": "2026-01-30T09:44:51.459322"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5510.552, "latencies_ms": [5510.552], "images_per_second": 0.181, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The white refrigerator is located to the right of the white stove, which is situated to the left of the white oven. The white cabinets are positioned above the stove and oven, while the white countertop is situated in the middle of the kitchen.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14620.5, "ram_available_mb": 48220.4, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14620.2, "ram_available_mb": 48220.7, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.973, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T09:44:58.981822"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3137.255, "latencies_ms": [3137.255], "images_per_second": 0.319, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A small kitchen with white appliances and wood cabinets is shown in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14620.2, "ram_available_mb": 48220.7, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14618.2, "ram_available_mb": 48222.7, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.64}, "power_stats": {"power_gpu_soc_mean_watts": 23.271, "power_cpu_cv_mean_watts": 1.234, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 79.64}, "timestamp": "2026-01-30T09:45:04.144220"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3370.116, "latencies_ms": [3370.116], "images_per_second": 0.297, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 14618.2, "ram_available_mb": 48222.7, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14617.5, "ram_available_mb": 48223.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.643}, "power_stats": {"power_gpu_soc_mean_watts": 22.538, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 7.968, "gpu_utilization_percent_mean": 76.643}, "timestamp": "2026-01-30T09:45:09.558668"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4563.672, "latencies_ms": [4563.672], "images_per_second": 0.219, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " Two baseball players are running on the field, one of them is wearing a green shirt and the other is wearing a white shirt.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 14616.6, "ram_available_mb": 48224.3, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14618.7, "ram_available_mb": 48222.2, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.895}, "power_stats": {"power_gpu_soc_mean_watts": 23.155, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 79.895}, "timestamp": "2026-01-30T09:45:16.172422"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7321.5, "latencies_ms": [7321.5], "images_per_second": 0.137, "prompt_tokens": 1446, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. baseball player: 2\n2. baseball glove: 1\n3. baseball bat: 1\n4. baseball cap: 1\n5. baseball helmet: 1\n6. baseball field: 1\n7. baseball player's pants: 1\n8. baseball player's shirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14618.7, "ram_available_mb": 48222.2, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 14619.1, "ram_available_mb": 48221.8, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.839}, "power_stats": {"power_gpu_soc_mean_watts": 19.395, "power_cpu_cv_mean_watts": 2.533, "power_sys_5v0_mean_watts": 7.932, "gpu_utilization_percent_mean": 72.839}, "timestamp": "2026-01-30T09:45:25.551735"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5801.714, "latencies_ms": [5801.714], "images_per_second": 0.172, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The baseball player in the foreground is running towards the right side of the image, while the other player is running towards the left side. The baseball player in the foreground is closer to the camera than the other player.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14619.1, "ram_available_mb": 48221.8, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 14619.8, "ram_available_mb": 48221.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.438}, "power_stats": {"power_gpu_soc_mean_watts": 21.296, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 76.438}, "timestamp": "2026-01-30T09:45:33.366764"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4606.353, "latencies_ms": [4606.353], "images_per_second": 0.217, "prompt_tokens": 1444, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A baseball game is taking place on a field with a boy wearing a green shirt and a baseball glove running towards the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14619.8, "ram_available_mb": 48221.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14619.8, "ram_available_mb": 48221.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.974}, "power_stats": {"power_gpu_soc_mean_watts": 22.998, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 75.974}, "timestamp": "2026-01-30T09:45:40.032874"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5658.251, "latencies_ms": [5658.251], "images_per_second": 0.177, "prompt_tokens": 1442, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a baseball game with two players running on the field, one wearing a green shirt and the other wearing a white shirt. The field is covered in green grass, and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14619.8, "ram_available_mb": 48221.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14619.5, "ram_available_mb": 48221.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.596}, "power_stats": {"power_gpu_soc_mean_watts": 21.532, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 77.596}, "timestamp": "2026-01-30T09:45:47.731099"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3748.966, "latencies_ms": [3748.966], "images_per_second": 0.267, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A tennis player is preparing to hit a ball on a court with a J.P. Morgan advertisement in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14619.5, "ram_available_mb": 48221.4, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14619.5, "ram_available_mb": 48221.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.032}, "power_stats": {"power_gpu_soc_mean_watts": 21.801, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 7.918, "gpu_utilization_percent_mean": 76.032}, "timestamp": "2026-01-30T09:45:53.540396"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6060.0, "latencies_ms": [6060.0], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. tennis player: 1\n2. ball: 1\n3. racket: 1\n4. person: 1\n5. wall: 1\n6. advertisement: 1\n7. spectator: 1\n8. court: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14619.5, "ram_available_mb": 48221.4, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14619.7, "ram_available_mb": 48221.2, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.804}, "power_stats": {"power_gpu_soc_mean_watts": 18.296, "power_cpu_cv_mean_watts": 2.034, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 71.804}, "timestamp": "2026-01-30T09:46:01.632340"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4512.593, "latencies_ms": [4512.593], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground, with the ball and the umpire in the background. The player is closer to the camera than the umpire.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14619.7, "ram_available_mb": 48221.2, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 14620.0, "ram_available_mb": 48220.9, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.216, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 73.486}, "timestamp": "2026-01-30T09:46:08.183046"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3299.214, "latencies_ms": [3299.214], "images_per_second": 0.303, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A tennis player is playing on a court with a blue wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14620.0, "ram_available_mb": 48220.9, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14620.4, "ram_available_mb": 48220.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.37}, "power_stats": {"power_gpu_soc_mean_watts": 22.663, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 80.37}, "timestamp": "2026-01-30T09:46:13.522082"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6349.569, "latencies_ms": [6349.569], "images_per_second": 0.157, "prompt_tokens": 1109, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a vibrant blue tennis court, where a player in a crisp white outfit is in the midst of a powerful swing, his body leaning forward in anticipation. The court is bathed in bright sunlight, casting a sharp contrast between the blue of the court and the green of the surrounding grass.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14620.4, "ram_available_mb": 48220.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14621.4, "ram_available_mb": 48219.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.839, "power_cpu_cv_mean_watts": 2.114, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T09:46:21.892082"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3848.926, "latencies_ms": [3848.926], "images_per_second": 0.26, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A group of children and adults are posing for a picture on a tennis court, with one of the adults holding a trophy.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 14621.4, "ram_available_mb": 48219.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14621.6, "ram_available_mb": 48219.3, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.188}, "power_stats": {"power_gpu_soc_mean_watts": 21.751, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.92, "gpu_utilization_percent_mean": 78.188}, "timestamp": "2026-01-30T09:46:27.766772"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5823.368, "latencies_ms": [5823.368], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. boy: 4\n2. girl: 3\n3. boy: 2\n4. boy: 1\n5. boy: 1\n6. boy: 1\n7. boy: 1\n8. boy: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14621.6, "ram_available_mb": 48219.3, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14622.4, "ram_available_mb": 48218.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.082}, "power_stats": {"power_gpu_soc_mean_watts": 18.741, "power_cpu_cv_mean_watts": 1.954, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 71.082}, "timestamp": "2026-01-30T09:46:35.635648"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6541.993, "latencies_ms": [6541.993], "images_per_second": 0.153, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The group of children and adults are standing on a tennis court, with the tennis rackets held by the children and adults. The tennis rackets are positioned in the foreground, with the group of children and adults standing behind them. The tennis court is located in the background, with the tennis net and trees visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14622.4, "ram_available_mb": 48218.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 14622.6, "ram_available_mb": 48218.3, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.836}, "power_stats": {"power_gpu_soc_mean_watts": 17.906, "power_cpu_cv_mean_watts": 2.688, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 68.836}, "timestamp": "2026-01-30T09:46:44.226744"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3212.37, "latencies_ms": [3212.37], "images_per_second": 0.311, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of children and adults are posing for a picture on a tennis court.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14622.6, "ram_available_mb": 48218.3, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14623.6, "ram_available_mb": 48217.3, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.115}, "power_stats": {"power_gpu_soc_mean_watts": 23.439, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 81.115}, "timestamp": "2026-01-30T09:46:49.475574"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3526.907, "latencies_ms": [3526.907], "images_per_second": 0.284, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image is taken in a sunny day with clear blue sky. The tennis court is blue in color.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14623.6, "ram_available_mb": 48217.3, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.931}, "power_stats": {"power_gpu_soc_mean_watts": 22.398, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 77.931}, "timestamp": "2026-01-30T09:46:55.039945"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5122.517, "latencies_ms": [5122.517], "images_per_second": 0.195, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " In the image, a group of people are gathered on a stone-paved walkway, with a large bridge arching above them, and a white bird is seen walking on the ground near the water's edge.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14624.8, "ram_available_mb": 48216.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.047}, "power_stats": {"power_gpu_soc_mean_watts": 19.222, "power_cpu_cv_mean_watts": 1.873, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 73.047}, "timestamp": "2026-01-30T09:47:02.208002"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5822.716, "latencies_ms": [5822.716], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. people: 4\n3. birds: 1\n4. rocks: 2\n5. water: 1\n6. trees: 1\n7. buildings: 1\n8. bridge: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14624.8, "ram_available_mb": 48216.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14624.2, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.38}, "power_stats": {"power_gpu_soc_mean_watts": 18.327, "power_cpu_cv_mean_watts": 1.995, "power_sys_5v0_mean_watts": 7.805, "gpu_utilization_percent_mean": 72.38}, "timestamp": "2026-01-30T09:47:10.074885"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5759.621, "latencies_ms": [5759.621], "images_per_second": 0.174, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The main objects are positioned in a way that the bridge is in the foreground, with the people and the bird in the background. The bridge is located to the left of the people and the bird, and the people are sitting on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14624.2, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14622.4, "ram_available_mb": 48218.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.102}, "power_stats": {"power_gpu_soc_mean_watts": 18.604, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 72.102}, "timestamp": "2026-01-30T09:47:17.874987"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3781.218, "latencies_ms": [3781.218], "images_per_second": 0.264, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A group of people are sitting on a stone ledge by a river, watching a white bird swim in the water.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14622.4, "ram_available_mb": 48218.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14623.2, "ram_available_mb": 48217.7, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.161}, "power_stats": {"power_gpu_soc_mean_watts": 21.674, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 7.929, "gpu_utilization_percent_mean": 77.161}, "timestamp": "2026-01-30T09:47:23.689026"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6754.878, "latencies_ms": [6754.878], "images_per_second": 0.148, "prompt_tokens": 1109, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a bridge with a metal structure, a river with a white bird, and a group of people sitting on the bank. The lighting is natural, with the sun shining down on the scene, and the colors are vibrant, with the blue of the river contrasting with the green of the trees and the red of the people's clothing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14623.2, "ram_available_mb": 48217.7, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.754}, "power_stats": {"power_gpu_soc_mean_watts": 17.789, "power_cpu_cv_mean_watts": 2.101, "power_sys_5v0_mean_watts": 7.672, "gpu_utilization_percent_mean": 68.754}, "timestamp": "2026-01-30T09:47:32.477024"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3115.829, "latencies_ms": [3115.829], "images_per_second": 0.321, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman is looking at her phone with a Hello Kitty case.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14624.2, "ram_available_mb": 48216.7, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.414, "power_cpu_cv_mean_watts": 1.234, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 79.0}, "timestamp": "2026-01-30T09:47:37.646811"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6227.682, "latencies_ms": [6227.682], "images_per_second": 0.161, "prompt_tokens": 1114, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. woman: 1\n2. hair: 1\n3. earring: 1\n4. wristwatch: 1\n5. bracelet: 2\n6. phone: 1\n7. Hello Kitty: 1\n8. background: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 14624.2, "ram_available_mb": 48216.7, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.538}, "power_stats": {"power_gpu_soc_mean_watts": 18.083, "power_cpu_cv_mean_watts": 2.234, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 71.538}, "timestamp": "2026-01-30T09:47:45.911787"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4555.727, "latencies_ms": [4555.727], "images_per_second": 0.22, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The woman is in the foreground of the image, holding a Hello Kitty phone case. The background is blurred, indicating that the focus is on the woman and her phone case.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 14623.4, "ram_available_mb": 48217.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.974}, "power_stats": {"power_gpu_soc_mean_watts": 19.991, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 7.871, "gpu_utilization_percent_mean": 72.974}, "timestamp": "2026-01-30T09:47:52.485554"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3277.406, "latencies_ms": [3277.406], "images_per_second": 0.305, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman is taking a picture of herself with a Hello Kitty phone case.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14623.4, "ram_available_mb": 48217.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14623.3, "ram_available_mb": 48217.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.741}, "power_stats": {"power_gpu_soc_mean_watts": 22.423, "power_cpu_cv_mean_watts": 1.617, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 81.741}, "timestamp": "2026-01-30T09:47:57.781818"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3739.439, "latencies_ms": [3739.439], "images_per_second": 0.267, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is taken in a bright and sunny day, with the woman wearing a white shirt and a green bracelet.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14623.3, "ram_available_mb": 48217.6, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 14624.3, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.129}, "power_stats": {"power_gpu_soc_mean_watts": 22.065, "power_cpu_cv_mean_watts": 2.339, "power_sys_5v0_mean_watts": 7.961, "gpu_utilization_percent_mean": 76.129}, "timestamp": "2026-01-30T09:48:03.548596"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3800.29, "latencies_ms": [3800.29], "images_per_second": 0.263, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of children are riding on a red and yellow train car, with a wooden wall and a black speaker in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14624.3, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.226}, "power_stats": {"power_gpu_soc_mean_watts": 21.956, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 75.226}, "timestamp": "2026-01-30T09:48:09.372281"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6339.875, "latencies_ms": [6339.875], "images_per_second": 0.158, "prompt_tokens": 1114, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. children: 5\n2. train: 1\n3. track: 1\n4. wall: 1\n5. children's clothing: 5\n6. children's hair: 5\n7. children's eyes: 5\n8. children's hands: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.222}, "power_stats": {"power_gpu_soc_mean_watts": 17.985, "power_cpu_cv_mean_watts": 2.07, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 72.222}, "timestamp": "2026-01-30T09:48:17.733220"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4917.776, "latencies_ms": [4917.776], "images_per_second": 0.203, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The children are in the foreground, riding on a train that is in the middle of the image. The train is moving towards the right side of the image, and the children are looking towards the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14623.5, "ram_available_mb": 48217.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.463}, "power_stats": {"power_gpu_soc_mean_watts": 19.533, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 7.842, "gpu_utilization_percent_mean": 72.463}, "timestamp": "2026-01-30T09:48:24.704729"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3650.789, "latencies_ms": [3650.789], "images_per_second": 0.274, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of children are riding on a train car in a room with a wooden floor and a wall.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14623.5, "ram_available_mb": 48217.4, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14624.3, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.725, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 7.92, "gpu_utilization_percent_mean": 78.667}, "timestamp": "2026-01-30T09:48:30.411346"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5589.184, "latencies_ms": [5589.184], "images_per_second": 0.179, "prompt_tokens": 1110, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features a group of children riding on a red and yellow train car, with the train car being the main focus of the image. The lighting in the image is dim, and the children are wearing jackets, indicating that it might be a cold day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14624.3, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14624.5, "ram_available_mb": 48216.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.695, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 72.043}, "timestamp": "2026-01-30T09:48:38.035411"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4035.721, "latencies_ms": [4035.721], "images_per_second": 0.248, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white photo of a plate with a piece of food on it.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14624.5, "ram_available_mb": 48216.4, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14624.8, "ram_available_mb": 48216.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.364}, "power_stats": {"power_gpu_soc_mean_watts": 23.989, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.27, "gpu_utilization_percent_mean": 80.364}, "timestamp": "2026-01-30T09:48:44.123597"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6778.554, "latencies_ms": [6778.554], "images_per_second": 0.148, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. food: 1\n3. cup: 1\n4. fork: 1\n5. knife: 1\n6. table: 1\n7. background: 1\n8. glass: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14624.8, "ram_available_mb": 48216.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.241}, "power_stats": {"power_gpu_soc_mean_watts": 19.288, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.907, "gpu_utilization_percent_mean": 73.241}, "timestamp": "2026-01-30T09:48:52.949055"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6002.805, "latencies_ms": [6002.805], "images_per_second": 0.167, "prompt_tokens": 1450, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The main object, a piece of food, is in the foreground, with a small dish of sauce in the background. The food is positioned to the left of the dish, and the entire scene is set on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 14671.2, "ram_available_mb": 48169.7, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.62}, "power_stats": {"power_gpu_soc_mean_watts": 20.953, "power_cpu_cv_mean_watts": 1.939, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 78.62}, "timestamp": "2026-01-30T09:49:00.993942"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4069.616, "latencies_ms": [4069.616], "images_per_second": 0.246, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white photo of a plate of food with a side of salad.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14671.2, "ram_available_mb": 48169.7, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14676.5, "ram_available_mb": 48164.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.303}, "power_stats": {"power_gpu_soc_mean_watts": 23.99, "power_cpu_cv_mean_watts": 1.833, "power_sys_5v0_mean_watts": 8.29, "gpu_utilization_percent_mean": 84.303}, "timestamp": "2026-01-30T09:49:07.095271"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5190.454, "latencies_ms": [5190.454], "images_per_second": 0.193, "prompt_tokens": 1442, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is in black and white, with a focus on a plate of food. The lighting is soft and natural, and the food appears to be well-cooked.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14676.5, "ram_available_mb": 48164.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 14683.5, "ram_available_mb": 48157.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.256}, "power_stats": {"power_gpu_soc_mean_watts": 22.177, "power_cpu_cv_mean_watts": 2.134, "power_sys_5v0_mean_watts": 8.117, "gpu_utilization_percent_mean": 76.256}, "timestamp": "2026-01-30T09:49:14.324403"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3168.243, "latencies_ms": [3168.243], "images_per_second": 0.316, "prompt_tokens": 766, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man wearing a wetsuit is standing on a paddleboard in the ocean, holding a paddle in his hand.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14683.5, "ram_available_mb": 48157.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14698.5, "ram_available_mb": 48142.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5179.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.038}, "power_stats": {"power_gpu_soc_mean_watts": 19.384, "power_cpu_cv_mean_watts": 2.111, "power_sys_5v0_mean_watts": 7.597, "gpu_utilization_percent_mean": 74.038}, "timestamp": "2026-01-30T09:49:19.546144"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5322.168, "latencies_ms": [5322.168], "images_per_second": 0.188, "prompt_tokens": 780, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. paddle: 1\n3. surfboard: 1\n4. water: 1\n5. land: 1\n6. sky: 1\n7. city: 1\n8. buildings: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14698.5, "ram_available_mb": 48142.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 14710.2, "ram_available_mb": 48130.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.455}, "power_stats": {"power_gpu_soc_mean_watts": 16.291, "power_cpu_cv_mean_watts": 2.349, "power_sys_5v0_mean_watts": 7.493, "gpu_utilization_percent_mean": 68.455}, "timestamp": "2026-01-30T09:49:26.884259"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5475.497, "latencies_ms": [5475.497], "images_per_second": 0.183, "prompt_tokens": 784, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The person is in the foreground of the image, paddling a paddleboard on the water. The paddleboard is in the middle of the image, and the person is paddling it towards the right side of the image. The background of the image features a shoreline with buildings and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14710.2, "ram_available_mb": 48130.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14718.2, "ram_available_mb": 48122.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.467}, "power_stats": {"power_gpu_soc_mean_watts": 16.267, "power_cpu_cv_mean_watts": 2.386, "power_sys_5v0_mean_watts": 7.501, "gpu_utilization_percent_mean": 71.467}, "timestamp": "2026-01-30T09:49:34.375146"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2604.628, "latencies_ms": [2604.628], "images_per_second": 0.384, "prompt_tokens": 778, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is standing on a paddleboard in the ocean, holding a paddle.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14718.2, "ram_available_mb": 48122.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 14725.3, "ram_available_mb": 48115.6, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.952}, "power_stats": {"power_gpu_soc_mean_watts": 20.966, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 73.952}, "timestamp": "2026-01-30T09:49:39.009800"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4605.646, "latencies_ms": [4605.646], "images_per_second": 0.217, "prompt_tokens": 776, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image is in black and white, with the water being a dark shade and the sky a lighter one. The person is wearing a wetsuit, which is black, and is holding a paddle, which is also black.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14725.3, "ram_available_mb": 48115.6, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 14726.4, "ram_available_mb": 48114.5, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.538}, "power_stats": {"power_gpu_soc_mean_watts": 16.748, "power_cpu_cv_mean_watts": 2.25, "power_sys_5v0_mean_watts": 7.494, "gpu_utilization_percent_mean": 68.538}, "timestamp": "2026-01-30T09:49:45.644055"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3931.074, "latencies_ms": [3931.074], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A white computer desk with a laptop, keyboard, mouse, and speakers is placed in front of a window with blinds.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14726.4, "ram_available_mb": 48114.5, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14732.5, "ram_available_mb": 48108.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.312}, "power_stats": {"power_gpu_soc_mean_watts": 21.612, "power_cpu_cv_mean_watts": 2.116, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 77.312}, "timestamp": "2026-01-30T09:49:51.590698"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4415.641, "latencies_ms": [4415.641], "images_per_second": 0.226, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 1, monitor: 1, keyboard: 1, mouse: 1, speakers: 2, printer: 1, lamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14732.5, "ram_available_mb": 48108.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 14739.1, "ram_available_mb": 48101.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.703}, "power_stats": {"power_gpu_soc_mean_watts": 20.65, "power_cpu_cv_mean_watts": 2.252, "power_sys_5v0_mean_watts": 7.948, "gpu_utilization_percent_mean": 75.703}, "timestamp": "2026-01-30T09:49:58.044088"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4183.312, "latencies_ms": [4183.312], "images_per_second": 0.239, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The laptop is to the left of the computer monitor, the keyboard is in front of the monitor, and the speakers are to the right of the monitor.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14739.1, "ram_available_mb": 48101.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 14737.9, "ram_available_mb": 48103.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.457}, "power_stats": {"power_gpu_soc_mean_watts": 20.81, "power_cpu_cv_mean_watts": 2.186, "power_sys_5v0_mean_watts": 7.957, "gpu_utilization_percent_mean": 74.457}, "timestamp": "2026-01-30T09:50:04.262809"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3082.271, "latencies_ms": [3082.271], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A white desk with a computer, laptop, and speakers on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14737.6, "ram_available_mb": 48103.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.84}, "power_stats": {"power_gpu_soc_mean_watts": 23.638, "power_cpu_cv_mean_watts": 2.019, "power_sys_5v0_mean_watts": 8.159, "gpu_utilization_percent_mean": 78.84}, "timestamp": "2026-01-30T09:50:09.369332"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3673.932, "latencies_ms": [3673.932], "images_per_second": 0.272, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the desk is made of white wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 14738.6, "ram_available_mb": 48102.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.133}, "power_stats": {"power_gpu_soc_mean_watts": 22.355, "power_cpu_cv_mean_watts": 2.377, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 75.133}, "timestamp": "2026-01-30T09:50:15.060819"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5906.452, "latencies_ms": [5906.452], "images_per_second": 0.169, "prompt_tokens": 1099, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a bustling highway scene under a concrete overpass, where a green highway sign prominently displays the directions to \"North Ventura 101\" and \"Hollywood Blvd Sunset Blvd\" in white lettering, guiding drivers through the city.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14738.6, "ram_available_mb": 48102.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14736.5, "ram_available_mb": 48104.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.673}, "power_stats": {"power_gpu_soc_mean_watts": 18.362, "power_cpu_cv_mean_watts": 2.273, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 72.673}, "timestamp": "2026-01-30T09:50:23.008076"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6162.321, "latencies_ms": [6162.321], "images_per_second": 0.162, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. sign: 4\n2. car: 3\n3. streetlamp: 1\n4. tree: 1\n5. road: 1\n6. vehicle: 1\n7. road sign: 1\n8. building: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14736.5, "ram_available_mb": 48104.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14735.6, "ram_available_mb": 48105.3, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.019}, "power_stats": {"power_gpu_soc_mean_watts": 17.889, "power_cpu_cv_mean_watts": 2.28, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 70.019}, "timestamp": "2026-01-30T09:50:31.200922"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4539.28, "latencies_ms": [4539.28], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The sign is located in the foreground of the image, while the vehicles are in the background. The sign is also above the vehicles, indicating that it is a traffic sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14735.6, "ram_available_mb": 48105.3, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14737.8, "ram_available_mb": 48103.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.622}, "power_stats": {"power_gpu_soc_mean_watts": 20.25, "power_cpu_cv_mean_watts": 2.025, "power_sys_5v0_mean_watts": 7.886, "gpu_utilization_percent_mean": 74.622}, "timestamp": "2026-01-30T09:50:37.767948"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3398.093, "latencies_ms": [3398.093], "images_per_second": 0.294, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A busy highway with cars and trucks driving under a bridge with signs pointing to different locations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14737.8, "ram_available_mb": 48103.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.464}, "power_stats": {"power_gpu_soc_mean_watts": 22.651, "power_cpu_cv_mean_watts": 2.032, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 77.464}, "timestamp": "2026-01-30T09:50:43.201129"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5261.042, "latencies_ms": [5261.042], "images_per_second": 0.19, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image depicts a busy highway with several vehicles, including a black SUV, under a green highway sign that indicates the direction to North Ventura and Hollywood Blvd. The sky is clear and blue, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14740.3, "ram_available_mb": 48100.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.07}, "power_stats": {"power_gpu_soc_mean_watts": 19.512, "power_cpu_cv_mean_watts": 2.273, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 72.07}, "timestamp": "2026-01-30T09:50:50.483910"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4704.013, "latencies_ms": [4704.013], "images_per_second": 0.213, "prompt_tokens": 1432, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A red double-decker bus is driving down a street with a sign on the front that says \"15 Aldwych\".", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 14740.3, "ram_available_mb": 48100.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.632}, "power_stats": {"power_gpu_soc_mean_watts": 22.985, "power_cpu_cv_mean_watts": 1.95, "power_sys_5v0_mean_watts": 8.219, "gpu_utilization_percent_mean": 79.632}, "timestamp": "2026-01-30T09:50:57.221439"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5375.487, "latencies_ms": [5375.487], "images_per_second": 0.186, "prompt_tokens": 1446, "response_tokens_est": 39, "n_tiles": 1, "output_text": " 1. red double decker bus\n2. people\n3. trees\n4. buildings\n5. street\n6. license plate\n7. bus number\n8. bus route", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14746.3, "ram_available_mb": 48094.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.4}, "power_stats": {"power_gpu_soc_mean_watts": 21.927, "power_cpu_cv_mean_watts": 2.021, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 77.4}, "timestamp": "2026-01-30T09:51:04.636976"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5661.803, "latencies_ms": [5661.803], "images_per_second": 0.177, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The red double-decker bus is in the foreground, moving towards the left side of the image. The building in the background is far away from the camera, and the trees are in the middle ground.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14746.3, "ram_available_mb": 48094.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14752.2, "ram_available_mb": 48088.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.064}, "power_stats": {"power_gpu_soc_mean_watts": 21.488, "power_cpu_cv_mean_watts": 2.062, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 77.064}, "timestamp": "2026-01-30T09:51:12.326522"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4975.581, "latencies_ms": [4975.581], "images_per_second": 0.201, "prompt_tokens": 1444, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A red double-decker bus is driving down a street in a city, passing by a park with trees and a building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14752.2, "ram_available_mb": 48088.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14757.3, "ram_available_mb": 48083.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.805}, "power_stats": {"power_gpu_soc_mean_watts": 22.522, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 8.135, "gpu_utilization_percent_mean": 80.805}, "timestamp": "2026-01-30T09:51:19.340455"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3935.077, "latencies_ms": [3935.077], "images_per_second": 0.254, "prompt_tokens": 1442, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The bus is red with a yellow stripe, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14757.3, "ram_available_mb": 48083.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 14767.8, "ram_available_mb": 48073.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.906}, "power_stats": {"power_gpu_soc_mean_watts": 24.438, "power_cpu_cv_mean_watts": 2.053, "power_sys_5v0_mean_watts": 8.35, "gpu_utilization_percent_mean": 82.906}, "timestamp": "2026-01-30T09:51:25.309834"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3116.865, "latencies_ms": [3116.865], "images_per_second": 0.321, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cat is laying on top of a laptop computer.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14767.8, "ram_available_mb": 48073.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14774.9, "ram_available_mb": 48066.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.588, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 84.28}, "timestamp": "2026-01-30T09:51:30.454275"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6507.456, "latencies_ms": [6507.456], "images_per_second": 0.154, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. black and white cat: 1\n2. laptop: 1\n3. keyboard: 1\n4. white wall: 1\n5. white baseboard: 1\n6. white door frame: 1\n7. white door: 1\n8. white wall panel: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14774.9, "ram_available_mb": 48066.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 14787.1, "ram_available_mb": 48053.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.818}, "power_stats": {"power_gpu_soc_mean_watts": 17.752, "power_cpu_cv_mean_watts": 2.316, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 68.818}, "timestamp": "2026-01-30T09:51:38.973435"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5041.896, "latencies_ms": [5041.896], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The black and white cat is positioned to the left of the laptop, which is situated in the middle of the image. The laptop is located in the foreground of the image, while the cat is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14787.1, "ram_available_mb": 48053.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 14798.6, "ram_available_mb": 48042.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.61}, "power_stats": {"power_gpu_soc_mean_watts": 19.855, "power_cpu_cv_mean_watts": 2.208, "power_sys_5v0_mean_watts": 7.871, "gpu_utilization_percent_mean": 72.61}, "timestamp": "2026-01-30T09:51:46.030225"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3213.075, "latencies_ms": [3213.075], "images_per_second": 0.311, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cat is laying on top of a laptop computer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14798.6, "ram_available_mb": 48042.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14808.6, "ram_available_mb": 48032.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.115}, "power_stats": {"power_gpu_soc_mean_watts": 22.742, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 81.115}, "timestamp": "2026-01-30T09:51:51.271047"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3077.479, "latencies_ms": [3077.479], "images_per_second": 0.325, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The cat is black and white, and the laptop is silver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14808.6, "ram_available_mb": 48032.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 14650.7, "ram_available_mb": 48190.2, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.12}, "power_stats": {"power_gpu_soc_mean_watts": 23.348, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 81.12}, "timestamp": "2026-01-30T09:51:56.385886"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3530.246, "latencies_ms": [3530.246], "images_per_second": 0.283, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Two airplanes fly over a bridge and the Sydney Opera House, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 14650.7, "ram_available_mb": 48190.2, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 14702.9, "ram_available_mb": 48138.0, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.517}, "power_stats": {"power_gpu_soc_mean_watts": 22.474, "power_cpu_cv_mean_watts": 2.182, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 76.517}, "timestamp": "2026-01-30T09:52:01.950842"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5953.834, "latencies_ms": [5953.834], "images_per_second": 0.168, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. airplane: 2\n2. bridge: 1\n3. building: 1\n4. city skyline: 1\n5. water: 1\n6. clouds: 1\n7. sky: 1\n8. flags: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14702.9, "ram_available_mb": 48138.0, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 14703.7, "ram_available_mb": 48137.2, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.7}, "power_stats": {"power_gpu_soc_mean_watts": 18.283, "power_cpu_cv_mean_watts": 2.275, "power_sys_5v0_mean_watts": 7.811, "gpu_utilization_percent_mean": 69.7}, "timestamp": "2026-01-30T09:52:09.950005"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4742.435, "latencies_ms": [4742.435], "images_per_second": 0.211, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The two airplanes are flying above the Sydney Harbour Bridge, which is positioned in the foreground of the image. The Sydney Opera House is situated in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14703.7, "ram_available_mb": 48137.2, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14714.3, "ram_available_mb": 48126.6, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.846}, "power_stats": {"power_gpu_soc_mean_watts": 20.019, "power_cpu_cv_mean_watts": 2.034, "power_sys_5v0_mean_watts": 7.857, "gpu_utilization_percent_mean": 74.846}, "timestamp": "2026-01-30T09:52:16.706783"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3594.533, "latencies_ms": [3594.533], "images_per_second": 0.278, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two airplanes fly over a large bridge and the Sydney Opera House, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14714.3, "ram_available_mb": 48126.6, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14721.2, "ram_available_mb": 48119.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.733}, "power_stats": {"power_gpu_soc_mean_watts": 21.97, "power_cpu_cv_mean_watts": 1.963, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 74.733}, "timestamp": "2026-01-30T09:52:22.351752"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3585.4, "latencies_ms": [3585.4], "images_per_second": 0.279, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The sky is overcast with a grayish hue, and the bridge is a dark brown color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14721.2, "ram_available_mb": 48119.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14736.2, "ram_available_mb": 48104.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.655}, "power_stats": {"power_gpu_soc_mean_watts": 22.352, "power_cpu_cv_mean_watts": 1.989, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 77.655}, "timestamp": "2026-01-30T09:52:27.961380"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3268.549, "latencies_ms": [3268.549], "images_per_second": 0.306, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white photo of a zebra nursing its young in a grassy field.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14736.2, "ram_available_mb": 48104.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.37}, "power_stats": {"power_gpu_soc_mean_watts": 23.148, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 79.37}, "timestamp": "2026-01-30T09:52:33.277755"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3147.539, "latencies_ms": [3147.539], "images_per_second": 0.318, "prompt_tokens": 1113, "response_tokens_est": 15, "n_tiles": 1, "output_text": " zebra: 1\nbaby zebra: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14754.4, "ram_available_mb": 48086.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.154}, "power_stats": {"power_gpu_soc_mean_watts": 23.466, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 8.121, "gpu_utilization_percent_mean": 79.154}, "timestamp": "2026-01-30T09:52:38.466971"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6547.568, "latencies_ms": [6547.568], "images_per_second": 0.153, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The zebra is positioned on the left side of the image, with its body facing towards the right side. The baby zebra is positioned on the right side of the image, with its body facing towards the left side. The baby zebra is positioned very close to the mother zebra, with its head near the mother's udder.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14754.4, "ram_available_mb": 48086.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 14761.0, "ram_available_mb": 48079.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.145}, "power_stats": {"power_gpu_soc_mean_watts": 17.975, "power_cpu_cv_mean_watts": 2.338, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 70.145}, "timestamp": "2026-01-30T09:52:47.066834"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2993.668, "latencies_ms": [2993.668], "images_per_second": 0.334, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A zebra is nursing its young in a grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14761.0, "ram_available_mb": 48079.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14773.8, "ram_available_mb": 48067.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.417}, "power_stats": {"power_gpu_soc_mean_watts": 23.535, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.13, "gpu_utilization_percent_mean": 81.417}, "timestamp": "2026-01-30T09:52:52.095871"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5005.138, "latencies_ms": [5005.138], "images_per_second": 0.2, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image is in black and white, with the zebra's stripes standing out against the white background. The lighting is natural, coming from the side, casting shadows and highlighting the texture of the zebra's fur.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14773.8, "ram_available_mb": 48067.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14779.8, "ram_available_mb": 48061.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.262}, "power_stats": {"power_gpu_soc_mean_watts": 19.563, "power_cpu_cv_mean_watts": 2.26, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 72.262}, "timestamp": "2026-01-30T09:52:59.130379"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4464.893, "latencies_ms": [4464.893], "images_per_second": 0.224, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image shows a room with a bed, a small round table, and a chair, all placed in front of a window with a view of a building outside.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 14779.8, "ram_available_mb": 48061.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14788.8, "ram_available_mb": 48052.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.194}, "power_stats": {"power_gpu_soc_mean_watts": 20.443, "power_cpu_cv_mean_watts": 2.125, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 73.194}, "timestamp": "2026-01-30T09:53:05.634463"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5900.978, "latencies_ms": [5900.978], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. chair: 2\n3. table: 1\n4. lamp: 1\n5. window: 2\n6. door: 1\n7. wall: 1\n8. carpet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14788.8, "ram_available_mb": 48052.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14797.1, "ram_available_mb": 48043.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.438, "power_cpu_cv_mean_watts": 2.235, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-30T09:53:13.564029"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5048.304, "latencies_ms": [5048.304], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the window and door to the left and right, respectively. The table and chairs are located in the foreground, while the lamp is situated in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14797.1, "ram_available_mb": 48043.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 14814.1, "ram_available_mb": 48026.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.707}, "power_stats": {"power_gpu_soc_mean_watts": 19.396, "power_cpu_cv_mean_watts": 2.286, "power_sys_5v0_mean_watts": 7.873, "gpu_utilization_percent_mean": 73.707}, "timestamp": "2026-01-30T09:53:20.633795"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3092.732, "latencies_ms": [3092.732], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A small room with a bed, a table, and a chair.", "error": null, "sys_before": {"cpu_percent": 40.0, "ram_used_mb": 14814.1, "ram_available_mb": 48026.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.308}, "power_stats": {"power_gpu_soc_mean_watts": 23.329, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 8.129, "gpu_utilization_percent_mean": 80.308}, "timestamp": "2026-01-30T09:53:25.770771"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3951.947, "latencies_ms": [3951.947], "images_per_second": 0.253, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The room is painted purple and has a bed with a colorful blanket. The room is lit by natural light coming through the windows.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14836.7, "ram_available_mb": 48004.2, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.061}, "power_stats": {"power_gpu_soc_mean_watts": 21.489, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 7.95, "gpu_utilization_percent_mean": 77.061}, "timestamp": "2026-01-30T09:53:31.763737"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3224.53, "latencies_ms": [3224.53], "images_per_second": 0.31, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A purple bus with the number 96 on it is driving down the street.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14836.7, "ram_available_mb": 48004.2, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14847.0, "ram_available_mb": 47993.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.038}, "power_stats": {"power_gpu_soc_mean_watts": 23.5, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 8.184, "gpu_utilization_percent_mean": 79.038}, "timestamp": "2026-01-30T09:53:37.015228"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5832.5, "latencies_ms": [5832.5], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bus: 1\n2. person: 1\n3. pole: 1\n4. sign: 1\n5. tree: 1\n6. building: 1\n7. street: 1\n8. sidewalk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14847.0, "ram_available_mb": 47993.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 14643.1, "ram_available_mb": 48197.8, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.102}, "power_stats": {"power_gpu_soc_mean_watts": 18.628, "power_cpu_cv_mean_watts": 2.371, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 72.102}, "timestamp": "2026-01-30T09:53:44.873754"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4634.384, "latencies_ms": [4634.384], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the driver's side facing the camera. The bus is in the foreground, with the background showing a street and buildings.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14643.1, "ram_available_mb": 48197.8, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14658.8, "ram_available_mb": 48182.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.658}, "power_stats": {"power_gpu_soc_mean_watts": 20.212, "power_cpu_cv_mean_watts": 2.203, "power_sys_5v0_mean_watts": 7.938, "gpu_utilization_percent_mean": 74.658}, "timestamp": "2026-01-30T09:53:51.546929"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3300.316, "latencies_ms": [3300.316], "images_per_second": 0.303, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A purple bus with the number 96 on it is driving down a street.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14658.8, "ram_available_mb": 48182.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14681.1, "ram_available_mb": 48159.8, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.63}, "power_stats": {"power_gpu_soc_mean_watts": 23.281, "power_cpu_cv_mean_watts": 2.122, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 82.63}, "timestamp": "2026-01-30T09:53:56.871175"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3664.298, "latencies_ms": [3664.298], "images_per_second": 0.273, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The bus is purple with a white roof and has a white license plate. The sky is clear and blue.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14681.1, "ram_available_mb": 48159.8, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 14690.6, "ram_available_mb": 48150.3, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.833}, "power_stats": {"power_gpu_soc_mean_watts": 22.357, "power_cpu_cv_mean_watts": 2.231, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 75.833}, "timestamp": "2026-01-30T09:54:02.565636"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3807.572, "latencies_ms": [3807.572], "images_per_second": 0.263, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image features a white bowl filled with a bunch of green apples, with the apples being the main focus of the image.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 14690.6, "ram_available_mb": 48150.3, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 14688.6, "ram_available_mb": 48152.3, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.194}, "power_stats": {"power_gpu_soc_mean_watts": 21.882, "power_cpu_cv_mean_watts": 2.262, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 77.194}, "timestamp": "2026-01-30T09:54:08.434067"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2647.836, "latencies_ms": [2647.836], "images_per_second": 0.378, "prompt_tokens": 1113, "response_tokens_est": 5, "n_tiles": 1, "output_text": " apple: 10", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14688.6, "ram_available_mb": 48152.3, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14694.1, "ram_available_mb": 48146.8, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.238}, "power_stats": {"power_gpu_soc_mean_watts": 23.56, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 87.238}, "timestamp": "2026-01-30T09:54:13.121551"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4520.532, "latencies_ms": [4520.532], "images_per_second": 0.221, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The apples are in the foreground, with the bowl placed in the middle of the image. The bowl is located in the foreground, and the apples are placed inside it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14694.1, "ram_available_mb": 48146.8, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14696.0, "ram_available_mb": 48144.9, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.868}, "power_stats": {"power_gpu_soc_mean_watts": 20.223, "power_cpu_cv_mean_watts": 2.14, "power_sys_5v0_mean_watts": 7.861, "gpu_utilization_percent_mean": 77.868}, "timestamp": "2026-01-30T09:54:19.682277"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4038.98, "latencies_ms": [4038.98], "images_per_second": 0.248, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " In a dimly lit room, a white bowl cradles a collection of vibrant green apples, their glossy skins reflecting the soft light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14696.0, "ram_available_mb": 48144.9, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 11.2, "ram_used_mb": 14701.5, "ram_available_mb": 48139.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.394}, "power_stats": {"power_gpu_soc_mean_watts": 21.32, "power_cpu_cv_mean_watts": 2.513, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 75.394}, "timestamp": "2026-01-30T09:54:25.736032"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3151.475, "latencies_ms": [3151.475], "images_per_second": 0.317, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The apples are green and shiny, and the bowl is white.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14701.5, "ram_available_mb": 48139.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14706.8, "ram_available_mb": 48134.1, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.962}, "power_stats": {"power_gpu_soc_mean_watts": 22.9, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 83.962}, "timestamp": "2026-01-30T09:54:30.917154"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4276.744, "latencies_ms": [4276.744], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the batter, catcher, and umpire all in position, ready to react to the pitch.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14706.8, "ram_available_mb": 48134.1, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14708.2, "ram_available_mb": 48132.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.417}, "power_stats": {"power_gpu_soc_mean_watts": 20.867, "power_cpu_cv_mean_watts": 2.137, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 74.417}, "timestamp": "2026-01-30T09:54:37.227425"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6139.24, "latencies_ms": [6139.24], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. home plate: 1\n6. grass: 1\n7. dirt: 1\n8. net: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14708.2, "ram_available_mb": 48132.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 14708.5, "ram_available_mb": 48132.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.235}, "power_stats": {"power_gpu_soc_mean_watts": 18.391, "power_cpu_cv_mean_watts": 2.364, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 71.235}, "timestamp": "2026-01-30T09:54:45.377080"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4755.323, "latencies_ms": [4755.323], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The pitcher is standing on the mound, which is located in the middle of the field.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14708.5, "ram_available_mb": 48132.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14714.7, "ram_available_mb": 48126.2, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.154}, "power_stats": {"power_gpu_soc_mean_watts": 19.817, "power_cpu_cv_mean_watts": 2.178, "power_sys_5v0_mean_watts": 7.838, "gpu_utilization_percent_mean": 73.154}, "timestamp": "2026-01-30T09:54:52.151113"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7322.481, "latencies_ms": [7322.481], "images_per_second": 0.137, "prompt_tokens": 1111, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The image captures a moment in a baseball game, with the batter, wearing a red helmet and white uniform, in the midst of swinging his bat at a pitch. The umpire, dressed in a blue shirt and black pants, stands behind the catcher, who is crouched in anticipation. The field is a vibrant green, contrasting with the brown dirt of the infield.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14714.7, "ram_available_mb": 48126.2, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 14733.2, "ram_available_mb": 48107.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.328}, "power_stats": {"power_gpu_soc_mean_watts": 17.339, "power_cpu_cv_mean_watts": 2.39, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 71.328}, "timestamp": "2026-01-30T09:55:01.495959"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6785.651, "latencies_ms": [6785.651], "images_per_second": 0.147, "prompt_tokens": 1109, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the lush green of the field contrasting against the brown dirt of the infield. The players are dressed in crisp white uniforms, their red helmets adding a pop of color to the scene. The lighting is natural, casting a warm glow over the field as the sun shines down on the game.", "error": null, "sys_before": {"cpu_percent": 42.9, "ram_used_mb": 14733.2, "ram_available_mb": 48107.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 14735.5, "ram_available_mb": 48105.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.263}, "power_stats": {"power_gpu_soc_mean_watts": 17.306, "power_cpu_cv_mean_watts": 2.692, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 69.263}, "timestamp": "2026-01-30T09:55:10.305429"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4303.783, "latencies_ms": [4303.783], "images_per_second": 0.232, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A white cake with red and blue berries is on a table with a red tablecloth, surrounded by wine glasses, plates of cheese, and bread.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14735.5, "ram_available_mb": 48105.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 14738.3, "ram_available_mb": 48102.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.086}, "power_stats": {"power_gpu_soc_mean_watts": 20.823, "power_cpu_cv_mean_watts": 2.06, "power_sys_5v0_mean_watts": 7.907, "gpu_utilization_percent_mean": 78.086}, "timestamp": "2026-01-30T09:55:16.639061"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4594.833, "latencies_ms": [4594.833], "images_per_second": 0.218, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " cake: 1, glasses: 10, plates: 10, knives: 2, cups: 1, bowls: 1, grapes: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14738.3, "ram_available_mb": 48102.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14740.1, "ram_available_mb": 48100.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.237}, "power_stats": {"power_gpu_soc_mean_watts": 20.064, "power_cpu_cv_mean_watts": 2.15, "power_sys_5v0_mean_watts": 7.907, "gpu_utilization_percent_mean": 72.237}, "timestamp": "2026-01-30T09:55:23.277850"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6033.61, "latencies_ms": [6033.61], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The cake is located in the foreground, to the left of the plates of cheese and grapes. The plates of cheese and grapes are in the middle of the table, with the cake to the left of them. The glasses are located in the background, behind the plates of cheese and grapes.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14740.1, "ram_available_mb": 48100.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 14739.2, "ram_available_mb": 48101.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.72}, "power_stats": {"power_gpu_soc_mean_watts": 18.461, "power_cpu_cv_mean_watts": 2.291, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 70.72}, "timestamp": "2026-01-30T09:55:31.348966"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3329.41, "latencies_ms": [3329.41], "images_per_second": 0.3, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A table is set with a cake, plates of food, and glasses of water.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14739.2, "ram_available_mb": 48101.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.259}, "power_stats": {"power_gpu_soc_mean_watts": 22.985, "power_cpu_cv_mean_watts": 1.884, "power_sys_5v0_mean_watts": 8.097, "gpu_utilization_percent_mean": 77.259}, "timestamp": "2026-01-30T09:55:36.702865"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4366.798, "latencies_ms": [4366.798], "images_per_second": 0.229, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image features a red tablecloth, with a white cake and a plate of food on it. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14744.6, "ram_available_mb": 48096.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.444}, "power_stats": {"power_gpu_soc_mean_watts": 20.746, "power_cpu_cv_mean_watts": 2.126, "power_sys_5v0_mean_watts": 7.931, "gpu_utilization_percent_mean": 76.444}, "timestamp": "2026-01-30T09:55:43.090751"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3246.612, "latencies_ms": [3246.612], "images_per_second": 0.308, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is riding a wave on a blue surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14744.6, "ram_available_mb": 48096.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.658, "power_cpu_cv_mean_watts": 1.914, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 81.185}, "timestamp": "2026-01-30T09:55:48.399169"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5942.243, "latencies_ms": [5942.243], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. wave: 1\n4. water: 1\n5. sky: 0\n6. clouds: 0\n7. land: 0\n8. surfboard: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 14744.0, "ram_available_mb": 48096.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.84}, "power_stats": {"power_gpu_soc_mean_watts": 18.389, "power_cpu_cv_mean_watts": 2.339, "power_sys_5v0_mean_watts": 7.836, "gpu_utilization_percent_mean": 71.84}, "timestamp": "2026-01-30T09:55:56.355041"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4884.157, "latencies_ms": [4884.157], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, with the wave in the background. The surfer is on the left side of the wave, and the wave is on the right side.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14744.0, "ram_available_mb": 48096.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 14745.7, "ram_available_mb": 48095.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.394, "power_cpu_cv_mean_watts": 2.208, "power_sys_5v0_mean_watts": 7.859, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T09:56:03.261795"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3112.125, "latencies_ms": [3112.125], "images_per_second": 0.321, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14745.7, "ram_available_mb": 48095.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14743.5, "ram_available_mb": 48097.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.524, "power_cpu_cv_mean_watts": 1.843, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 81.76}, "timestamp": "2026-01-30T09:56:08.395916"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6359.357, "latencies_ms": [6359.357], "images_per_second": 0.157, "prompt_tokens": 1109, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a surfer in a black wetsuit riding a wave in the ocean, with the water appearing a deep green color and the sky not visible in the frame. The lighting is natural, suggesting it is daytime, and the surfer is in the foreground, with the wave in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14743.5, "ram_available_mb": 48097.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14747.4, "ram_available_mb": 48093.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.604}, "power_stats": {"power_gpu_soc_mean_watts": 18.048, "power_cpu_cv_mean_watts": 2.268, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 72.604}, "timestamp": "2026-01-30T09:56:16.797690"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3505.535, "latencies_ms": [3505.535], "images_per_second": 0.285, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of children are posing for a black and white photo in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 14747.4, "ram_available_mb": 48093.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14753.4, "ram_available_mb": 48087.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.271, "power_cpu_cv_mean_watts": 1.961, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 76.379}, "timestamp": "2026-01-30T09:56:22.328871"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5306.47, "latencies_ms": [5306.47], "images_per_second": 0.188, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " 1. group of children\n2. brick wall\n3. children's clothing\n4. children's shoes\n5. children's hair\n6. children's faces\n7. children's eyes\n8. children's noses", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14752.9, "ram_available_mb": 48088.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 12.6, "ram_used_mb": 14751.8, "ram_available_mb": 48089.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.222}, "power_stats": {"power_gpu_soc_mean_watts": 19.3, "power_cpu_cv_mean_watts": 2.591, "power_sys_5v0_mean_watts": 7.869, "gpu_utilization_percent_mean": 72.222}, "timestamp": "2026-01-30T09:56:29.673103"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5559.772, "latencies_ms": [5559.772], "images_per_second": 0.18, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The group of children is positioned in front of a brick building, with the children sitting on the ground and standing behind them. The children are arranged in rows, with some sitting and others standing, creating a sense of depth and perspective in the image.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14751.8, "ram_available_mb": 48089.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.891}, "power_stats": {"power_gpu_soc_mean_watts": 18.6, "power_cpu_cv_mean_watts": 2.246, "power_sys_5v0_mean_watts": 7.813, "gpu_utilization_percent_mean": 73.891}, "timestamp": "2026-01-30T09:56:37.249022"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3522.267, "latencies_ms": [3522.267], "images_per_second": 0.284, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of children are posing for a black and white photo in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.172}, "power_stats": {"power_gpu_soc_mean_watts": 22.173, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 7.973, "gpu_utilization_percent_mean": 77.172}, "timestamp": "2026-01-30T09:56:42.789194"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6106.324, "latencies_ms": [6106.324], "images_per_second": 0.164, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image is a black and white photograph with a grainy texture, capturing a moment of unity among the children. The lighting is soft and diffused, creating a sense of nostalgia and warmth. The children are dressed in their school uniforms, which are predominantly white and black, suggesting a formal setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.365}, "power_stats": {"power_gpu_soc_mean_watts": 18.136, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 70.365}, "timestamp": "2026-01-30T09:56:50.946485"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3452.837, "latencies_ms": [3452.837], "images_per_second": 0.29, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate of bread and a knife on a table with a wine glass in the background.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 13980.7, "ram_available_mb": 48860.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.336, "power_cpu_cv_mean_watts": 1.416, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 81.0}, "timestamp": "2026-01-30T09:56:56.445167"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4568.457, "latencies_ms": [4568.457], "images_per_second": 0.219, "prompt_tokens": 1114, "response_tokens_est": 36, "n_tiles": 1, "output_text": " knife: 1, plate: 1, bread: 1, cup: 1, wine glass: 1, napkin: 1, butter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.7, "ram_available_mb": 48860.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 13980.3, "ram_available_mb": 48860.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.658}, "power_stats": {"power_gpu_soc_mean_watts": 20.538, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 7.872, "gpu_utilization_percent_mean": 75.658}, "timestamp": "2026-01-30T09:57:03.030848"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6556.553, "latencies_ms": [6556.553], "images_per_second": 0.153, "prompt_tokens": 1118, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the bread and butter knife in the center, and the wine glass in the background. The bread is placed on the left side of the plate, while the butter knife is on the right side. The wine glass is located behind the plate, and the person is visible in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13980.3, "ram_available_mb": 48860.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13980.0, "ram_available_mb": 48860.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.218}, "power_stats": {"power_gpu_soc_mean_watts": 17.489, "power_cpu_cv_mean_watts": 2.025, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 70.218}, "timestamp": "2026-01-30T09:57:11.615611"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3834.344, "latencies_ms": [3834.344], "images_per_second": 0.261, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " In a cozy restaurant, a plate of bread and cheese is served on a table, accompanied by a glass of red wine.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13980.0, "ram_available_mb": 48860.9, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 13979.2, "ram_available_mb": 48861.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.156}, "power_stats": {"power_gpu_soc_mean_watts": 21.584, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 78.156}, "timestamp": "2026-01-30T09:57:17.468162"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4241.802, "latencies_ms": [4241.802], "images_per_second": 0.236, "prompt_tokens": 1110, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image features a wooden table with a white plate of food, a knife, and a wine glass. The lighting is natural, and the colors are warm.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13979.2, "ram_available_mb": 48861.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13978.2, "ram_available_mb": 48862.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.844, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 72.057}, "timestamp": "2026-01-30T09:57:23.726003"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4263.396, "latencies_ms": [4263.396], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A skier in a colorful outfit is jumping in the air with skis attached, while another skier in a white outfit stands nearby.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13978.2, "ram_available_mb": 48862.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13977.5, "ram_available_mb": 48863.4, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.385, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 71.8}, "timestamp": "2026-01-30T09:57:30.033983"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6175.537, "latencies_ms": [6175.537], "images_per_second": 0.162, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skier: 1\n2. ski poles: 2\n3. skis: 2\n4. snow: 1\n5. trees: 4\n6. person: 1\n7. helmet: 1\n8. goggles: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13977.5, "ram_available_mb": 48863.4, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13977.1, "ram_available_mb": 48863.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.96}, "power_stats": {"power_gpu_soc_mean_watts": 18.163, "power_cpu_cv_mean_watts": 1.979, "power_sys_5v0_mean_watts": 7.825, "gpu_utilization_percent_mean": 70.96}, "timestamp": "2026-01-30T09:57:38.238433"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4576.44, "latencies_ms": [4576.44], "images_per_second": 0.219, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The skier is in the foreground, jumping over a snow ramp, while the trees are in the background. The skier is closer to the camera than the trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13977.1, "ram_available_mb": 48863.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 13977.6, "ram_available_mb": 48863.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.632}, "power_stats": {"power_gpu_soc_mean_watts": 20.011, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.819, "gpu_utilization_percent_mean": 75.632}, "timestamp": "2026-01-30T09:57:44.876440"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4028.289, "latencies_ms": [4028.289], "images_per_second": 0.248, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A skier is jumping in the air with skis while wearing a colorful outfit. There are other skiers in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13977.6, "ram_available_mb": 48863.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 13978.3, "ram_available_mb": 48862.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.121}, "power_stats": {"power_gpu_soc_mean_watts": 21.331, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.892, "gpu_utilization_percent_mean": 77.121}, "timestamp": "2026-01-30T09:57:50.947984"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5099.194, "latencies_ms": [5099.194], "images_per_second": 0.196, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a skier in mid-air against a clear blue sky, with snow-covered trees in the background. The skier is wearing a colorful jacket and pants, and is holding ski poles.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13978.3, "ram_available_mb": 48862.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 13978.3, "ram_available_mb": 48862.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.262}, "power_stats": {"power_gpu_soc_mean_watts": 19.298, "power_cpu_cv_mean_watts": 1.831, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 74.262}, "timestamp": "2026-01-30T09:57:58.066941"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3317.481, "latencies_ms": [3317.481], "images_per_second": 0.301, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is walking on a snowy mountain with ski poles and wearing a green jacket.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 13978.3, "ram_available_mb": 48862.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13978.1, "ram_available_mb": 48862.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.037}, "power_stats": {"power_gpu_soc_mean_watts": 23.07, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 77.037}, "timestamp": "2026-01-30T09:58:03.430801"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5807.242, "latencies_ms": [5807.242], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. ski poles: 2\n3. backpack: 1\n4. snow: 1\n5. rocks: 2\n6. trees: 2\n7. clouds: 2\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13978.1, "ram_available_mb": 48862.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 13978.0, "ram_available_mb": 48862.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.633}, "power_stats": {"power_gpu_soc_mean_watts": 18.478, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 72.633}, "timestamp": "2026-01-30T09:58:11.259061"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4803.985, "latencies_ms": [4803.985], "images_per_second": 0.208, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The person is in the foreground of the image, with the snow-covered landscape and mountains in the background. The person is facing away from the camera, with the mountains and sky visible behind them.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13977.8, "ram_available_mb": 48863.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13977.5, "ram_available_mb": 48863.4, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.439}, "power_stats": {"power_gpu_soc_mean_watts": 19.749, "power_cpu_cv_mean_watts": 1.847, "power_sys_5v0_mean_watts": 7.898, "gpu_utilization_percent_mean": 73.439}, "timestamp": "2026-01-30T09:58:18.095240"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3496.613, "latencies_ms": [3496.613], "images_per_second": 0.286, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is walking on a snowy mountain trail with ski poles, wearing a green shirt and black pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13977.5, "ram_available_mb": 48863.4, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 13976.9, "ram_available_mb": 48864.0, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.621}, "power_stats": {"power_gpu_soc_mean_watts": 22.312, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 77.621}, "timestamp": "2026-01-30T09:58:23.606586"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5230.001, "latencies_ms": [5230.001], "images_per_second": 0.191, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a person wearing a green jacket and black pants, standing on a snowy mountain with a clear blue sky and white clouds in the background. The snow is pristine and untouched, with the person's footprints visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13976.9, "ram_available_mb": 48864.0, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.205}, "power_stats": {"power_gpu_soc_mean_watts": 19.56, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 7.852, "gpu_utilization_percent_mean": 70.205}, "timestamp": "2026-01-30T09:58:30.848889"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3192.318, "latencies_ms": [3192.318], "images_per_second": 0.313, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A banana and a chocolate donut are placed in a plastic bag.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13976.3, "ram_available_mb": 48864.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.885}, "power_stats": {"power_gpu_soc_mean_watts": 22.865, "power_cpu_cv_mean_watts": 1.294, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 80.885}, "timestamp": "2026-01-30T09:58:36.069726"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3251.074, "latencies_ms": [3251.074], "images_per_second": 0.308, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " banana: 1, donut: 1, plastic bag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13976.3, "ram_available_mb": 48864.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.519}, "power_stats": {"power_gpu_soc_mean_watts": 22.925, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 80.519}, "timestamp": "2026-01-30T09:58:41.341974"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4652.303, "latencies_ms": [4652.303], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The banana is positioned to the left of the donut, which is placed in the center of the image. The banana is in the foreground, while the donut is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.051}, "power_stats": {"power_gpu_soc_mean_watts": 20.329, "power_cpu_cv_mean_watts": 1.921, "power_sys_5v0_mean_watts": 7.908, "gpu_utilization_percent_mean": 74.051}, "timestamp": "2026-01-30T09:58:48.009946"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3060.893, "latencies_ms": [3060.893], "images_per_second": 0.327, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A banana and a donut are placed in a plastic bag.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.84}, "power_stats": {"power_gpu_soc_mean_watts": 23.286, "power_cpu_cv_mean_watts": 1.154, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 77.84}, "timestamp": "2026-01-30T09:58:53.129837"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4973.508, "latencies_ms": [4973.508], "images_per_second": 0.201, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a banana and a donut in a plastic bag, with the banana being yellow and the donut being brown. The lighting is dim, and the bag appears to be made of clear plastic.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.098}, "power_stats": {"power_gpu_soc_mean_watts": 19.916, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 7.827, "gpu_utilization_percent_mean": 73.098}, "timestamp": "2026-01-30T09:59:00.138026"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4767.042, "latencies_ms": [4767.042], "images_per_second": 0.21, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A white mug with a pirate skull and crossbones design and the words \"PIRATE'S TREASURES\" is placed on a glass surface next to a large knife.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 13977.1, "ram_available_mb": 48863.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.375}, "power_stats": {"power_gpu_soc_mean_watts": 19.532, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.819, "gpu_utilization_percent_mean": 72.375}, "timestamp": "2026-01-30T09:59:06.952929"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3568.789, "latencies_ms": [3568.789], "images_per_second": 0.28, "prompt_tokens": 1113, "response_tokens_est": 20, "n_tiles": 1, "output_text": " mug: 1, knife: 1, glass: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13977.1, "ram_available_mb": 48863.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.793}, "power_stats": {"power_gpu_soc_mean_watts": 22.283, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 81.793}, "timestamp": "2026-01-30T09:59:12.557969"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4481.72, "latencies_ms": [4481.72], "images_per_second": 0.223, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The mug is located to the left of the knife, which is placed in the foreground of the image. The mug is positioned closer to the camera than the knife.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13976.9, "ram_available_mb": 48864.0, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.691, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 7.924, "gpu_utilization_percent_mean": 74.054}, "timestamp": "2026-01-30T09:59:19.081246"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4349.009, "latencies_ms": [4349.009], "images_per_second": 0.23, "prompt_tokens": 1111, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A white mug with a pirate skull and crossbones design is sitting on a glass table. Next to the mug is a large knife with a black handle.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13976.9, "ram_available_mb": 48864.0, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 13977.4, "ram_available_mb": 48863.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.694}, "power_stats": {"power_gpu_soc_mean_watts": 20.577, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 7.94, "gpu_utilization_percent_mean": 74.694}, "timestamp": "2026-01-30T09:59:25.442026"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3615.531, "latencies_ms": [3615.531], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The mug is white and the knife is black. The mug is on a glass table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13977.4, "ram_available_mb": 48863.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.133}, "power_stats": {"power_gpu_soc_mean_watts": 21.796, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.919, "gpu_utilization_percent_mean": 81.133}, "timestamp": "2026-01-30T09:59:31.079366"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5055.774, "latencies_ms": [5055.774], "images_per_second": 0.198, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A group of people are gathered around a wooden counter in a wine tasting room, with a man in a white shirt and a woman in a black shirt standing out.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 13976.8, "ram_available_mb": 48864.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.595}, "power_stats": {"power_gpu_soc_mean_watts": 21.922, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 78.595}, "timestamp": "2026-01-30T09:59:38.163610"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6677.61, "latencies_ms": [6677.61], "images_per_second": 0.15, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13976.8, "ram_available_mb": 48864.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.732}, "power_stats": {"power_gpu_soc_mean_watts": 20.062, "power_cpu_cv_mean_watts": 2.075, "power_sys_5v0_mean_watts": 7.949, "gpu_utilization_percent_mean": 73.732}, "timestamp": "2026-01-30T09:59:46.897908"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8133.816, "latencies_ms": [8133.816], "images_per_second": 0.123, "prompt_tokens": 1450, "response_tokens_est": 80, "n_tiles": 1, "output_text": " The man in the white cap is standing to the left of the man in the blue shirt, who is standing in front of the counter. The woman in the black shirt is standing to the right of the man in the blue shirt, and the man in the white shirt is standing behind the counter. The man in the white cap is standing closer to the camera than the man in the blue shirt.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 13975.1, "ram_available_mb": 48865.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.101}, "power_stats": {"power_gpu_soc_mean_watts": 18.656, "power_cpu_cv_mean_watts": 2.072, "power_sys_5v0_mean_watts": 7.96, "gpu_utilization_percent_mean": 76.101}, "timestamp": "2026-01-30T09:59:57.053548"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4623.249, "latencies_ms": [4623.249], "images_per_second": 0.216, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of people are gathered in a wine tasting room, standing around a wooden counter with wine bottles on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13975.1, "ram_available_mb": 48865.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13976.4, "ram_available_mb": 48864.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.132}, "power_stats": {"power_gpu_soc_mean_watts": 22.813, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 80.132}, "timestamp": "2026-01-30T10:00:03.696321"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4552.82, "latencies_ms": [4552.82], "images_per_second": 0.22, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm ambiance, and the wooden floor is polished and clean.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 13976.4, "ram_available_mb": 48864.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13975.6, "ram_available_mb": 48865.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.108}, "power_stats": {"power_gpu_soc_mean_watts": 23.596, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 79.108}, "timestamp": "2026-01-30T10:00:10.269367"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4615.935, "latencies_ms": [4615.935], "images_per_second": 0.217, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In the image, there are two white birds standing in a field of tall grass, with a large body of water and a group of boats docked nearby, under a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13975.6, "ram_available_mb": 48865.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.526}, "power_stats": {"power_gpu_soc_mean_watts": 20.318, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.904, "gpu_utilization_percent_mean": 73.526}, "timestamp": "2026-01-30T10:00:16.908551"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5835.191, "latencies_ms": [5835.191], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. birds: 2\n2. grass: 1\n3. water: 1\n4. sky: 1\n5. clouds: 1\n6. boats: 1\n7. dock: 1\n8. crane: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.571}, "power_stats": {"power_gpu_soc_mean_watts": 18.364, "power_cpu_cv_mean_watts": 1.954, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 71.571}, "timestamp": "2026-01-30T10:00:24.762427"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4032.026, "latencies_ms": [4032.026], "images_per_second": 0.248, "prompt_tokens": 1117, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The two white birds are in the foreground, while the boats are in the background. The birds are closer to the camera than the boats.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 13975.0, "ram_available_mb": 48865.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.97}, "power_stats": {"power_gpu_soc_mean_watts": 21.685, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 76.97}, "timestamp": "2026-01-30T10:00:30.813395"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4660.143, "latencies_ms": [4660.143], "images_per_second": 0.215, "prompt_tokens": 1111, "response_tokens_est": 38, "n_tiles": 1, "output_text": " In the foreground, two white birds are standing in a field of tall grass. In the background, there is a body of water with several boats docked, and a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13975.0, "ram_available_mb": 48865.9, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 13975.2, "ram_available_mb": 48865.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.538}, "power_stats": {"power_gpu_soc_mean_watts": 19.962, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 7.917, "gpu_utilization_percent_mean": 73.538}, "timestamp": "2026-01-30T10:00:37.492557"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3884.901, "latencies_ms": [3884.901], "images_per_second": 0.257, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image features a vibrant green field with two white birds, a cloudy sky, and a body of water in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13975.2, "ram_available_mb": 48865.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 13975.2, "ram_available_mb": 48865.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.938}, "power_stats": {"power_gpu_soc_mean_watts": 21.772, "power_cpu_cv_mean_watts": 1.465, "power_sys_5v0_mean_watts": 7.943, "gpu_utilization_percent_mean": 74.938}, "timestamp": "2026-01-30T10:00:43.419569"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3683.104, "latencies_ms": [3683.104], "images_per_second": 0.272, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man is sitting on a toilet in a bathroom with a checkered tile wall and a window.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 13975.2, "ram_available_mb": 48865.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 13976.1, "ram_available_mb": 48864.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.233}, "power_stats": {"power_gpu_soc_mean_watts": 21.768, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 7.905, "gpu_utilization_percent_mean": 80.233}, "timestamp": "2026-01-30T10:00:49.138614"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6717.52, "latencies_ms": [6717.52], "images_per_second": 0.149, "prompt_tokens": 1114, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. man: 1\n2. toilet: 1\n3. man's pants: 1\n4. man's shirt: 1\n5. man's shoes: 1\n6. man's socks: 1\n7. man's belt: 1\n8. man's belt buckle: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13976.1, "ram_available_mb": 48864.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 13976.6, "ram_available_mb": 48864.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.911}, "power_stats": {"power_gpu_soc_mean_watts": 17.555, "power_cpu_cv_mean_watts": 2.031, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 70.911}, "timestamp": "2026-01-30T10:00:57.871310"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4820.113, "latencies_ms": [4820.113], "images_per_second": 0.207, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is sitting on the toilet, which is located in the foreground of the image. The sink is positioned to the left of the toilet, and the window is located above the sink.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13976.6, "ram_available_mb": 48864.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.025}, "power_stats": {"power_gpu_soc_mean_watts": 19.708, "power_cpu_cv_mean_watts": 1.763, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 75.025}, "timestamp": "2026-01-30T10:01:04.710453"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3320.785, "latencies_ms": [3320.785], "images_per_second": 0.301, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man is sitting on a toilet in a bathroom, wearing a shirt and pants.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13976.4, "ram_available_mb": 48864.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.593}, "power_stats": {"power_gpu_soc_mean_watts": 22.851, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 8.105, "gpu_utilization_percent_mean": 79.593}, "timestamp": "2026-01-30T10:01:10.055791"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3501.789, "latencies_ms": [3501.789], "images_per_second": 0.286, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image is in black and white, and the man is wearing a black shirt and jeans.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13976.4, "ram_available_mb": 48864.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.172}, "power_stats": {"power_gpu_soc_mean_watts": 22.283, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 79.172}, "timestamp": "2026-01-30T10:01:15.602415"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3969.843, "latencies_ms": [3969.843], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a group of people are standing on a snow-covered mountain, with a large rock formation in the background.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 13975.3, "ram_available_mb": 48865.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.031}, "power_stats": {"power_gpu_soc_mean_watts": 21.471, "power_cpu_cv_mean_watts": 1.59, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 76.031}, "timestamp": "2026-01-30T10:01:21.597981"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6182.433, "latencies_ms": [6182.433], "images_per_second": 0.162, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. mountain: 1\n2. people: 4\n3. ski tracks: 3\n4. snow: 1\n5. rocks: 1\n6. sky: 1\n7. mountain peak: 1\n8. snow-covered slope: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13975.3, "ram_available_mb": 48865.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 13975.2, "ram_available_mb": 48865.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.717}, "power_stats": {"power_gpu_soc_mean_watts": 18.171, "power_cpu_cv_mean_watts": 2.063, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 71.717}, "timestamp": "2026-01-30T10:01:29.818877"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4973.842, "latencies_ms": [4973.842], "images_per_second": 0.201, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The group of people is positioned in the foreground of the image, with the mountain range in the background. The mountain range is located to the right of the group, and the sky is visible above the mountain range.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13976.8, "ram_available_mb": 48864.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 13846.7, "ram_available_mb": 48994.2, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.476}, "power_stats": {"power_gpu_soc_mean_watts": 19.516, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 7.877, "gpu_utilization_percent_mean": 71.476}, "timestamp": "2026-01-30T10:01:36.812482"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3500.126, "latencies_ms": [3500.126], "images_per_second": 0.286, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are standing on a snowy mountain, with a large rock formation in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13846.7, "ram_available_mb": 48994.2, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13848.3, "ram_available_mb": 48992.6, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.552}, "power_stats": {"power_gpu_soc_mean_watts": 22.602, "power_cpu_cv_mean_watts": 1.492, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 77.552}, "timestamp": "2026-01-30T10:01:42.331427"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5530.056, "latencies_ms": [5530.056], "images_per_second": 0.181, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a group of people standing on a snow-covered mountain, with the sky above them being a clear blue. The snow is pristine white, and the mountain's surface is rugged and rocky, with some areas appearing to be covered in snow.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13848.3, "ram_available_mb": 48992.6, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 13848.6, "ram_available_mb": 48992.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.457}, "power_stats": {"power_gpu_soc_mean_watts": 18.943, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 73.457}, "timestamp": "2026-01-30T10:01:49.904433"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4262.9, "latencies_ms": [4262.9], "images_per_second": 0.235, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A white bowl filled with rice, broccoli, and a red bean dish is placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13848.6, "ram_available_mb": 48992.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13851.0, "ram_available_mb": 48989.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.629}, "power_stats": {"power_gpu_soc_mean_watts": 23.699, "power_cpu_cv_mean_watts": 1.27, "power_sys_5v0_mean_watts": 8.33, "gpu_utilization_percent_mean": 80.629}, "timestamp": "2026-01-30T10:01:56.214000"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4224.257, "latencies_ms": [4224.257], "images_per_second": 0.237, "prompt_tokens": 1446, "response_tokens_est": 19, "n_tiles": 1, "output_text": " broccoli: 2, rice: 1, bean: 1, vegetable: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13851.0, "ram_available_mb": 48989.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13850.4, "ram_available_mb": 48990.5, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.057}, "power_stats": {"power_gpu_soc_mean_watts": 23.89, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 8.239, "gpu_utilization_percent_mean": 83.057}, "timestamp": "2026-01-30T10:02:02.462458"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5627.961, "latencies_ms": [5627.961], "images_per_second": 0.178, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The broccoli is located to the left of the rice, which is in the center of the bowl. The red bean dish is on top of the rice, and the white rice is on the bottom of the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13850.4, "ram_available_mb": 48990.5, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13850.7, "ram_available_mb": 48990.2, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.488, "power_cpu_cv_mean_watts": 1.781, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 78.0}, "timestamp": "2026-01-30T10:02:10.151309"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3528.865, "latencies_ms": [3528.865], "images_per_second": 0.283, "prompt_tokens": 1444, "response_tokens_est": 9, "n_tiles": 1, "output_text": " A bowl of food is on a table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13850.7, "ram_available_mb": 48990.2, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13850.6, "ram_available_mb": 48990.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.897}, "power_stats": {"power_gpu_soc_mean_watts": 25.237, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.401, "gpu_utilization_percent_mean": 88.897}, "timestamp": "2026-01-30T10:02:15.721861"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3533.007, "latencies_ms": [3533.007], "images_per_second": 0.283, "prompt_tokens": 1442, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The bowl is white and the food is colorful.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13850.6, "ram_available_mb": 48990.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13854.9, "ram_available_mb": 48986.0, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.552}, "power_stats": {"power_gpu_soc_mean_watts": 25.474, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.432, "gpu_utilization_percent_mean": 85.552}, "timestamp": "2026-01-30T10:02:21.272484"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4045.581, "latencies_ms": [4045.581], "images_per_second": 0.247, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A person is riding a skateboard on a wooden ramp, wearing black and white sneakers with a checkered pattern on the bottom.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13854.9, "ram_available_mb": 48986.0, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.697}, "power_stats": {"power_gpu_soc_mean_watts": 21.186, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 7.95, "gpu_utilization_percent_mean": 77.697}, "timestamp": "2026-01-30T10:02:27.353143"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6623.917, "latencies_ms": [6623.917], "images_per_second": 0.151, "prompt_tokens": 1113, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. wooden plank: 1\n4. grass: 1\n5. wooden board: 1\n6. white letters: 1\n7. black and white checkered pattern: 1\n8. black and white shoes: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 13854.0, "ram_available_mb": 48986.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.909}, "power_stats": {"power_gpu_soc_mean_watts": 17.963, "power_cpu_cv_mean_watts": 2.054, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 68.909}, "timestamp": "2026-01-30T10:02:35.994237"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4341.25, "latencies_ms": [4341.25], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The skateboard is in the foreground, with the person's feet on it. The person is wearing jeans, and the skateboard is on a wooden ramp.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13854.0, "ram_available_mb": 48986.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.917}, "power_stats": {"power_gpu_soc_mean_watts": 20.754, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 7.917, "gpu_utilization_percent_mean": 75.917}, "timestamp": "2026-01-30T10:02:42.382242"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3390.581, "latencies_ms": [3390.581], "images_per_second": 0.295, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is riding a skateboard on a wooden ramp in a grassy area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13855.0, "ram_available_mb": 48985.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.296}, "power_stats": {"power_gpu_soc_mean_watts": 22.449, "power_cpu_cv_mean_watts": 1.305, "power_sys_5v0_mean_watts": 7.966, "gpu_utilization_percent_mean": 84.296}, "timestamp": "2026-01-30T10:02:47.802970"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4732.665, "latencies_ms": [4732.665], "images_per_second": 0.211, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a person wearing black and white sneakers with a checkered pattern on the bottom, standing on a wooden ramp. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13855.0, "ram_available_mb": 48985.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 13855.0, "ram_available_mb": 48985.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.718}, "power_stats": {"power_gpu_soc_mean_watts": 20.084, "power_cpu_cv_mean_watts": 1.674, "power_sys_5v0_mean_watts": 7.943, "gpu_utilization_percent_mean": 75.718}, "timestamp": "2026-01-30T10:02:54.566493"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3335.757, "latencies_ms": [3335.757], "images_per_second": 0.3, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bunch of bananas are on a desk with a computer keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13855.0, "ram_available_mb": 48985.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13854.5, "ram_available_mb": 48986.4, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.852}, "power_stats": {"power_gpu_soc_mean_watts": 22.985, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 78.852}, "timestamp": "2026-01-30T10:02:59.948939"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2435.163, "latencies_ms": [2435.163], "images_per_second": 0.411, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 4", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13854.5, "ram_available_mb": 48986.4, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13855.1, "ram_available_mb": 48985.8, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 90.4}, "power_stats": {"power_gpu_soc_mean_watts": 24.595, "power_cpu_cv_mean_watts": 1.221, "power_sys_5v0_mean_watts": 8.131, "gpu_utilization_percent_mean": 90.4}, "timestamp": "2026-01-30T10:03:04.406765"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4962.425, "latencies_ms": [4962.425], "images_per_second": 0.202, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The bananas are located in the foreground of the image, with the keyboard and computer monitor in the background. The bananas are positioned to the left of the keyboard, and the computer monitor is to the right of the keyboard.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13855.1, "ram_available_mb": 48985.8, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13854.3, "ram_available_mb": 48986.6, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.238}, "power_stats": {"power_gpu_soc_mean_watts": 19.983, "power_cpu_cv_mean_watts": 1.888, "power_sys_5v0_mean_watts": 7.91, "gpu_utilization_percent_mean": 73.238}, "timestamp": "2026-01-30T10:03:11.401783"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3291.475, "latencies_ms": [3291.475], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bunch of bananas are on a desk with a computer keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13854.3, "ram_available_mb": 48986.6, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.464, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 80.222}, "timestamp": "2026-01-30T10:03:16.735885"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3143.255, "latencies_ms": [3143.255], "images_per_second": 0.318, "prompt_tokens": 1109, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The bananas are yellow and ripe, and the table is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13854.3, "ram_available_mb": 48986.6, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.328, "power_cpu_cv_mean_watts": 1.248, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 79.5}, "timestamp": "2026-01-30T10:03:21.910635"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3243.369, "latencies_ms": [3243.369], "images_per_second": 0.308, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A plate of food with rice, vegetables, and chicken is on a table.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13854.3, "ram_available_mb": 48986.6, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 13854.1, "ram_available_mb": 48986.8, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.423}, "power_stats": {"power_gpu_soc_mean_watts": 23.269, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 77.423}, "timestamp": "2026-01-30T10:03:27.176866"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4712.422, "latencies_ms": [4712.422], "images_per_second": 0.212, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " plate: 1, fork: 1, knife: 1, glass: 1, rice: 1, carrots: 1, broccoli: 1, cauliflower: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13853.2, "ram_available_mb": 48987.7, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13853.2, "ram_available_mb": 48987.7, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.974}, "power_stats": {"power_gpu_soc_mean_watts": 20.38, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 7.903, "gpu_utilization_percent_mean": 72.974}, "timestamp": "2026-01-30T10:03:33.912734"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4769.408, "latencies_ms": [4769.408], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The plate with the food is in the foreground, and the glass of water is in the background. The fork is on the left side of the plate, and the spoon is on the right side.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13853.2, "ram_available_mb": 48987.7, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 13853.2, "ram_available_mb": 48987.7, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.744}, "power_stats": {"power_gpu_soc_mean_watts": 20.244, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 7.911, "gpu_utilization_percent_mean": 73.744}, "timestamp": "2026-01-30T10:03:40.696510"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3124.408, "latencies_ms": [3124.408], "images_per_second": 0.32, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate of food is on a table with a glass of water.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13853.2, "ram_available_mb": 48987.7, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13852.8, "ram_available_mb": 48988.1, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.769}, "power_stats": {"power_gpu_soc_mean_watts": 23.388, "power_cpu_cv_mean_watts": 1.294, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 81.769}, "timestamp": "2026-01-30T10:03:45.869456"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3863.343, "latencies_ms": [3863.343], "images_per_second": 0.259, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The plate is white and red, and the food is colorful. The lighting is natural, and the table is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13852.8, "ram_available_mb": 48988.1, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 13852.5, "ram_available_mb": 48988.4, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.344}, "power_stats": {"power_gpu_soc_mean_watts": 21.633, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 74.344}, "timestamp": "2026-01-30T10:03:51.761273"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4303.033, "latencies_ms": [4303.033], "images_per_second": 0.232, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A young girl in a colorful dress is playing with a Wii remote in a living room with a couch, a coffee table, and a staircase in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13852.5, "ram_available_mb": 48988.4, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13851.7, "ram_available_mb": 48989.2, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.25}, "power_stats": {"power_gpu_soc_mean_watts": 20.954, "power_cpu_cv_mean_watts": 2.047, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 77.25}, "timestamp": "2026-01-30T10:03:58.115590"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5933.341, "latencies_ms": [5933.341], "images_per_second": 0.169, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. couch: 1\n2. rug: 1\n3. chair: 1\n4. table: 1\n5. sofa: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13851.7, "ram_available_mb": 48989.2, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 13851.6, "ram_available_mb": 48989.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.08}, "power_stats": {"power_gpu_soc_mean_watts": 18.276, "power_cpu_cv_mean_watts": 2.107, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 71.08}, "timestamp": "2026-01-30T10:04:06.082653"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4835.504, "latencies_ms": [4835.504], "images_per_second": 0.207, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The couch is located in the background, with the girl standing in the foreground. The person in the white dress is standing near the couch, while the person in the green shirt is standing near the bar.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13851.6, "ram_available_mb": 48989.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 13851.0, "ram_available_mb": 48989.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.641}, "power_stats": {"power_gpu_soc_mean_watts": 20.604, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 76.641}, "timestamp": "2026-01-30T10:04:12.937808"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3973.64, "latencies_ms": [3973.64], "images_per_second": 0.252, "prompt_tokens": 1112, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of people are gathered in a living room, with a young girl playing with a toy in the center of the room.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13851.0, "ram_available_mb": 48989.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 13851.3, "ram_available_mb": 48989.6, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.688}, "power_stats": {"power_gpu_soc_mean_watts": 21.293, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 7.937, "gpu_utilization_percent_mean": 77.688}, "timestamp": "2026-01-30T10:04:18.924627"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3632.029, "latencies_ms": [3632.029], "images_per_second": 0.275, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from the windows, and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13851.3, "ram_available_mb": 48989.6, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 13851.5, "ram_available_mb": 48989.4, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.133}, "power_stats": {"power_gpu_soc_mean_watts": 22.074, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 77.133}, "timestamp": "2026-01-30T10:04:24.569849"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3625.337, "latencies_ms": [3625.337], "images_per_second": 0.276, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two men are shaking hands in a large room with tables and chairs, and other people in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13851.5, "ram_available_mb": 48989.4, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13852.0, "ram_available_mb": 48988.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.817, "power_cpu_cv_mean_watts": 1.549, "power_sys_5v0_mean_watts": 7.945, "gpu_utilization_percent_mean": 78.667}, "timestamp": "2026-01-30T10:04:30.225521"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5887.815, "latencies_ms": [5887.815], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 2\n2. man: 1\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 13852.0, "ram_available_mb": 48988.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 13850.3, "ram_available_mb": 48990.6, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.521}, "power_stats": {"power_gpu_soc_mean_watts": 18.426, "power_cpu_cv_mean_watts": 2.044, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 71.521}, "timestamp": "2026-01-30T10:04:38.148985"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6644.509, "latencies_ms": [6644.509], "images_per_second": 0.151, "prompt_tokens": 1117, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The man in the dark suit is standing to the right of the man in the patterned shirt, and the man in the dark suit is in the foreground of the image. The man in the patterned shirt is standing to the left of the man in the dark suit, and the man in the patterned shirt is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13850.3, "ram_available_mb": 48990.6, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 13850.9, "ram_available_mb": 48990.0, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.309}, "power_stats": {"power_gpu_soc_mean_watts": 17.77, "power_cpu_cv_mean_watts": 2.075, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 69.309}, "timestamp": "2026-01-30T10:04:46.821384"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3132.239, "latencies_ms": [3132.239], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two men are shaking hands in a large room with many other people.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13850.9, "ram_available_mb": 48990.0, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13850.9, "ram_available_mb": 48990.0, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.396, "power_cpu_cv_mean_watts": 1.234, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 81.76}, "timestamp": "2026-01-30T10:04:51.977177"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3667.517, "latencies_ms": [3667.517], "images_per_second": 0.273, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with warm lighting, and the attendees are dressed in formal attire.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13850.9, "ram_available_mb": 48990.0, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13851.9, "ram_available_mb": 48989.0, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.067}, "power_stats": {"power_gpu_soc_mean_watts": 22.38, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 78.067}, "timestamp": "2026-01-30T10:04:57.664193"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3331.034, "latencies_ms": [3331.034], "images_per_second": 0.3, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing a white shirt and a striped tie is standing in a dark room.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13851.9, "ram_available_mb": 48989.0, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 13851.6, "ram_available_mb": 48989.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.963}, "power_stats": {"power_gpu_soc_mean_watts": 22.892, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 76.963}, "timestamp": "2026-01-30T10:05:03.039009"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5821.853, "latencies_ms": [5821.853], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. tie: 1\n2. shirt: 1\n3. hand: 1\n4. person: 1\n5. tie: 1\n6. shirt: 1\n7. hand: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13851.6, "ram_available_mb": 48989.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 11.9, "ram_used_mb": 14010.1, "ram_available_mb": 48830.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.286}, "power_stats": {"power_gpu_soc_mean_watts": 18.418, "power_cpu_cv_mean_watts": 2.084, "power_sys_5v0_mean_watts": 7.822, "gpu_utilization_percent_mean": 71.286}, "timestamp": "2026-01-30T10:05:10.890071"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4778.727, "latencies_ms": [4778.727], "images_per_second": 0.209, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is standing in the foreground, wearing a white shirt and a striped tie. The background is dark and out of focus, suggesting that the man is in a dimly lit room.", "error": null, "sys_before": {"cpu_percent": 42.9, "ram_used_mb": 14011.5, "ram_available_mb": 48829.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 37.5, "ram_used_mb": 14575.3, "ram_available_mb": 48265.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.275}, "power_stats": {"power_gpu_soc_mean_watts": 19.99, "power_cpu_cv_mean_watts": 5.779, "power_sys_5v0_mean_watts": 8.111, "gpu_utilization_percent_mean": 74.275}, "timestamp": "2026-01-30T10:05:17.690301"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3105.655, "latencies_ms": [3105.655], "images_per_second": 0.322, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man wearing a tie and a shirt is standing in a dark room.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14575.3, "ram_available_mb": 48265.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 20.2, "ram_used_mb": 14746.7, "ram_available_mb": 48094.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.654}, "power_stats": {"power_gpu_soc_mean_watts": 23.267, "power_cpu_cv_mean_watts": 4.191, "power_sys_5v0_mean_watts": 8.293, "gpu_utilization_percent_mean": 74.654}, "timestamp": "2026-01-30T10:05:22.820262"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3638.184, "latencies_ms": [3638.184], "images_per_second": 0.275, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The man is wearing a white shirt and a striped tie. The lighting is dim and the background is dark.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14746.7, "ram_available_mb": 48094.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 11.5, "ram_used_mb": 14727.3, "ram_available_mb": 48113.6, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.367}, "power_stats": {"power_gpu_soc_mean_watts": 22.193, "power_cpu_cv_mean_watts": 2.563, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 80.367}, "timestamp": "2026-01-30T10:05:28.496082"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4057.664, "latencies_ms": [4057.664], "images_per_second": 0.246, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A room with a red chair, a blue and red plaid couch, a TV on a stand, and a whiteboard with writing on it.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 14727.3, "ram_available_mb": 48113.6, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 14756.0, "ram_available_mb": 48084.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.265}, "power_stats": {"power_gpu_soc_mean_watts": 21.242, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 78.265}, "timestamp": "2026-01-30T10:05:34.593054"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3718.768, "latencies_ms": [3718.768], "images_per_second": 0.269, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " chair: 1, couch: 2, television: 1, whiteboard: 1, poster: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14756.0, "ram_available_mb": 48084.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14757.4, "ram_available_mb": 48083.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.871}, "power_stats": {"power_gpu_soc_mean_watts": 21.992, "power_cpu_cv_mean_watts": 1.486, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 77.871}, "timestamp": "2026-01-30T10:05:40.372652"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6040.793, "latencies_ms": [6040.793], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The red armchair is positioned to the left of the television, which is placed on a wooden stand in the center of the room. The blue and red plaid couch is located to the right of the television, and the whiteboard is mounted on the wall to the left of the television.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 14757.4, "ram_available_mb": 48083.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 14762.3, "ram_available_mb": 48078.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.216}, "power_stats": {"power_gpu_soc_mean_watts": 18.418, "power_cpu_cv_mean_watts": 2.034, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 72.216}, "timestamp": "2026-01-30T10:05:48.433762"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2960.22, "latencies_ms": [2960.22], "images_per_second": 0.338, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A room with a TV, chairs, and a whiteboard.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14762.3, "ram_available_mb": 48078.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14551.7, "ram_available_mb": 48289.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.13}, "power_stats": {"power_gpu_soc_mean_watts": 24.153, "power_cpu_cv_mean_watts": 1.376, "power_sys_5v0_mean_watts": 8.288, "gpu_utilization_percent_mean": 86.13}, "timestamp": "2026-01-30T10:05:53.411089"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2993.484, "latencies_ms": [2993.484], "images_per_second": 0.334, "prompt_tokens": 1109, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The room is painted yellow and has a plaid couch.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14551.7, "ram_available_mb": 48289.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14551.7, "ram_available_mb": 48289.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.667}, "power_stats": {"power_gpu_soc_mean_watts": 23.635, "power_cpu_cv_mean_watts": 1.185, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 83.667}, "timestamp": "2026-01-30T10:05:58.428287"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3977.885, "latencies_ms": [3977.885], "images_per_second": 0.251, "prompt_tokens": 1432, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is riding a wave on a surfboard.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14551.7, "ram_available_mb": 48289.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14553.1, "ram_available_mb": 48287.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.939}, "power_stats": {"power_gpu_soc_mean_watts": 24.426, "power_cpu_cv_mean_watts": 1.359, "power_sys_5v0_mean_watts": 8.367, "gpu_utilization_percent_mean": 82.939}, "timestamp": "2026-01-30T10:06:04.474030"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7774.975, "latencies_ms": [7774.975], "images_per_second": 0.129, "prompt_tokens": 1446, "response_tokens_est": 76, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wetsuit: 1\n4. Wetsuit sleeve: 1\n5. Wetsuit leg: 1\n6. Wetsuit arm: 1\n7. Wetsuit chest: 1\n8. Wetsuit back: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14553.1, "ram_available_mb": 48287.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 14551.4, "ram_available_mb": 48289.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.938}, "power_stats": {"power_gpu_soc_mean_watts": 19.487, "power_cpu_cv_mean_watts": 2.644, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 74.938}, "timestamp": "2026-01-30T10:06:14.287284"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5791.821, "latencies_ms": [5791.821], "images_per_second": 0.173, "prompt_tokens": 1450, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that is in the middle of the image. The surfer is wearing a yellow shirt and black shorts, and is positioned on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14551.4, "ram_available_mb": 48289.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14551.8, "ram_available_mb": 48289.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.771}, "power_stats": {"power_gpu_soc_mean_watts": 21.194, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 8.111, "gpu_utilization_percent_mean": 77.771}, "timestamp": "2026-01-30T10:06:22.100093"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4299.01, "latencies_ms": [4299.01], "images_per_second": 0.233, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14551.8, "ram_available_mb": 48289.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14554.7, "ram_available_mb": 48286.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.167}, "power_stats": {"power_gpu_soc_mean_watts": 23.821, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 83.167}, "timestamp": "2026-01-30T10:06:28.437226"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4538.935, "latencies_ms": [4538.935], "images_per_second": 0.22, "prompt_tokens": 1442, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The surfer is wearing a yellow shirt and black pants, and the water is a greenish-blue color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14554.7, "ram_available_mb": 48286.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14553.8, "ram_available_mb": 48287.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.026}, "power_stats": {"power_gpu_soc_mean_watts": 22.631, "power_cpu_cv_mean_watts": 1.486, "power_sys_5v0_mean_watts": 8.112, "gpu_utilization_percent_mean": 82.026}, "timestamp": "2026-01-30T10:06:35.020720"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3306.522, "latencies_ms": [3306.522], "images_per_second": 0.302, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black cat is sitting in front of a computer monitor, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14553.8, "ram_available_mb": 48287.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14551.1, "ram_available_mb": 48289.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.789, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 83.185}, "timestamp": "2026-01-30T10:06:40.360764"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4477.57, "latencies_ms": [4477.57], "images_per_second": 0.223, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. black cat\n2. laptop\n3. computer monitor\n4. keyboard\n5. mouse\n6. phone\n7. mousepad\n8. desk", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14551.1, "ram_available_mb": 48289.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 14552.1, "ram_available_mb": 48288.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.919}, "power_stats": {"power_gpu_soc_mean_watts": 20.752, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 7.903, "gpu_utilization_percent_mean": 74.919}, "timestamp": "2026-01-30T10:06:46.853606"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5017.924, "latencies_ms": [5017.924], "images_per_second": 0.199, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The cat is positioned in the foreground, with its head turned towards the computer screen, which is located in the middle ground. The laptop is situated to the left of the cat, while the phone is placed to the right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14552.1, "ram_available_mb": 48288.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 14552.6, "ram_available_mb": 48288.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.488}, "power_stats": {"power_gpu_soc_mean_watts": 19.752, "power_cpu_cv_mean_watts": 1.856, "power_sys_5v0_mean_watts": 7.946, "gpu_utilization_percent_mean": 71.488}, "timestamp": "2026-01-30T10:06:53.884563"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3285.619, "latencies_ms": [3285.619], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black cat is sitting in front of a computer monitor, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14552.6, "ram_available_mb": 48288.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14552.4, "ram_available_mb": 48288.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.704}, "power_stats": {"power_gpu_soc_mean_watts": 23.212, "power_cpu_cv_mean_watts": 1.364, "power_sys_5v0_mean_watts": 8.07, "gpu_utilization_percent_mean": 78.704}, "timestamp": "2026-01-30T10:06:59.204430"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5920.429, "latencies_ms": [5920.429], "images_per_second": 0.169, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image is a close-up of a black cat sitting in front of a computer screen, with the cat's head turned to the side, and the screen displaying a webpage with text. The lighting in the image is bright, and the cat's fur appears to be soft and fluffy.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14552.4, "ram_available_mb": 48288.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14552.5, "ram_available_mb": 48288.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.86}, "power_stats": {"power_gpu_soc_mean_watts": 18.446, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 69.86}, "timestamp": "2026-01-30T10:07:07.156948"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4543.983, "latencies_ms": [4543.983], "images_per_second": 0.22, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A group of people, including a man in a blue shirt and a child in a pink jacket, are cutting a red ribbon with a pair of scissors in front of a building.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14552.5, "ram_available_mb": 48288.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 14556.7, "ram_available_mb": 48284.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.605}, "power_stats": {"power_gpu_soc_mean_watts": 20.426, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 7.893, "gpu_utilization_percent_mean": 73.605}, "timestamp": "2026-01-30T10:07:13.756439"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6361.987, "latencies_ms": [6361.987], "images_per_second": 0.157, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. People: 10\n2. Balloons: 2\n3. Helmet: 2\n4. Helmet: 1\n5. Helmet: 1\n6. Helmet: 1\n7. Helmet: 1\n8. Helmet: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14556.7, "ram_available_mb": 48284.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14554.7, "ram_available_mb": 48286.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.981}, "power_stats": {"power_gpu_soc_mean_watts": 18.108, "power_cpu_cv_mean_watts": 2.093, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 71.981}, "timestamp": "2026-01-30T10:07:22.163706"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6418.029, "latencies_ms": [6418.029], "images_per_second": 0.156, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the people standing in front of the building. The ribbon is positioned in the center of the image, with the people standing on either side of it. The people are positioned in the background of the image, with the building being the main focus of the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14554.7, "ram_available_mb": 48286.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14554.0, "ram_available_mb": 48286.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.038}, "power_stats": {"power_gpu_soc_mean_watts": 18.338, "power_cpu_cv_mean_watts": 2.07, "power_sys_5v0_mean_watts": 7.814, "gpu_utilization_percent_mean": 72.038}, "timestamp": "2026-01-30T10:07:30.597747"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3570.591, "latencies_ms": [3570.591], "images_per_second": 0.28, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered outside a building, cutting a red ribbon with a pair of scissors.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14554.0, "ram_available_mb": 48286.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14554.4, "ram_available_mb": 48286.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.655}, "power_stats": {"power_gpu_soc_mean_watts": 22.333, "power_cpu_cv_mean_watts": 1.436, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 75.655}, "timestamp": "2026-01-30T10:07:36.219151"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5873.135, "latencies_ms": [5873.135], "images_per_second": 0.17, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image is a vibrant and lively scene with a mix of warm and cool colors, capturing the essence of a bustling city street. The lighting is natural, with the sun casting a soft glow on the scene, and the weather appears to be clear, with no signs of rain or wind.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14554.4, "ram_available_mb": 48286.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 14555.3, "ram_available_mb": 48285.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.714}, "power_stats": {"power_gpu_soc_mean_watts": 18.872, "power_cpu_cv_mean_watts": 2.027, "power_sys_5v0_mean_watts": 7.876, "gpu_utilization_percent_mean": 71.714}, "timestamp": "2026-01-30T10:07:44.121728"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4477.965, "latencies_ms": [4477.965], "images_per_second": 0.223, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A white and pink bus with the number 65745 on the front is driving down a street with a sign that says \"First Group\" on top.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14555.3, "ram_available_mb": 48285.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14555.4, "ram_available_mb": 48285.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.459}, "power_stats": {"power_gpu_soc_mean_watts": 20.298, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.873, "gpu_utilization_percent_mean": 74.459}, "timestamp": "2026-01-30T10:07:50.665475"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5882.485, "latencies_ms": [5882.485], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bus: 1\n2. people: 1\n3. buildings: 1\n4. flowers: 1\n5. road: 1\n6. sky: 1\n7. clouds: 1\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14555.4, "ram_available_mb": 48285.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14555.2, "ram_available_mb": 48285.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.02}, "power_stats": {"power_gpu_soc_mean_watts": 18.74, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 72.02}, "timestamp": "2026-01-30T10:07:58.561552"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4644.637, "latencies_ms": [4644.637], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the street and buildings in the background. The bus is in the foreground, with the sidewalk and people in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14555.2, "ram_available_mb": 48285.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14556.1, "ram_available_mb": 48284.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.769}, "power_stats": {"power_gpu_soc_mean_watts": 20.202, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 7.872, "gpu_utilization_percent_mean": 72.769}, "timestamp": "2026-01-30T10:08:05.235694"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3456.461, "latencies_ms": [3456.461], "images_per_second": 0.289, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A white and pink bus is driving down a street with buildings and people in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14556.1, "ram_available_mb": 48284.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14554.8, "ram_available_mb": 48286.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.25}, "power_stats": {"power_gpu_soc_mean_watts": 22.313, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 80.25}, "timestamp": "2026-01-30T10:08:10.727245"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3290.273, "latencies_ms": [3290.273], "images_per_second": 0.304, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The bus is white, blue, and pink, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14554.8, "ram_available_mb": 48286.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14556.0, "ram_available_mb": 48284.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.37}, "power_stats": {"power_gpu_soc_mean_watts": 22.888, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 80.37}, "timestamp": "2026-01-30T10:08:16.075288"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3374.173, "latencies_ms": [3374.173], "images_per_second": 0.296, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man is sitting on the floor in front of a mirror, holding a cell phone.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 14556.0, "ram_available_mb": 48284.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14557.2, "ram_available_mb": 48283.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.607}, "power_stats": {"power_gpu_soc_mean_watts": 22.768, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 75.607}, "timestamp": "2026-01-30T10:08:21.505242"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5860.536, "latencies_ms": [5860.536], "images_per_second": 0.171, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Man: 1\n2. Mirror: 1\n3. Floor: 1\n4. Wall: 1\n5. Window: 1\n6. Door: 1\n7. Table: 1\n8. Chair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14557.2, "ram_available_mb": 48283.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14557.7, "ram_available_mb": 48283.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.224}, "power_stats": {"power_gpu_soc_mean_watts": 18.766, "power_cpu_cv_mean_watts": 1.994, "power_sys_5v0_mean_watts": 7.823, "gpu_utilization_percent_mean": 71.224}, "timestamp": "2026-01-30T10:08:29.386010"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5748.481, "latencies_ms": [5748.481], "images_per_second": 0.174, "prompt_tokens": 1118, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man is sitting in front of the mirror, which is positioned on the left side of the image. The mirror is reflecting the room behind him, which is located in the background. The man is sitting on the floor, which is in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14557.7, "ram_available_mb": 48283.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 14558.4, "ram_available_mb": 48282.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.562}, "power_stats": {"power_gpu_soc_mean_watts": 18.766, "power_cpu_cv_mean_watts": 1.961, "power_sys_5v0_mean_watts": 7.805, "gpu_utilization_percent_mean": 70.562}, "timestamp": "2026-01-30T10:08:37.148767"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3473.785, "latencies_ms": [3473.785], "images_per_second": 0.288, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is sitting on the floor in front of a mirror, taking a picture of himself.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14558.4, "ram_available_mb": 48282.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14558.6, "ram_available_mb": 48282.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.643}, "power_stats": {"power_gpu_soc_mean_watts": 22.498, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 79.643}, "timestamp": "2026-01-30T10:08:42.649293"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3477.507, "latencies_ms": [3477.507], "images_per_second": 0.288, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the wooden floor is polished and clean.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14558.6, "ram_available_mb": 48282.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14558.5, "ram_available_mb": 48282.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.793}, "power_stats": {"power_gpu_soc_mean_watts": 22.248, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 79.793}, "timestamp": "2026-01-30T10:08:48.159319"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4012.188, "latencies_ms": [4012.188], "images_per_second": 0.249, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A group of people, including a man holding a surfboard, are posing for a photo in a room with a door and a window.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 14558.5, "ram_available_mb": 48282.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14557.8, "ram_available_mb": 48283.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.424}, "power_stats": {"power_gpu_soc_mean_watts": 21.311, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 77.424}, "timestamp": "2026-01-30T10:08:54.197554"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5815.785, "latencies_ms": [5815.785], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. surfboard: 4\n2. person: 4\n3. person: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14557.8, "ram_available_mb": 48283.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 14561.5, "ram_available_mb": 48279.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.52}, "power_stats": {"power_gpu_soc_mean_watts": 18.897, "power_cpu_cv_mean_watts": 2.043, "power_sys_5v0_mean_watts": 7.84, "gpu_utilization_percent_mean": 73.52}, "timestamp": "2026-01-30T10:09:02.038077"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5099.2, "latencies_ms": [5099.2], "images_per_second": 0.196, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The surfboards are positioned in the foreground, with the group of people standing behind them. The person taking the photo is positioned to the left of the surfboards, while the person holding the flag is positioned to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14561.5, "ram_available_mb": 48279.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14577.6, "ram_available_mb": 48263.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.738}, "power_stats": {"power_gpu_soc_mean_watts": 19.434, "power_cpu_cv_mean_watts": 2.012, "power_sys_5v0_mean_watts": 7.928, "gpu_utilization_percent_mean": 72.738}, "timestamp": "2026-01-30T10:09:09.183259"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3351.59, "latencies_ms": [3351.59], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are posing for a picture in a room with surfboards.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14577.6, "ram_available_mb": 48263.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14572.1, "ram_available_mb": 48268.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.63}, "power_stats": {"power_gpu_soc_mean_watts": 22.547, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 82.63}, "timestamp": "2026-01-30T10:09:14.576778"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4492.602, "latencies_ms": [4492.602], "images_per_second": 0.223, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a white wall and a black door. The surfboards are in various colors, including yellow, blue, and red.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14572.1, "ram_available_mb": 48268.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 14572.0, "ram_available_mb": 48268.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.568}, "power_stats": {"power_gpu_soc_mean_watts": 20.665, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 7.933, "gpu_utilization_percent_mean": 76.568}, "timestamp": "2026-01-30T10:09:21.103984"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5097.682, "latencies_ms": [5097.682], "images_per_second": 0.196, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a large, golden-colored airplane with the words \"POLSKIE LOTNIE LOTNICZE\" written on its side, parked on a runway with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14572.0, "ram_available_mb": 48268.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14572.4, "ram_available_mb": 48268.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.833}, "power_stats": {"power_gpu_soc_mean_watts": 19.495, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 73.833}, "timestamp": "2026-01-30T10:09:28.249621"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5923.981, "latencies_ms": [5923.981], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. tail: 1\n3. wing: 2\n4. engine: 2\n5. wheels: 2\n6. logo: 1\n7. clouds: 1\n8. runway: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14572.4, "ram_available_mb": 48268.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14573.5, "ram_available_mb": 48267.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.224}, "power_stats": {"power_gpu_soc_mean_watts": 18.405, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 73.224}, "timestamp": "2026-01-30T10:09:36.190859"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4693.905, "latencies_ms": [4693.905], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The airplane is positioned in the foreground, with the runway and other aircraft in the background. The airplane is facing towards the left side of the image, and the tail of the airplane is visible.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14573.5, "ram_available_mb": 48267.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 14570.8, "ram_available_mb": 48270.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.051}, "power_stats": {"power_gpu_soc_mean_watts": 20.241, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 7.922, "gpu_utilization_percent_mean": 74.051}, "timestamp": "2026-01-30T10:09:42.905605"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3384.633, "latencies_ms": [3384.633], "images_per_second": 0.295, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A golden-colored airplane is parked on a runway with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14570.8, "ram_available_mb": 48270.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14571.0, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.393}, "power_stats": {"power_gpu_soc_mean_watts": 22.66, "power_cpu_cv_mean_watts": 1.359, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 78.393}, "timestamp": "2026-01-30T10:09:48.332093"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3265.427, "latencies_ms": [3265.427], "images_per_second": 0.306, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The airplane is gold and blue, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14571.0, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14571.8, "ram_available_mb": 48269.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.858, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 79.222}, "timestamp": "2026-01-30T10:09:53.621922"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3237.546, "latencies_ms": [3237.546], "images_per_second": 0.309, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A toilet with a lid up and water in it is in a bathroom.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14571.8, "ram_available_mb": 48269.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14572.5, "ram_available_mb": 48268.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.423}, "power_stats": {"power_gpu_soc_mean_watts": 22.903, "power_cpu_cv_mean_watts": 1.247, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 82.423}, "timestamp": "2026-01-30T10:09:58.876735"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5969.575, "latencies_ms": [5969.575], "images_per_second": 0.168, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " toilet: 1\ntoilet lid: 1\ntoilet seat: 1\ntoilet bowl: 1\ntoilet tank: 1\ntoilet tank lid: 1\ntoilet tank handle: 1\ntoilet tank knob: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14572.5, "ram_available_mb": 48268.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14570.9, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.2}, "power_stats": {"power_gpu_soc_mean_watts": 18.023, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 72.2}, "timestamp": "2026-01-30T10:10:06.889817"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5170.959, "latencies_ms": [5170.959], "images_per_second": 0.193, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the sink and towel rack in the background. The person's legs are visible in the bottom left corner of the image, suggesting they are standing near the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14570.9, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 14571.0, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.791}, "power_stats": {"power_gpu_soc_mean_watts": 19.297, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 7.81, "gpu_utilization_percent_mean": 73.791}, "timestamp": "2026-01-30T10:10:14.088665"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2990.812, "latencies_ms": [2990.812], "images_per_second": 0.334, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A toilet with a lid up is in a bathroom.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14571.0, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14571.3, "ram_available_mb": 48269.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.875}, "power_stats": {"power_gpu_soc_mean_watts": 23.077, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 82.875}, "timestamp": "2026-01-30T10:10:19.127002"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2845.463, "latencies_ms": [2845.463], "images_per_second": 0.351, "prompt_tokens": 1110, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The toilet is white and the water is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14571.3, "ram_available_mb": 48269.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 14570.2, "ram_available_mb": 48270.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.478}, "power_stats": {"power_gpu_soc_mean_watts": 23.889, "power_cpu_cv_mean_watts": 1.166, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 78.478}, "timestamp": "2026-01-30T10:10:23.996172"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3482.733, "latencies_ms": [3482.733], "images_per_second": 0.287, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A person wearing a blue jacket and a white helmet is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 13.8, "ram_used_mb": 14570.2, "ram_available_mb": 48270.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14570.7, "ram_available_mb": 48270.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.679}, "power_stats": {"power_gpu_soc_mean_watts": 22.742, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 79.679}, "timestamp": "2026-01-30T10:10:29.505639"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6011.203, "latencies_ms": [6011.203], "images_per_second": 0.166, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. goggles: 1\n4. ski poles: 2\n5. skis: 2\n6. snow: 1\n7. trees: 1\n8. snowboard: 0", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14570.7, "ram_available_mb": 48270.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 14570.7, "ram_available_mb": 48270.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.66}, "power_stats": {"power_gpu_soc_mean_watts": 18.494, "power_cpu_cv_mean_watts": 2.114, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 72.66}, "timestamp": "2026-01-30T10:10:37.529174"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5259.111, "latencies_ms": [5259.111], "images_per_second": 0.19, "prompt_tokens": 1118, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the snowy forest and trees in the background. The skier is skiing towards the left side of the image, with the trees and forest extending towards the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14570.7, "ram_available_mb": 48270.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14571.1, "ram_available_mb": 48269.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.659}, "power_stats": {"power_gpu_soc_mean_watts": 19.223, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.839, "gpu_utilization_percent_mean": 74.659}, "timestamp": "2026-01-30T10:10:44.811404"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3010.13, "latencies_ms": [3010.13], "images_per_second": 0.332, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A person is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14571.1, "ram_available_mb": 48269.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14571.1, "ram_available_mb": 48269.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.292}, "power_stats": {"power_gpu_soc_mean_watts": 23.278, "power_cpu_cv_mean_watts": 1.234, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 83.292}, "timestamp": "2026-01-30T10:10:49.840035"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3437.88, "latencies_ms": [3437.88], "images_per_second": 0.291, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a blue jacket and black pants, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14571.1, "ram_available_mb": 48269.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14570.9, "ram_available_mb": 48270.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.857}, "power_stats": {"power_gpu_soc_mean_watts": 22.927, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 76.857}, "timestamp": "2026-01-30T10:10:55.317944"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3921.234, "latencies_ms": [3921.234], "images_per_second": 0.255, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man in a yellow shirt and black shorts is playing tennis on a blue court with a crowd of people watching in the stands.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14570.6, "ram_available_mb": 48270.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 14570.9, "ram_available_mb": 48270.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.97}, "power_stats": {"power_gpu_soc_mean_watts": 21.288, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.916, "gpu_utilization_percent_mean": 75.97}, "timestamp": "2026-01-30T10:11:01.270756"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6629.173, "latencies_ms": [6629.173], "images_per_second": 0.151, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. blue court: 1\n5. white lines: 1\n6. white lines on court: 1\n7. white lines on court: 1\n8. white lines on court: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14570.9, "ram_available_mb": 48270.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14569.9, "ram_available_mb": 48271.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.596}, "power_stats": {"power_gpu_soc_mean_watts": 17.798, "power_cpu_cv_mean_watts": 2.129, "power_sys_5v0_mean_watts": 7.867, "gpu_utilization_percent_mean": 70.596}, "timestamp": "2026-01-30T10:11:09.943140"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4230.221, "latencies_ms": [4230.221], "images_per_second": 0.236, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The tennis player is in the foreground, with the crowd in the background. The player is near the net, while the ball is in the air.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14569.9, "ram_available_mb": 48271.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14569.1, "ram_available_mb": 48271.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.286}, "power_stats": {"power_gpu_soc_mean_watts": 20.883, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.923, "gpu_utilization_percent_mean": 75.286}, "timestamp": "2026-01-30T10:11:16.201668"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3867.499, "latencies_ms": [3867.499], "images_per_second": 0.259, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man in a yellow shirt and black shorts is playing tennis on a blue court, with a crowd of people watching in the stands.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14569.1, "ram_available_mb": 48271.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14569.6, "ram_available_mb": 48271.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.594}, "power_stats": {"power_gpu_soc_mean_watts": 21.803, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 76.594}, "timestamp": "2026-01-30T10:11:22.126039"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5005.55, "latencies_ms": [5005.55], "images_per_second": 0.2, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a tennis court with a blue surface, white lines, and a man in a yellow shirt and black shorts playing tennis. The lighting is bright, and the court is surrounded by a crowd of spectators.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14569.6, "ram_available_mb": 48271.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14570.1, "ram_available_mb": 48270.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.167}, "power_stats": {"power_gpu_soc_mean_watts": 19.893, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 7.857, "gpu_utilization_percent_mean": 72.167}, "timestamp": "2026-01-30T10:11:29.177306"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4208.836, "latencies_ms": [4208.836], "images_per_second": 0.238, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image shows a plate with two small metal bowls, one containing a reddish-brown curry and the other filled with orange and white dumplings.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14570.1, "ram_available_mb": 48270.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.743}, "power_stats": {"power_gpu_soc_mean_watts": 20.688, "power_cpu_cv_mean_watts": 2.403, "power_sys_5v0_mean_watts": 7.925, "gpu_utilization_percent_mean": 74.743}, "timestamp": "2026-01-30T10:11:35.434307"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3835.382, "latencies_ms": [3835.382], "images_per_second": 0.261, "prompt_tokens": 1113, "response_tokens_est": 25, "n_tiles": 1, "output_text": " bowl: 2, plate: 1, napkin: 1, glass: 1, food: 3", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14569.2, "ram_available_mb": 48271.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.594}, "power_stats": {"power_gpu_soc_mean_watts": 21.564, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 77.594}, "timestamp": "2026-01-30T10:11:41.303874"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5308.583, "latencies_ms": [5308.583], "images_per_second": 0.188, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The bowl of curry is located to the left of the bowl of fruit, with the curry bowl being closer to the camera than the fruit bowl. The fruit bowl is positioned in the foreground, while the curry bowl is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14569.0, "ram_available_mb": 48271.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.178}, "power_stats": {"power_gpu_soc_mean_watts": 18.983, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 70.178}, "timestamp": "2026-01-30T10:11:48.646340"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3653.829, "latencies_ms": [3653.829], "images_per_second": 0.274, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A plate with two bowls of food on it, one with a red sauce and the other with orange food.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14568.5, "ram_available_mb": 48272.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.033}, "power_stats": {"power_gpu_soc_mean_watts": 22.067, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 77.033}, "timestamp": "2026-01-30T10:11:54.337557"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5396.122, "latencies_ms": [5396.122], "images_per_second": 0.185, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a plate with two bowls of food, one containing a reddish-brown dish and the other a bowl of orange and white food. The food is placed on a white napkin, and the background is a dark green tablecloth.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14568.5, "ram_available_mb": 48272.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 14568.1, "ram_available_mb": 48272.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.178}, "power_stats": {"power_gpu_soc_mean_watts": 19.413, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 73.178}, "timestamp": "2026-01-30T10:12:01.783455"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4233.529, "latencies_ms": [4233.529], "images_per_second": 0.236, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, there are four sheep standing in a grassy area, with one sheep looking directly at the camera, and the others facing away from it.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14568.1, "ram_available_mb": 48272.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14567.8, "ram_available_mb": 48273.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.286}, "power_stats": {"power_gpu_soc_mean_watts": 20.619, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.944, "gpu_utilization_percent_mean": 75.286}, "timestamp": "2026-01-30T10:12:08.078887"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2624.366, "latencies_ms": [2624.366], "images_per_second": 0.381, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " sheep: 5", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14567.8, "ram_available_mb": 48273.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14567.3, "ram_available_mb": 48273.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.429}, "power_stats": {"power_gpu_soc_mean_watts": 23.474, "power_cpu_cv_mean_watts": 1.029, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 87.429}, "timestamp": "2026-01-30T10:12:12.764578"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4937.117, "latencies_ms": [4937.117], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The sheep are positioned in the foreground of the image, with the brick wall serving as the background. The sheep are standing close to each other, with one sheep in the foreground and the others in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14567.3, "ram_available_mb": 48273.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 14568.2, "ram_available_mb": 48272.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.634}, "power_stats": {"power_gpu_soc_mean_watts": 19.995, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 7.886, "gpu_utilization_percent_mean": 75.634}, "timestamp": "2026-01-30T10:12:19.745115"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3530.033, "latencies_ms": [3530.033], "images_per_second": 0.283, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " In a sunny day, a group of sheep are standing in a grassy area near a brick wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14568.2, "ram_available_mb": 48272.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14567.0, "ram_available_mb": 48273.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.69}, "power_stats": {"power_gpu_soc_mean_watts": 22.218, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 78.69}, "timestamp": "2026-01-30T10:12:25.337459"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4949.676, "latencies_ms": [4949.676], "images_per_second": 0.202, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a group of sheep with thick wool coats, standing in a grassy area with a brick wall in the background. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14567.0, "ram_available_mb": 48273.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 14567.5, "ram_available_mb": 48273.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.732}, "power_stats": {"power_gpu_soc_mean_watts": 19.919, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.864, "gpu_utilization_percent_mean": 71.732}, "timestamp": "2026-01-30T10:12:32.315790"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4200.421, "latencies_ms": [4200.421], "images_per_second": 0.238, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " In the image, a bunch of bananas and an apple are placed on a blue and white patterned background.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 14567.0, "ram_available_mb": 48273.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14565.2, "ram_available_mb": 48275.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.971}, "power_stats": {"power_gpu_soc_mean_watts": 23.865, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.356, "gpu_utilization_percent_mean": 82.971}, "timestamp": "2026-01-30T10:12:38.553191"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3594.25, "latencies_ms": [3594.25], "images_per_second": 0.278, "prompt_tokens": 1446, "response_tokens_est": 9, "n_tiles": 1, "output_text": " banana: 5, apple: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14565.2, "ram_available_mb": 48275.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 14565.9, "ram_available_mb": 48275.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.793}, "power_stats": {"power_gpu_soc_mean_watts": 25.396, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.333, "gpu_utilization_percent_mean": 84.793}, "timestamp": "2026-01-30T10:12:44.178153"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6595.48, "latencies_ms": [6595.48], "images_per_second": 0.152, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The red apple is positioned in the center of the image, with the bananas surrounding it. The bananas are arranged in a circular pattern, with the red apple placed in the middle. The background is a blue and white floral pattern, which provides a contrast to the vibrant colors of the fruit.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14565.9, "ram_available_mb": 48275.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14564.6, "ram_available_mb": 48276.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.321}, "power_stats": {"power_gpu_soc_mean_watts": 20.233, "power_cpu_cv_mean_watts": 1.981, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 75.321}, "timestamp": "2026-01-30T10:12:52.792016"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6517.706, "latencies_ms": [6517.706], "images_per_second": 0.153, "prompt_tokens": 1444, "response_tokens_est": 55, "n_tiles": 1, "output_text": " In the center of the image, a vibrant red apple sits atop a bunch of bananas, which are arranged in a circular pattern around it. The bananas are a bright yellow color, and the apple's red hue stands out against the backdrop of a blue and white floral pattern.", "error": null, "sys_before": {"cpu_percent": 18.7, "ram_used_mb": 14564.6, "ram_available_mb": 48276.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14565.5, "ram_available_mb": 48275.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.222}, "power_stats": {"power_gpu_soc_mean_watts": 20.39, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 8.091, "gpu_utilization_percent_mean": 76.222}, "timestamp": "2026-01-30T10:13:01.354240"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7330.039, "latencies_ms": [7330.039], "images_per_second": 0.136, "prompt_tokens": 1442, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a vibrant display of bananas and an apple, with the bananas arranged in a circular pattern around the apple. The bananas are a bright yellow color, while the apple is a striking combination of red and yellow hues. The background is a cool blue color with a floral pattern, providing a stark contrast to the warm colors of the fruit.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14564.9, "ram_available_mb": 48276.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 14563.7, "ram_available_mb": 48277.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.279}, "power_stats": {"power_gpu_soc_mean_watts": 19.488, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 75.279}, "timestamp": "2026-01-30T10:13:10.733448"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3689.981, "latencies_ms": [3689.981], "images_per_second": 0.271, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A blue and white train with red seats is parked at a station with trees and power lines in the background.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14563.7, "ram_available_mb": 48277.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14563.8, "ram_available_mb": 48277.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.833}, "power_stats": {"power_gpu_soc_mean_watts": 21.801, "power_cpu_cv_mean_watts": 1.495, "power_sys_5v0_mean_watts": 7.96, "gpu_utilization_percent_mean": 77.833}, "timestamp": "2026-01-30T10:13:16.451332"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5947.279, "latencies_ms": [5947.279], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. train: 1\n2. windows: 12\n3. doors: 2\n4. seats: 12\n5. trolley: 1\n6. tracks: 2\n7. trees: 1\n8. wires: 1", "error": null, "sys_before": {"cpu_percent": 50.0, "ram_used_mb": 14563.8, "ram_available_mb": 48277.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14563.7, "ram_available_mb": 48277.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.78}, "power_stats": {"power_gpu_soc_mean_watts": 18.585, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 72.78}, "timestamp": "2026-01-30T10:13:24.442345"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4847.602, "latencies_ms": [4847.602], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The train is positioned on the left side of the image, with the tracks extending towards the right. The background features a clear blue sky and trees, while the foreground includes a fence and a building.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14563.7, "ram_available_mb": 48277.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14561.8, "ram_available_mb": 48279.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.25}, "power_stats": {"power_gpu_soc_mean_watts": 19.994, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.85, "gpu_utilization_percent_mean": 73.25}, "timestamp": "2026-01-30T10:13:31.331381"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3567.718, "latencies_ms": [3567.718], "images_per_second": 0.28, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A blue and white train is parked at a station, with trees and other vehicles in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14561.8, "ram_available_mb": 48279.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 14562.4, "ram_available_mb": 48278.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.793}, "power_stats": {"power_gpu_soc_mean_watts": 22.136, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 78.793}, "timestamp": "2026-01-30T10:13:36.926001"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3106.804, "latencies_ms": [3106.804], "images_per_second": 0.322, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The train is blue and white, and the sky is clear blue.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14562.4, "ram_available_mb": 48278.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14562.3, "ram_available_mb": 48278.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.423}, "power_stats": {"power_gpu_soc_mean_watts": 23.245, "power_cpu_cv_mean_watts": 1.324, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 82.423}, "timestamp": "2026-01-30T10:13:42.065886"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3925.118, "latencies_ms": [3925.118], "images_per_second": 0.255, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image depicts a bathroom with a shower, a bathtub, and a double sink vanity, all with a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14562.3, "ram_available_mb": 48278.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14563.5, "ram_available_mb": 48277.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.531}, "power_stats": {"power_gpu_soc_mean_watts": 21.638, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 80.531}, "timestamp": "2026-01-30T10:13:48.010479"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6065.874, "latencies_ms": [6065.874], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Bathtub: 1\n2. Shower: 1\n3. Mirror: 2\n4. Sink: 1\n5. Cabinet: 1\n6. Towel: 1\n7. Rug: 1\n8. Light: 2", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14563.5, "ram_available_mb": 48277.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14564.0, "ram_available_mb": 48276.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.942}, "power_stats": {"power_gpu_soc_mean_watts": 18.161, "power_cpu_cv_mean_watts": 2.048, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 71.942}, "timestamp": "2026-01-30T10:13:56.110283"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4711.558, "latencies_ms": [4711.558], "images_per_second": 0.212, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The shower is located to the left of the sink, and the bathtub is situated behind the shower. The sink is positioned in the foreground, while the mirror is located in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14564.0, "ram_available_mb": 48276.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 14564.1, "ram_available_mb": 48276.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.179}, "power_stats": {"power_gpu_soc_mean_watts": 19.921, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.872, "gpu_utilization_percent_mean": 72.179}, "timestamp": "2026-01-30T10:14:02.848321"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3278.953, "latencies_ms": [3278.953], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bathroom with a shower, bathtub, and sink is shown in the image.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14564.1, "ram_available_mb": 48276.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14564.2, "ram_available_mb": 48276.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.679, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 78.667}, "timestamp": "2026-01-30T10:14:08.141686"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4406.259, "latencies_ms": [4406.259], "images_per_second": 0.227, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The bathroom has a warm color scheme with beige walls and a red rug on the floor. The lighting is bright and natural, coming from a window in the background.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14564.2, "ram_available_mb": 48276.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 14564.8, "ram_available_mb": 48276.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.771, "power_cpu_cv_mean_watts": 1.753, "power_sys_5v0_mean_watts": 7.935, "gpu_utilization_percent_mean": 73.054}, "timestamp": "2026-01-30T10:14:14.568704"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4125.998, "latencies_ms": [4125.998], "images_per_second": 0.242, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A black and white photo captures a surfer skillfully riding a wave, with the word \"STAR\" prominently displayed in the top right corner.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14564.8, "ram_available_mb": 48276.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14568.5, "ram_available_mb": 48272.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.382}, "power_stats": {"power_gpu_soc_mean_watts": 21.025, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 76.382}, "timestamp": "2026-01-30T10:14:20.730068"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5969.36, "latencies_ms": [5969.36], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wave: 1\n4. Water: 1\n5. Ocean: 1\n6. Sky: 1\n7. Clouds: 1\n8. Text: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14568.5, "ram_available_mb": 48272.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14566.2, "ram_available_mb": 48274.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.38}, "power_stats": {"power_gpu_soc_mean_watts": 18.846, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 74.38}, "timestamp": "2026-01-30T10:14:28.753864"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5226.995, "latencies_ms": [5226.995], "images_per_second": 0.191, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The surfer is in the middle of the wave, with the spray of water from the wave being the closest object to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14566.2, "ram_available_mb": 48274.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14566.8, "ram_available_mb": 48274.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.341}, "power_stats": {"power_gpu_soc_mean_watts": 19.187, "power_cpu_cv_mean_watts": 1.957, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 72.341}, "timestamp": "2026-01-30T10:14:36.007703"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3205.248, "latencies_ms": [3205.248], "images_per_second": 0.312, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14566.8, "ram_available_mb": 48274.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14566.5, "ram_available_mb": 48274.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.846}, "power_stats": {"power_gpu_soc_mean_watts": 22.844, "power_cpu_cv_mean_watts": 1.294, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 82.846}, "timestamp": "2026-01-30T10:14:41.238839"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5834.251, "latencies_ms": [5834.251], "images_per_second": 0.171, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image is in black and white, with the surfer's silhouette standing out against the white foam of the wave. The lighting is natural, with the sun reflecting off the water, creating a dramatic contrast between the dark silhouette of the surfer and the bright white foam.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14566.5, "ram_available_mb": 48274.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14566.5, "ram_available_mb": 48274.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.735}, "power_stats": {"power_gpu_soc_mean_watts": 18.564, "power_cpu_cv_mean_watts": 1.962, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 72.735}, "timestamp": "2026-01-30T10:14:49.097971"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5298.637, "latencies_ms": [5298.637], "images_per_second": 0.189, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " A baseball player in a white uniform with the number 10 on it is standing at home plate with a bat in his hand, while a catcher in a black uniform and a umpire in a blue shirt are behind him.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 14566.5, "ram_available_mb": 48274.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14566.4, "ram_available_mb": 48274.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.045, "power_cpu_cv_mean_watts": 1.912, "power_sys_5v0_mean_watts": 7.84, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T10:14:56.436675"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6331.732, "latencies_ms": [6331.732], "images_per_second": 0.158, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. home plate: 1\n6. baseball: 1\n7. grass: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14566.1, "ram_available_mb": 48274.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14566.1, "ram_available_mb": 48274.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.358}, "power_stats": {"power_gpu_soc_mean_watts": 17.732, "power_cpu_cv_mean_watts": 2.018, "power_sys_5v0_mean_watts": 7.685, "gpu_utilization_percent_mean": 71.358}, "timestamp": "2026-01-30T10:15:04.783624"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4455.076, "latencies_ms": [4455.076], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14566.1, "ram_available_mb": 48274.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 14566.4, "ram_available_mb": 48274.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.86, "power_cpu_cv_mean_watts": 1.764, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 76.054}, "timestamp": "2026-01-30T10:15:11.291912"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3354.169, "latencies_ms": [3354.169], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A baseball game is taking place in a stadium with a crowd of people watching.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14566.4, "ram_available_mb": 48274.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14567.9, "ram_available_mb": 48273.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.259}, "power_stats": {"power_gpu_soc_mean_watts": 22.507, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 82.259}, "timestamp": "2026-01-30T10:15:16.674058"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6308.156, "latencies_ms": [6308.156], "images_per_second": 0.159, "prompt_tokens": 1109, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the players dressed in crisp white uniforms and the lush green grass of the field contrasting against the blue sky. The lighting is natural, casting a warm glow on the players and the field, while the weather appears to be clear, with no signs of rain or wind.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14567.9, "ram_available_mb": 48273.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14572.2, "ram_available_mb": 48268.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.094}, "power_stats": {"power_gpu_soc_mean_watts": 18.152, "power_cpu_cv_mean_watts": 1.995, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 71.094}, "timestamp": "2026-01-30T10:15:24.997539"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4091.356, "latencies_ms": [4091.356], "images_per_second": 0.244, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a bunch of fruits and nuts on a white surface.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14572.2, "ram_available_mb": 48268.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14572.0, "ram_available_mb": 48268.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.206}, "power_stats": {"power_gpu_soc_mean_watts": 23.36, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 8.215, "gpu_utilization_percent_mean": 80.206}, "timestamp": "2026-01-30T10:15:31.144786"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5330.782, "latencies_ms": [5330.782], "images_per_second": 0.188, "prompt_tokens": 1446, "response_tokens_est": 39, "n_tiles": 1, "output_text": " apple: 2, grapes: 10, orange: 1, grapes: 10, grapes: 10, grapes: 10, grapes: 10", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14572.0, "ram_available_mb": 48268.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14572.4, "ram_available_mb": 48268.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.156}, "power_stats": {"power_gpu_soc_mean_watts": 22.049, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.217, "gpu_utilization_percent_mean": 77.156}, "timestamp": "2026-01-30T10:15:38.521744"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7790.989, "latencies_ms": [7790.989], "images_per_second": 0.128, "prompt_tokens": 1450, "response_tokens_est": 76, "n_tiles": 1, "output_text": " The main objects are arranged in a diagonal line from the top left to the bottom right, with the grapes and oranges placed in the foreground and the peanuts in the background. The objects are positioned in a way that creates a sense of depth and perspective, with the larger objects (grapes and oranges) in the foreground and the smaller objects (peanuts) in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14572.4, "ram_available_mb": 48268.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 14571.6, "ram_available_mb": 48269.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.677}, "power_stats": {"power_gpu_soc_mean_watts": 19.68, "power_cpu_cv_mean_watts": 2.052, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 72.677}, "timestamp": "2026-01-30T10:15:48.326108"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4041.98, "latencies_ms": [4041.98], "images_per_second": 0.247, "prompt_tokens": 1444, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a bunch of fruits and nuts on a white surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14571.6, "ram_available_mb": 48269.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14570.6, "ram_available_mb": 48270.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.97}, "power_stats": {"power_gpu_soc_mean_watts": 24.058, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.297, "gpu_utilization_percent_mean": 79.97}, "timestamp": "2026-01-30T10:15:54.396833"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4565.008, "latencies_ms": [4565.008], "images_per_second": 0.219, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is a black and white photo with a white background, and the fruits are all in shades of white and gray.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14570.6, "ram_available_mb": 48270.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.649}, "power_stats": {"power_gpu_soc_mean_watts": 23.569, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.245, "gpu_utilization_percent_mean": 81.649}, "timestamp": "2026-01-30T10:16:00.974702"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 8330.894, "latencies_ms": [8330.894], "images_per_second": 0.12, "prompt_tokens": 1099, "response_tokens_est": 96, "n_tiles": 1, "output_text": " The image captures a bustling urban street scene, where a variety of vehicles, including cars and a bus, are in motion, while pedestrians can be seen walking along the sidewalks. The buildings lining the street are a mix of modern and older architectural styles, with some featuring balconies and others boasting large windows. The sky overhead is a clear blue, suggesting a bright and sunny day, and the street is lined with trees and greenery, adding a touch of nature to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14569.8, "ram_available_mb": 48271.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.722}, "power_stats": {"power_gpu_soc_mean_watts": 16.412, "power_cpu_cv_mean_watts": 2.236, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 67.722}, "timestamp": "2026-01-30T10:16:11.355233"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5960.089, "latencies_ms": [5960.089], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. street: 2 lanes\n2. car: 2\n3. building: 3\n4. sidewalk: 1\n5. streetlight: 2\n6. tree: 1\n7. road: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14569.8, "ram_available_mb": 48271.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14570.5, "ram_available_mb": 48270.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.02}, "power_stats": {"power_gpu_soc_mean_watts": 18.363, "power_cpu_cv_mean_watts": 2.034, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 73.02}, "timestamp": "2026-01-30T10:16:19.339873"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7023.51, "latencies_ms": [7023.51], "images_per_second": 0.142, "prompt_tokens": 1117, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The main objects in the image are positioned in a way that the street is in the foreground, with the buildings and trees in the background. The street is on the left side of the image, while the buildings and trees are on the right side. The buildings are located on both sides of the street, with the trees lining the sidewalk on the right side.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14570.5, "ram_available_mb": 48270.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 28.0, "ram_used_mb": 15258.4, "ram_available_mb": 47582.5, "ram_percent": 24.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.167}, "power_stats": {"power_gpu_soc_mean_watts": 17.424, "power_cpu_cv_mean_watts": 4.112, "power_sys_5v0_mean_watts": 7.897, "gpu_utilization_percent_mean": 68.167}, "timestamp": "2026-01-30T10:16:28.399897"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6800.474, "latencies_ms": [6800.474], "images_per_second": 0.147, "prompt_tokens": 1111, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The image captures a bustling urban street scene, where modern buildings of varying heights and designs line the street. The buildings are adorned with balconies and windows, reflecting the city's vibrant life. Cars are parked neatly along the side of the road, and a few pedestrians can be seen strolling along the sidewalk, adding to the lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 52.0, "ram_used_mb": 15259.9, "ram_available_mb": 47581.0, "ram_percent": 24.3}, "sys_after": {"cpu_percent": 29.7, "ram_used_mb": 15414.1, "ram_available_mb": 47426.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.776}, "power_stats": {"power_gpu_soc_mean_watts": 17.265, "power_cpu_cv_mean_watts": 5.621, "power_sys_5v0_mean_watts": 7.924, "gpu_utilization_percent_mean": 69.776}, "timestamp": "2026-01-30T10:16:37.233156"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4278.67, "latencies_ms": [4278.67], "images_per_second": 0.234, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image features a street with a clear blue sky and a few clouds. The buildings are made of brick and concrete, and the road is paved with asphalt.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15414.1, "ram_available_mb": 47426.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 20.1, "ram_used_mb": 15464.3, "ram_available_mb": 47376.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.833}, "power_stats": {"power_gpu_soc_mean_watts": 20.951, "power_cpu_cv_mean_watts": 4.295, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 75.833}, "timestamp": "2026-01-30T10:16:43.528977"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4472.74, "latencies_ms": [4472.74], "images_per_second": 0.224, "prompt_tokens": 1100, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, there are two people standing close to each other, with one person wearing a blue shirt and the other wearing a white shirt, both smiling and embracing each other.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15464.3, "ram_available_mb": 47376.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.3, "ram_used_mb": 15486.9, "ram_available_mb": 47354.0, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.622, "power_cpu_cv_mean_watts": 3.67, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 75.054}, "timestamp": "2026-01-30T10:16:50.014802"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5780.806, "latencies_ms": [5780.806], "images_per_second": 0.173, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 2\n2. tie: 1\n3. television: 1\n4. wall: 1\n5. chair: 1\n6. table: 1\n7. wall clock: 1\n8. picture: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15486.9, "ram_available_mb": 47354.0, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 15506.1, "ram_available_mb": 47334.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.625}, "power_stats": {"power_gpu_soc_mean_watts": 19.157, "power_cpu_cv_mean_watts": 2.37, "power_sys_5v0_mean_watts": 7.896, "gpu_utilization_percent_mean": 73.625}, "timestamp": "2026-01-30T10:16:57.820296"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4636.905, "latencies_ms": [4636.905], "images_per_second": 0.216, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The woman is standing to the right of the man, with her arm around his shoulder. The man is standing in front of a bar counter, with the woman standing behind him.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15506.1, "ram_available_mb": 47334.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 15516.3, "ram_available_mb": 47324.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.184}, "power_stats": {"power_gpu_soc_mean_watts": 20.352, "power_cpu_cv_mean_watts": 2.119, "power_sys_5v0_mean_watts": 7.902, "gpu_utilization_percent_mean": 75.184}, "timestamp": "2026-01-30T10:17:04.469842"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2834.558, "latencies_ms": [2834.558], "images_per_second": 0.353, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " Two people are posing for a picture in a bar.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15516.3, "ram_available_mb": 47324.6, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 15530.9, "ram_available_mb": 47310.0, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.043}, "power_stats": {"power_gpu_soc_mean_watts": 24.119, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.257, "gpu_utilization_percent_mean": 82.043}, "timestamp": "2026-01-30T10:17:09.348278"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3831.644, "latencies_ms": [3831.644], "images_per_second": 0.261, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm ambiance, and the subjects are wearing formal attire.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15530.9, "ram_available_mb": 47310.0, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 15546.1, "ram_available_mb": 47294.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.781}, "power_stats": {"power_gpu_soc_mean_watts": 21.578, "power_cpu_cv_mean_watts": 1.99, "power_sys_5v0_mean_watts": 7.96, "gpu_utilization_percent_mean": 77.781}, "timestamp": "2026-01-30T10:17:15.199097"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3439.037, "latencies_ms": [3439.037], "images_per_second": 0.291, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman in a costume is smiling at the camera while standing in a crowd of people.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 15546.1, "ram_available_mb": 47294.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 15546.6, "ram_available_mb": 47294.3, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.16, "power_cpu_cv_mean_watts": 1.473, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 81.714}, "timestamp": "2026-01-30T10:17:20.676568"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5955.162, "latencies_ms": [5955.162], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. hat: 1\n3. headband: 1\n4. earring: 1\n5. necklace: 1\n6. bracelet: 1\n7. shirt: 1\n8. pants: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15546.6, "ram_available_mb": 47294.3, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.4, "ram_used_mb": 15552.8, "ram_available_mb": 47288.1, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.28}, "power_stats": {"power_gpu_soc_mean_watts": 18.586, "power_cpu_cv_mean_watts": 2.059, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 72.28}, "timestamp": "2026-01-30T10:17:28.684634"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4751.979, "latencies_ms": [4751.979], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The woman is in the foreground, wearing a black and gold costume, while the man is in the background, wearing a white hat. The woman is closer to the camera than the man.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15552.8, "ram_available_mb": 47288.1, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 15559.0, "ram_available_mb": 47281.9, "ram_percent": 24.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.775}, "power_stats": {"power_gpu_soc_mean_watts": 19.724, "power_cpu_cv_mean_watts": 2.503, "power_sys_5v0_mean_watts": 7.887, "gpu_utilization_percent_mean": 74.775}, "timestamp": "2026-01-30T10:17:35.463002"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3512.19, "latencies_ms": [3512.19], "images_per_second": 0.285, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered in an outdoor setting, dressed in elaborate costumes and engaging in conversation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15559.0, "ram_available_mb": 47281.9, "ram_percent": 24.8}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 15560.4, "ram_available_mb": 47280.5, "ram_percent": 24.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.345}, "power_stats": {"power_gpu_soc_mean_watts": 22.401, "power_cpu_cv_mean_watts": 1.436, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 74.345}, "timestamp": "2026-01-30T10:17:41.005649"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3606.713, "latencies_ms": [3606.713], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting, and the woman is wearing a black and gold costume.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15560.4, "ram_available_mb": 47280.5, "ram_percent": 24.8}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 15561.4, "ram_available_mb": 47279.5, "ram_percent": 24.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.121, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 79.1}, "timestamp": "2026-01-30T10:17:46.645326"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6624.027, "latencies_ms": [6624.027], "images_per_second": 0.151, "prompt_tokens": 1100, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image depicts a small bathroom with white tiled walls and floor, a white toilet, a white sink, a white shower head, a white pipe, a white toilet tank, a white toilet paper holder, a green bucket, a red bucket, a white soap dish, a white soap dispenser, a white window, and a white drain.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 15561.4, "ram_available_mb": 47279.5, "ram_percent": 24.8}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 15560.4, "ram_available_mb": 47280.5, "ram_percent": 24.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.589}, "power_stats": {"power_gpu_soc_mean_watts": 17.493, "power_cpu_cv_mean_watts": 2.131, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 70.589}, "timestamp": "2026-01-30T10:17:55.309363"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5068.477, "latencies_ms": [5068.477], "images_per_second": 0.197, "prompt_tokens": 1114, "response_tokens_est": 43, "n_tiles": 1, "output_text": " 1. white toilet\n2. white sink\n3. white bathtub\n4. white shower head\n5. white pipe\n6. white toilet tank\n7. white toilet paper\n8. white soap", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15560.4, "ram_available_mb": 47280.5, "ram_percent": 24.8}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 15560.2, "ram_available_mb": 47280.7, "ram_percent": 24.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.69}, "power_stats": {"power_gpu_soc_mean_watts": 19.385, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 73.69}, "timestamp": "2026-01-30T10:18:02.430533"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6184.009, "latencies_ms": [6184.009], "images_per_second": 0.162, "prompt_tokens": 1118, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The green bucket is located in the foreground, near the sink, while the red bucket is positioned in the background, near the toilet. The white pipe is situated in the middle of the image, with the shower head on the left side and the toilet on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15560.2, "ram_available_mb": 47280.7, "ram_percent": 24.8}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15627.3, "ram_available_mb": 47213.6, "ram_percent": 24.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.706}, "power_stats": {"power_gpu_soc_mean_watts": 18.347, "power_cpu_cv_mean_watts": 2.482, "power_sys_5v0_mean_watts": 7.59, "gpu_utilization_percent_mean": 78.706}, "timestamp": "2026-01-30T10:18:10.635423"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5814.108, "latencies_ms": [5814.108], "images_per_second": 0.172, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A small bathroom with white walls and a white floor has a shower, a toilet, and a sink.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15627.3, "ram_available_mb": 47213.6, "ram_percent": 24.9}, "sys_after": {"cpu_percent": 14.7, "ram_used_mb": 15359.5, "ram_available_mb": 47481.4, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.812}, "power_stats": {"power_gpu_soc_mean_watts": 17.638, "power_cpu_cv_mean_watts": 2.111, "power_sys_5v0_mean_watts": 6.623, "gpu_utilization_percent_mean": 96.812}, "timestamp": "2026-01-30T10:18:18.477777"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3183.975, "latencies_ms": [3183.975], "images_per_second": 0.314, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bathroom is white with a blue and green bucket, and a window with a black frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15359.5, "ram_available_mb": 47481.4, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 15362.3, "ram_available_mb": 47478.6, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.885}, "power_stats": {"power_gpu_soc_mean_watts": 23.813, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 7.953, "gpu_utilization_percent_mean": 75.885}, "timestamp": "2026-01-30T10:18:23.692291"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6905.372, "latencies_ms": [6905.372], "images_per_second": 0.145, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man wearing glasses and a green shirt is standing next to a large gray elephant in a natural setting with trees in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15362.3, "ram_available_mb": 47478.6, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 13.8, "ram_used_mb": 15357.1, "ram_available_mb": 47483.8, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.534}, "power_stats": {"power_gpu_soc_mean_watts": 16.55, "power_cpu_cv_mean_watts": 2.803, "power_sys_5v0_mean_watts": 6.407, "gpu_utilization_percent_mean": 97.534}, "timestamp": "2026-01-30T10:18:32.635332"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4541.245, "latencies_ms": [4541.245], "images_per_second": 0.22, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " elephant: 1, man: 1, glasses: 1, shirt: 1, elephant's trunk: 1, elephant's ear: 1, elephant's eye: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15357.1, "ram_available_mb": 47483.8, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 15357.2, "ram_available_mb": 47483.7, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.263}, "power_stats": {"power_gpu_soc_mean_watts": 21.027, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 7.839, "gpu_utilization_percent_mean": 74.263}, "timestamp": "2026-01-30T10:18:39.190456"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7930.602, "latencies_ms": [7930.602], "images_per_second": 0.126, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The man is standing to the right of the elephant, with the elephant's trunk reaching towards his face. The man is in the foreground, while the elephant is in the background.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15357.2, "ram_available_mb": 47483.7, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 12.9, "ram_used_mb": 15358.0, "ram_available_mb": 47482.9, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.227}, "power_stats": {"power_gpu_soc_mean_watts": 16.134, "power_cpu_cv_mean_watts": 2.694, "power_sys_5v0_mean_watts": 6.41, "gpu_utilization_percent_mean": 97.227}, "timestamp": "2026-01-30T10:18:49.142105"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3279.909, "latencies_ms": [3279.909], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing glasses is standing next to an elephant in a natural setting with trees in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15358.0, "ram_available_mb": 47482.9, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15357.8, "ram_available_mb": 47483.1, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.889}, "power_stats": {"power_gpu_soc_mean_watts": 23.006, "power_cpu_cv_mean_watts": 1.112, "power_sys_5v0_mean_watts": 7.89, "gpu_utilization_percent_mean": 72.889}, "timestamp": "2026-01-30T10:18:54.461754"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9014.41, "latencies_ms": [9014.41], "images_per_second": 0.111, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a man wearing glasses and a green shirt standing next to a large elephant. The elephant is gray and has wrinkled skin, while the man's shirt is a solid color. The background is a lush green forest with trees and hills visible.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 15356.8, "ram_available_mb": 47484.1, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15356.9, "ram_available_mb": 47483.9, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.211}, "power_stats": {"power_gpu_soc_mean_watts": 15.91, "power_cpu_cv_mean_watts": 2.914, "power_sys_5v0_mean_watts": 6.433, "gpu_utilization_percent_mean": 94.211}, "timestamp": "2026-01-30T10:19:05.500258"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4034.175, "latencies_ms": [4034.175], "images_per_second": 0.248, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Five children are sitting on the grass holding frisbees, with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 15356.9, "ram_available_mb": 47483.9, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 15356.9, "ram_available_mb": 47484.0, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.242}, "power_stats": {"power_gpu_soc_mean_watts": 21.022, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 7.413, "gpu_utilization_percent_mean": 95.242}, "timestamp": "2026-01-30T10:19:11.562883"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5001.891, "latencies_ms": [5001.891], "images_per_second": 0.2, "prompt_tokens": 1113, "response_tokens_est": 7, "n_tiles": 1, "output_text": " 1. boy: 5", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15356.9, "ram_available_mb": 47484.0, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 15356.1, "ram_available_mb": 47484.8, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.732}, "power_stats": {"power_gpu_soc_mean_watts": 17.875, "power_cpu_cv_mean_watts": 1.963, "power_sys_5v0_mean_watts": 6.417, "gpu_utilization_percent_mean": 96.732}, "timestamp": "2026-01-30T10:19:18.580738"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7027.054, "latencies_ms": [7027.054], "images_per_second": 0.142, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The frisbees are positioned in the foreground, with the child on the left holding a white frisbee and the child on the right holding a red frisbee. The children are sitting on the grass, with the child on the left being closest to the camera and the child on the right being farthest from the camera.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15356.1, "ram_available_mb": 47484.8, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 14.7, "ram_used_mb": 15370.6, "ram_available_mb": 47470.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.763}, "power_stats": {"power_gpu_soc_mean_watts": 18.293, "power_cpu_cv_mean_watts": 2.64, "power_sys_5v0_mean_watts": 7.47, "gpu_utilization_percent_mean": 81.763}, "timestamp": "2026-01-30T10:19:27.665400"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4968.517, "latencies_ms": [4968.517], "images_per_second": 0.201, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " Five children are sitting on the grass playing with frisbees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15370.6, "ram_available_mb": 47470.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 15382.7, "ram_available_mb": 47458.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.366}, "power_stats": {"power_gpu_soc_mean_watts": 18.669, "power_cpu_cv_mean_watts": 2.188, "power_sys_5v0_mean_watts": 6.717, "gpu_utilization_percent_mean": 95.366}, "timestamp": "2026-01-30T10:19:34.678225"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4292.233, "latencies_ms": [4292.233], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image is taken in a bright and sunny day with clear sky. The children are sitting on the grass, which is green and lush.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15382.7, "ram_available_mb": 47458.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.6, "ram_used_mb": 15379.7, "ram_available_mb": 47461.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.963, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.546, "gpu_utilization_percent_mean": 81.0}, "timestamp": "2026-01-30T10:19:40.992362"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6458.349, "latencies_ms": [6458.349], "images_per_second": 0.155, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young girl wearing a red coat and holding a black umbrella with pink designs stands on a wet sidewalk in front of a bush.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15379.7, "ram_available_mb": 47461.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 15377.6, "ram_available_mb": 47463.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.815}, "power_stats": {"power_gpu_soc_mean_watts": 16.909, "power_cpu_cv_mean_watts": 2.677, "power_sys_5v0_mean_watts": 6.406, "gpu_utilization_percent_mean": 89.815}, "timestamp": "2026-01-30T10:19:49.497740"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4816.287, "latencies_ms": [4816.287], "images_per_second": 0.208, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " umbrella: 1, child: 1, sidewalk: 1, house: 1, bush: 1, car: 1, tree: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15377.6, "ram_available_mb": 47463.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 15379.7, "ram_available_mb": 47461.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.385}, "power_stats": {"power_gpu_soc_mean_watts": 20.352, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 7.41, "gpu_utilization_percent_mean": 84.385}, "timestamp": "2026-01-30T10:19:56.339380"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7689.014, "latencies_ms": [7689.014], "images_per_second": 0.13, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The child is standing in the foreground of the image, with the umbrella held above her head. The umbrella is positioned to the left of the child, and the background features a hedge and a house.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15379.7, "ram_available_mb": 47461.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 15378.1, "ram_available_mb": 47462.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.922}, "power_stats": {"power_gpu_soc_mean_watts": 16.496, "power_cpu_cv_mean_watts": 2.459, "power_sys_5v0_mean_watts": 6.443, "gpu_utilization_percent_mean": 88.922}, "timestamp": "2026-01-30T10:20:06.081422"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4169.761, "latencies_ms": [4169.761], "images_per_second": 0.24, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A little girl is standing on the sidewalk with an umbrella.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15378.1, "ram_available_mb": 47462.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 15379.5, "ram_available_mb": 47461.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.152}, "power_stats": {"power_gpu_soc_mean_watts": 19.783, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 6.986, "gpu_utilization_percent_mean": 95.152}, "timestamp": "2026-01-30T10:20:12.269821"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6928.68, "latencies_ms": [6928.68], "images_per_second": 0.144, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a young girl wearing a red coat and holding a black umbrella with pink patterns. The scene is set on a rainy day with wet pavement and a gray sky.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15379.5, "ram_available_mb": 47461.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 15378.7, "ram_available_mb": 47462.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.207}, "power_stats": {"power_gpu_soc_mean_watts": 16.993, "power_cpu_cv_mean_watts": 2.506, "power_sys_5v0_mean_watts": 6.52, "gpu_utilization_percent_mean": 89.207}, "timestamp": "2026-01-30T10:20:21.249727"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7190.978, "latencies_ms": [7190.978], "images_per_second": 0.139, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In the image, a group of elephants is seen walking through a muddy area, with one elephant in the foreground prominently displayed and the others slightly blurred in the background, creating a sense of depth and movement.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 15378.7, "ram_available_mb": 47462.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 15380.4, "ram_available_mb": 47460.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.593}, "power_stats": {"power_gpu_soc_mean_watts": 16.623, "power_cpu_cv_mean_watts": 2.274, "power_sys_5v0_mean_watts": 6.613, "gpu_utilization_percent_mean": 94.593}, "timestamp": "2026-01-30T10:20:30.465821"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4166.088, "latencies_ms": [4166.088], "images_per_second": 0.24, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " elephant: 1, trunk: 1, ear: 1, eye: 1, leg: 1, tail: 1, water: 1", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 15380.4, "ram_available_mb": 47460.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 15381.4, "ram_available_mb": 47459.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.118}, "power_stats": {"power_gpu_soc_mean_watts": 20.919, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 73.118}, "timestamp": "2026-01-30T10:20:36.665223"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7116.101, "latencies_ms": [7116.101], "images_per_second": 0.141, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The main elephant is in the foreground, with the other elephants in the background. The elephants are walking towards the camera, with the main elephant in the center of the frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15381.4, "ram_available_mb": 47459.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15381.7, "ram_available_mb": 47459.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.233}, "power_stats": {"power_gpu_soc_mean_watts": 16.559, "power_cpu_cv_mean_watts": 2.71, "power_sys_5v0_mean_watts": 6.476, "gpu_utilization_percent_mean": 96.233}, "timestamp": "2026-01-30T10:20:45.812042"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4052.176, "latencies_ms": [4052.176], "images_per_second": 0.247, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of elephants are walking through a muddy area near a body of water.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15381.7, "ram_available_mb": 47459.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 15382.1, "ram_available_mb": 47458.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.091}, "power_stats": {"power_gpu_soc_mean_watts": 20.814, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 7.112, "gpu_utilization_percent_mean": 86.091}, "timestamp": "2026-01-30T10:20:51.878985"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7014.457, "latencies_ms": [7014.457], "images_per_second": 0.143, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The elephants are in a muddy environment, with a mix of brown and red tones. The lighting is natural, and the elephants are in a natural setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15382.1, "ram_available_mb": 47458.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15382.1, "ram_available_mb": 47458.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.254}, "power_stats": {"power_gpu_soc_mean_watts": 16.398, "power_cpu_cv_mean_watts": 2.565, "power_sys_5v0_mean_watts": 6.43, "gpu_utilization_percent_mean": 96.254}, "timestamp": "2026-01-30T10:21:00.918390"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3847.277, "latencies_ms": [3847.277], "images_per_second": 0.26, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 22.6, "ram_used_mb": 15382.1, "ram_available_mb": 47458.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 15382.8, "ram_available_mb": 47458.1, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.656}, "power_stats": {"power_gpu_soc_mean_watts": 25.955, "power_cpu_cv_mean_watts": 1.351, "power_sys_5v0_mean_watts": 8.242, "gpu_utilization_percent_mean": 83.656}, "timestamp": "2026-01-30T10:21:06.793903"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11365.932, "latencies_ms": [11365.932], "images_per_second": 0.088, "prompt_tokens": 1446, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. surfer: 1\n2. wave: 1\n3. surfboard: 1\n4. water: 1\n5. sky: 0\n6. surfboard deck: 1\n7. surfboard leash: 1\n8. logo: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15382.8, "ram_available_mb": 47458.1, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15383.5, "ram_available_mb": 47457.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.229}, "power_stats": {"power_gpu_soc_mean_watts": 16.248, "power_cpu_cv_mean_watts": 2.932, "power_sys_5v0_mean_watts": 6.477, "gpu_utilization_percent_mean": 95.229}, "timestamp": "2026-01-30T10:21:20.187146"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7891.842, "latencies_ms": [7891.842], "images_per_second": 0.127, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, with the wave dominating the background. The surfer is leaning into the wave, with the surfboard positioned in the lower right corner of the image, close to the surfer.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15383.5, "ram_available_mb": 47457.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 15381.9, "ram_available_mb": 47459.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.53}, "power_stats": {"power_gpu_soc_mean_watts": 18.725, "power_cpu_cv_mean_watts": 2.457, "power_sys_5v0_mean_watts": 7.083, "gpu_utilization_percent_mean": 96.53}, "timestamp": "2026-01-30T10:21:30.109946"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4859.906, "latencies_ms": [4859.906], "images_per_second": 0.206, "prompt_tokens": 1444, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15381.9, "ram_available_mb": 47459.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 15382.7, "ram_available_mb": 47458.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.375}, "power_stats": {"power_gpu_soc_mean_watts": 21.764, "power_cpu_cv_mean_watts": 1.681, "power_sys_5v0_mean_watts": 7.209, "gpu_utilization_percent_mean": 91.375}, "timestamp": "2026-01-30T10:21:37.002557"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8187.809, "latencies_ms": [8187.809], "images_per_second": 0.122, "prompt_tokens": 1442, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The surfer is wearing a red and green wetsuit, and the wave is a deep green color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15382.7, "ram_available_mb": 47458.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15383.0, "ram_available_mb": 47457.9, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.333}, "power_stats": {"power_gpu_soc_mean_watts": 16.61, "power_cpu_cv_mean_watts": 2.344, "power_sys_5v0_mean_watts": 6.306, "gpu_utilization_percent_mean": 95.333}, "timestamp": "2026-01-30T10:21:47.225374"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3580.093, "latencies_ms": [3580.093], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two men on horseback are riding on a beach, with the ocean and a few people in the background.", "error": null, "sys_before": {"cpu_percent": 21.1, "ram_used_mb": 15383.0, "ram_available_mb": 47457.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 15382.3, "ram_available_mb": 47458.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.2}, "power_stats": {"power_gpu_soc_mean_watts": 22.773, "power_cpu_cv_mean_watts": 1.375, "power_sys_5v0_mean_watts": 7.691, "gpu_utilization_percent_mean": 77.2}, "timestamp": "2026-01-30T10:21:52.855869"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9719.663, "latencies_ms": [9719.663], "images_per_second": 0.103, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 2\n2. rider: 2\n3. rider: 1\n4. rider: 1\n5. rider: 1\n6. rider: 1\n7. rider: 1\n8. rider: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15382.3, "ram_available_mb": 47458.6, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.0, "ram_used_mb": 15383.4, "ram_available_mb": 47457.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.671}, "power_stats": {"power_gpu_soc_mean_watts": 15.696, "power_cpu_cv_mean_watts": 2.998, "power_sys_5v0_mean_watts": 6.377, "gpu_utilization_percent_mean": 97.671}, "timestamp": "2026-01-30T10:22:04.604599"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7298.19, "latencies_ms": [7298.19], "images_per_second": 0.137, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The two men on horseback are positioned in the foreground, with the ocean and beach extending into the background. The man on the left is closer to the camera, while the man on the right is farther away. The man on the left is also closer to the camera than the man on the right.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15383.4, "ram_available_mb": 47457.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.3, "ram_used_mb": 15384.4, "ram_available_mb": 47456.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 90.557}, "power_stats": {"power_gpu_soc_mean_watts": 17.955, "power_cpu_cv_mean_watts": 2.514, "power_sys_5v0_mean_watts": 7.074, "gpu_utilization_percent_mean": 90.557}, "timestamp": "2026-01-30T10:22:13.937748"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4409.922, "latencies_ms": [4409.922], "images_per_second": 0.227, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two men on horseback are riding on a beach, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15384.4, "ram_available_mb": 47456.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 15385.4, "ram_available_mb": 47455.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.108}, "power_stats": {"power_gpu_soc_mean_watts": 19.841, "power_cpu_cv_mean_watts": 2.024, "power_sys_5v0_mean_watts": 6.918, "gpu_utilization_percent_mean": 84.108}, "timestamp": "2026-01-30T10:22:20.398294"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5692.621, "latencies_ms": [5692.621], "images_per_second": 0.176, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a sandy beach with a clear blue sky and ocean in the background. The two men are dressed in white traditional clothing and are riding horses, which are kicking up dust as they move.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15385.4, "ram_available_mb": 47455.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 15385.9, "ram_available_mb": 47455.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.976, "power_cpu_cv_mean_watts": 2.096, "power_sys_5v0_mean_watts": 7.154, "gpu_utilization_percent_mean": 95.021}, "timestamp": "2026-01-30T10:22:28.102759"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4936.426, "latencies_ms": [4936.426], "images_per_second": 0.203, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A small dog is standing in front of a motorcycle that is parked in a driveway.", "error": null, "sys_before": {"cpu_percent": 20.8, "ram_used_mb": 15385.9, "ram_available_mb": 47455.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15387.1, "ram_available_mb": 47453.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.024}, "power_stats": {"power_gpu_soc_mean_watts": 18.735, "power_cpu_cv_mean_watts": 2.207, "power_sys_5v0_mean_watts": 6.686, "gpu_utilization_percent_mean": 87.024}, "timestamp": "2026-01-30T10:22:35.074510"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7518.78, "latencies_ms": [7518.78], "images_per_second": 0.133, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. motorcycle: 1\n2. dog: 1\n3. tire: 1\n4. handlebar: 1\n5. seat: 1\n6. front wheel: 1\n7. rear wheel: 1\n8. garage door: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15387.1, "ram_available_mb": 47453.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.7, "ram_used_mb": 15385.7, "ram_available_mb": 47455.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 93.016}, "power_stats": {"power_gpu_soc_mean_watts": 17.667, "power_cpu_cv_mean_watts": 2.504, "power_sys_5v0_mean_watts": 6.988, "gpu_utilization_percent_mean": 93.016}, "timestamp": "2026-01-30T10:22:44.640674"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6037.022, "latencies_ms": [6037.022], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The motorcycle is positioned to the left of the garage door, with the dog standing in front of it. The motorcycle is in the foreground, while the garage door is in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 15385.7, "ram_available_mb": 47455.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 15383.9, "ram_available_mb": 47457.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.4}, "power_stats": {"power_gpu_soc_mean_watts": 17.702, "power_cpu_cv_mean_watts": 2.122, "power_sys_5v0_mean_watts": 6.853, "gpu_utilization_percent_mean": 82.4}, "timestamp": "2026-01-30T10:22:52.694862"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5955.397, "latencies_ms": [5955.397], "images_per_second": 0.168, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A motorcycle is parked outside a garage with a dog standing next to it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15383.9, "ram_available_mb": 47457.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.3, "ram_used_mb": 15383.9, "ram_available_mb": 47457.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.06}, "power_stats": {"power_gpu_soc_mean_watts": 16.9, "power_cpu_cv_mean_watts": 2.763, "power_sys_5v0_mean_watts": 6.295, "gpu_utilization_percent_mean": 98.06}, "timestamp": "2026-01-30T10:23:00.676866"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4632.209, "latencies_ms": [4632.209], "images_per_second": 0.216, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The motorcycle is red and silver, and the garage is beige. The sky is blue and the grass is green.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15383.9, "ram_available_mb": 47457.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 15384.3, "ram_available_mb": 47456.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.474}, "power_stats": {"power_gpu_soc_mean_watts": 19.867, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.083, "gpu_utilization_percent_mean": 82.474}, "timestamp": "2026-01-30T10:23:07.340390"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5634.06, "latencies_ms": [5634.06], "images_per_second": 0.177, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is flying a kite on the beach, with a few other people in the background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 15384.3, "ram_available_mb": 47456.6, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 15382.9, "ram_available_mb": 47458.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.404}, "power_stats": {"power_gpu_soc_mean_watts": 17.162, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 6.402, "gpu_utilization_percent_mean": 88.404}, "timestamp": "2026-01-30T10:23:15.045063"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5518.907, "latencies_ms": [5518.907], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. kite: 1\n3. sand: 1\n4. water: 1\n5. trees: 1\n6. buildings: 1\n7. clouds: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15382.9, "ram_available_mb": 47458.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 15383.3, "ram_available_mb": 47457.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.957}, "power_stats": {"power_gpu_soc_mean_watts": 18.543, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.658, "gpu_utilization_percent_mean": 70.957}, "timestamp": "2026-01-30T10:23:22.617258"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8438.643, "latencies_ms": [8438.643], "images_per_second": 0.119, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The man is in the foreground, flying the kite in the middle of the beach. The kite is in the background, flying high in the sky. The beach is in the background, with people and trees.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15383.3, "ram_available_mb": 47457.6, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 14.3, "ram_used_mb": 15384.1, "ram_available_mb": 47456.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.871}, "power_stats": {"power_gpu_soc_mean_watts": 15.984, "power_cpu_cv_mean_watts": 2.111, "power_sys_5v0_mean_watts": 6.346, "gpu_utilization_percent_mean": 97.871}, "timestamp": "2026-01-30T10:23:33.107455"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2930.623, "latencies_ms": [2930.623], "images_per_second": 0.341, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is flying a kite on a beach with a lake in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15384.1, "ram_available_mb": 47456.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 15384.0, "ram_available_mb": 47456.9, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.583}, "power_stats": {"power_gpu_soc_mean_watts": 25.096, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 74.583}, "timestamp": "2026-01-30T10:23:38.086812"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6648.181, "latencies_ms": [6648.181], "images_per_second": 0.15, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The sky is blue and the kite is blue and black. The beach is sandy and the water is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15384.0, "ram_available_mb": 47456.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.9, "ram_used_mb": 15384.5, "ram_available_mb": 47456.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.909}, "power_stats": {"power_gpu_soc_mean_watts": 16.652, "power_cpu_cv_mean_watts": 2.395, "power_sys_5v0_mean_watts": 6.306, "gpu_utilization_percent_mean": 97.909}, "timestamp": "2026-01-30T10:23:46.748263"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5193.947, "latencies_ms": [5193.947], "images_per_second": 0.193, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image depicts a kitchen with wooden cabinets, a stainless steel refrigerator, and a black countertop, with various items such as a green bottle, a red bow, and a blue bottle placed on the countertop.", "error": null, "sys_before": {"cpu_percent": 26.9, "ram_used_mb": 15384.5, "ram_available_mb": 47456.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 15386.4, "ram_available_mb": 47454.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.512}, "power_stats": {"power_gpu_soc_mean_watts": 19.375, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.404, "gpu_utilization_percent_mean": 74.512}, "timestamp": "2026-01-30T10:23:53.987236"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7719.489, "latencies_ms": [7719.489], "images_per_second": 0.13, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " sink: 1, bottle: 2, bowl: 1, cup: 1, dish: 1, bottle: 1, bottle: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15386.4, "ram_available_mb": 47454.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.3, "ram_used_mb": 15386.5, "ram_available_mb": 47454.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.677}, "power_stats": {"power_gpu_soc_mean_watts": 16.305, "power_cpu_cv_mean_watts": 2.859, "power_sys_5v0_mean_watts": 6.359, "gpu_utilization_percent_mean": 96.677}, "timestamp": "2026-01-30T10:24:03.749513"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4885.54, "latencies_ms": [4885.54], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The green dish soap bottle is located near the sink, while the blue dish soap bottle is placed further back on the counter. The red bow is positioned in the foreground, close to the camera.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15386.5, "ram_available_mb": 47454.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 15386.0, "ram_available_mb": 47454.9, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.9}, "power_stats": {"power_gpu_soc_mean_watts": 19.849, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 7.497, "gpu_utilization_percent_mean": 77.9}, "timestamp": "2026-01-30T10:24:10.668532"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6129.131, "latencies_ms": [6129.131], "images_per_second": 0.163, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A kitchen with wooden cabinets, a black countertop, and a stainless steel refrigerator.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15386.0, "ram_available_mb": 47454.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.3, "ram_used_mb": 15387.0, "ram_available_mb": 47453.9, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.863}, "power_stats": {"power_gpu_soc_mean_watts": 17.015, "power_cpu_cv_mean_watts": 2.506, "power_sys_5v0_mean_watts": 6.324, "gpu_utilization_percent_mean": 96.863}, "timestamp": "2026-01-30T10:24:18.843550"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3094.146, "latencies_ms": [3094.146], "images_per_second": 0.323, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15387.0, "ram_available_mb": 47453.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 15388.1, "ram_available_mb": 47452.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.462}, "power_stats": {"power_gpu_soc_mean_watts": 23.725, "power_cpu_cv_mean_watts": 1.093, "power_sys_5v0_mean_watts": 7.908, "gpu_utilization_percent_mean": 74.462}, "timestamp": "2026-01-30T10:24:23.988209"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5766.153, "latencies_ms": [5766.153], "images_per_second": 0.173, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kite with a red and white design is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 18.8, "ram_used_mb": 15388.1, "ram_available_mb": 47452.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.4, "ram_used_mb": 15404.1, "ram_available_mb": 47436.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.265, "power_cpu_cv_mean_watts": 2.378, "power_sys_5v0_mean_watts": 6.35, "gpu_utilization_percent_mean": 98.0}, "timestamp": "2026-01-30T10:24:31.803396"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2761.84, "latencies_ms": [2761.84], "images_per_second": 0.362, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " kite: 1", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 15404.1, "ram_available_mb": 47436.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 15395.9, "ram_available_mb": 47445.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.043}, "power_stats": {"power_gpu_soc_mean_watts": 23.597, "power_cpu_cv_mean_watts": 1.48, "power_sys_5v0_mean_watts": 7.475, "gpu_utilization_percent_mean": 92.043}, "timestamp": "2026-01-30T10:24:36.599327"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8274.848, "latencies_ms": [8274.848], "images_per_second": 0.121, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The kite is in the foreground, flying in the sky, and the background is the clear blue sky. The kite is positioned to the left of the frame, and the strings are attached to the kite, which is the main object in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15395.9, "ram_available_mb": 47445.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15369.9, "ram_available_mb": 47471.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.114}, "power_stats": {"power_gpu_soc_mean_watts": 16.237, "power_cpu_cv_mean_watts": 2.838, "power_sys_5v0_mean_watts": 6.538, "gpu_utilization_percent_mean": 96.114}, "timestamp": "2026-01-30T10:24:46.911317"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2809.699, "latencies_ms": [2809.699], "images_per_second": 0.356, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kite with a red and white design is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15369.9, "ram_available_mb": 47471.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 15368.7, "ram_available_mb": 47472.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.304}, "power_stats": {"power_gpu_soc_mean_watts": 25.145, "power_cpu_cv_mean_watts": 1.01, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 76.304}, "timestamp": "2026-01-30T10:24:51.746552"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5391.084, "latencies_ms": [5391.084], "images_per_second": 0.185, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The kite is white with red and black patterns, and the sky is clear blue.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15368.7, "ram_available_mb": 47472.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.9, "ram_used_mb": 15368.1, "ram_available_mb": 47472.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.267}, "power_stats": {"power_gpu_soc_mean_watts": 17.451, "power_cpu_cv_mean_watts": 2.029, "power_sys_5v0_mean_watts": 6.467, "gpu_utilization_percent_mean": 95.267}, "timestamp": "2026-01-30T10:24:59.160951"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7020.738, "latencies_ms": [7020.738], "images_per_second": 0.142, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image depicts a spacious hotel room with two queen-sized beds, each adorned with white linens and a dark-colored bedspread, positioned side by side, with a window in the background allowing natural light to filter into the room.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15368.1, "ram_available_mb": 47472.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 15367.7, "ram_available_mb": 47473.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.102}, "power_stats": {"power_gpu_soc_mean_watts": 16.579, "power_cpu_cv_mean_watts": 2.335, "power_sys_5v0_mean_watts": 6.762, "gpu_utilization_percent_mean": 80.102}, "timestamp": "2026-01-30T10:25:08.253488"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9274.352, "latencies_ms": [9274.352], "images_per_second": 0.108, "prompt_tokens": 1113, "response_tokens_est": 55, "n_tiles": 1, "output_text": " 1. beds: 2\n2. pillows: 12\n3. lamps: 2\n4. paintings: 2\n5. window: 1\n6. door: 1\n7. floor: wooden\n8. ceiling: white", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15367.7, "ram_available_mb": 47473.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 15368.5, "ram_available_mb": 47472.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.269}, "power_stats": {"power_gpu_soc_mean_watts": 15.845, "power_cpu_cv_mean_watts": 2.86, "power_sys_5v0_mean_watts": 6.393, "gpu_utilization_percent_mean": 92.269}, "timestamp": "2026-01-30T10:25:19.549315"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8023.242, "latencies_ms": [8023.242], "images_per_second": 0.125, "prompt_tokens": 1117, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The beds are positioned on the left side of the room, with the window and door located on the right side. The lamp on the left bedside table is positioned closer to the camera than the lamp on the right bedside table. The artwork is positioned above the beds, with the window and door being further away from the beds.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15368.5, "ram_available_mb": 47472.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.7, "ram_used_mb": 15370.6, "ram_available_mb": 47470.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.576}, "power_stats": {"power_gpu_soc_mean_watts": 17.495, "power_cpu_cv_mean_watts": 2.5, "power_sys_5v0_mean_watts": 7.039, "gpu_utilization_percent_mean": 91.576}, "timestamp": "2026-01-30T10:25:29.600915"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7631.481, "latencies_ms": [7631.481], "images_per_second": 0.131, "prompt_tokens": 1111, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a serene hotel room bathed in soft light, where two queen-sized beds rest against a wall adorned with a vibrant abstract painting. The room exudes a sense of tranquility, with each bed neatly made and a lamp perched on the nightstand, ready to bathe the room in a warm glow.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15370.6, "ram_available_mb": 47470.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.2, "ram_used_mb": 15371.2, "ram_available_mb": 47469.7, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.359}, "power_stats": {"power_gpu_soc_mean_watts": 16.302, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 6.937, "gpu_utilization_percent_mean": 77.359}, "timestamp": "2026-01-30T10:25:39.271840"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7893.005, "latencies_ms": [7893.005], "images_per_second": 0.127, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The room is bathed in warm light, with a mix of natural and artificial light illuminating the space. The walls are painted in a soothing shade of green, and the wooden floor adds a touch of rustic charm.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15371.2, "ram_available_mb": 47469.7, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.9, "ram_used_mb": 15371.5, "ram_available_mb": 47469.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.031}, "power_stats": {"power_gpu_soc_mean_watts": 16.692, "power_cpu_cv_mean_watts": 2.162, "power_sys_5v0_mean_watts": 6.541, "gpu_utilization_percent_mean": 97.031}, "timestamp": "2026-01-30T10:25:49.185292"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4469.083, "latencies_ms": [4469.083], "images_per_second": 0.224, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a white helmet and a white and green racing suit is riding a white motorcycle on a road with a crowd of people watching from behind a fence.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 15371.5, "ram_available_mb": 47469.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.638, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 7.529, "gpu_utilization_percent_mean": 80.639}, "timestamp": "2026-01-30T10:25:55.686313"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4784.962, "latencies_ms": [4784.962], "images_per_second": 0.209, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. motorcycle: 1\n2. rider: 1\n3. helmet: 1\n4. fence: 2\n5. people: 8", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 15370.9, "ram_available_mb": 47470.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.55}, "power_stats": {"power_gpu_soc_mean_watts": 20.057, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 7.375, "gpu_utilization_percent_mean": 74.55}, "timestamp": "2026-01-30T10:26:02.499237"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4705.827, "latencies_ms": [4705.827], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The motorcycle is positioned on the left side of the image, with the rider leaning into a turn. The spectators are located in the background, on the right side of the image, and are positioned behind a fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15370.9, "ram_available_mb": 47470.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 15369.2, "ram_available_mb": 47471.7, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.974}, "power_stats": {"power_gpu_soc_mean_watts": 19.596, "power_cpu_cv_mean_watts": 1.489, "power_sys_5v0_mean_watts": 7.619, "gpu_utilization_percent_mean": 67.974}, "timestamp": "2026-01-30T10:26:09.232215"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7549.968, "latencies_ms": [7549.968], "images_per_second": 0.132, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a white helmet and a white and green racing suit is riding a white motorcycle on a road. There are people standing behind a fence watching him.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15369.2, "ram_available_mb": 47471.7, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.3, "ram_used_mb": 15369.3, "ram_available_mb": 47471.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.778}, "power_stats": {"power_gpu_soc_mean_watts": 16.336, "power_cpu_cv_mean_watts": 2.683, "power_sys_5v0_mean_watts": 6.334, "gpu_utilization_percent_mean": 96.778}, "timestamp": "2026-01-30T10:26:18.841052"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2908.913, "latencies_ms": [2908.913], "images_per_second": 0.344, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The motorcycle is white and green, and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15369.3, "ram_available_mb": 47471.6, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 15369.3, "ram_available_mb": 47471.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.164, "power_cpu_cv_mean_watts": 0.984, "power_sys_5v0_mean_watts": 7.879, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T10:26:23.809091"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6405.309, "latencies_ms": [6405.309], "images_per_second": 0.156, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A table set with a vase of white flowers and wine glasses is illuminated by a soft light.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 15369.3, "ram_available_mb": 47471.6, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.0, "ram_used_mb": 15371.7, "ram_available_mb": 47469.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.981}, "power_stats": {"power_gpu_soc_mean_watts": 16.824, "power_cpu_cv_mean_watts": 2.501, "power_sys_5v0_mean_watts": 6.306, "gpu_utilization_percent_mean": 97.981}, "timestamp": "2026-01-30T10:26:32.239400"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4262.185, "latencies_ms": [4262.185], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " table: 1\nflowers: 1\nglass: 4\nwine glass: 2\nspoon: 1\nplate: 1\ncloth: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15371.7, "ram_available_mb": 47469.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 15372.8, "ram_available_mb": 47468.1, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.68, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 7.689, "gpu_utilization_percent_mean": 69.8}, "timestamp": "2026-01-30T10:26:38.528386"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8143.981, "latencies_ms": [8143.981], "images_per_second": 0.123, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The vase with flowers is placed in the center of the table, with the glasses arranged around it. The table is set against a dark background, with the lights reflecting off the glassware.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15372.8, "ram_available_mb": 47468.1, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.5, "ram_used_mb": 15371.0, "ram_available_mb": 47469.9, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.162}, "power_stats": {"power_gpu_soc_mean_watts": 16.091, "power_cpu_cv_mean_watts": 2.627, "power_sys_5v0_mean_watts": 6.349, "gpu_utilization_percent_mean": 97.162}, "timestamp": "2026-01-30T10:26:48.702298"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3145.751, "latencies_ms": [3145.751], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A table set for a dinner party with a centerpiece of white flowers and wine glasses.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15371.0, "ram_available_mb": 47469.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.779, "power_cpu_cv_mean_watts": 1.009, "power_sys_5v0_mean_watts": 7.882, "gpu_utilization_percent_mean": 77.56}, "timestamp": "2026-01-30T10:26:53.868054"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7340.238, "latencies_ms": [7340.238], "images_per_second": 0.136, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The table is covered with a white tablecloth, and the glasses are clear. The lighting is dim, and the table is set for a formal dinner.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.5, "ram_used_mb": 15371.4, "ram_available_mb": 47469.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.839}, "power_stats": {"power_gpu_soc_mean_watts": 16.537, "power_cpu_cv_mean_watts": 2.681, "power_sys_5v0_mean_watts": 6.374, "gpu_utilization_percent_mean": 97.839}, "timestamp": "2026-01-30T10:27:03.246576"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3731.915, "latencies_ms": [3731.915], "images_per_second": 0.268, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a clock on a pole with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15371.4, "ram_available_mb": 47469.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 15372.1, "ram_available_mb": 47468.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.065}, "power_stats": {"power_gpu_soc_mean_watts": 25.675, "power_cpu_cv_mean_watts": 1.137, "power_sys_5v0_mean_watts": 8.248, "gpu_utilization_percent_mean": 75.065}, "timestamp": "2026-01-30T10:27:09.033685"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8686.457, "latencies_ms": [8686.457], "images_per_second": 0.115, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. clock: 2\n2. pole: 1\n3. sky: 1\n4. clouds: 1\n5. bird: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15372.1, "ram_available_mb": 47468.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 15372.6, "ram_available_mb": 47468.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.589}, "power_stats": {"power_gpu_soc_mean_watts": 17.225, "power_cpu_cv_mean_watts": 2.474, "power_sys_5v0_mean_watts": 6.481, "gpu_utilization_percent_mean": 91.589}, "timestamp": "2026-01-30T10:27:19.731771"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6387.633, "latencies_ms": [6387.633], "images_per_second": 0.157, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The clock is positioned in the center of the image, with the pole extending upwards and the sky in the background. The clock is relatively close to the camera, while the sky is farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15372.6, "ram_available_mb": 47468.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 15373.3, "ram_available_mb": 47467.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 93.385}, "power_stats": {"power_gpu_soc_mean_watts": 20.598, "power_cpu_cv_mean_watts": 1.617, "power_sys_5v0_mean_watts": 7.432, "gpu_utilization_percent_mean": 93.385}, "timestamp": "2026-01-30T10:27:28.151257"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6437.095, "latencies_ms": [6437.095], "images_per_second": 0.155, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a clock on a pole with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15373.0, "ram_available_mb": 47467.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 15372.7, "ram_available_mb": 47468.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.352}, "power_stats": {"power_gpu_soc_mean_watts": 18.899, "power_cpu_cv_mean_watts": 1.921, "power_sys_5v0_mean_watts": 6.717, "gpu_utilization_percent_mean": 89.352}, "timestamp": "2026-01-30T10:27:36.634313"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6733.388, "latencies_ms": [6733.388], "images_per_second": 0.149, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The clock is black and white, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15372.7, "ram_available_mb": 47468.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.607}, "power_stats": {"power_gpu_soc_mean_watts": 17.66, "power_cpu_cv_mean_watts": 1.988, "power_sys_5v0_mean_watts": 6.433, "gpu_utilization_percent_mean": 94.607}, "timestamp": "2026-01-30T10:27:45.407943"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3734.267, "latencies_ms": [3734.267], "images_per_second": 0.268, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a black shirt and a cap is riding a skateboard on a red and gray surface.", "error": null, "sys_before": {"cpu_percent": 23.5, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 15369.8, "ram_available_mb": 47471.1, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.839}, "power_stats": {"power_gpu_soc_mean_watts": 22.288, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 7.582, "gpu_utilization_percent_mean": 81.839}, "timestamp": "2026-01-30T10:27:51.177215"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8116.484, "latencies_ms": [8116.484], "images_per_second": 0.123, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. cap: 1\n4. pants: 1\n5. shoes: 1\n6. trees: 1\n7. ground: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15369.8, "ram_available_mb": 47471.1, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 14.1, "ram_used_mb": 15434.3, "ram_available_mb": 47406.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.449}, "power_stats": {"power_gpu_soc_mean_watts": 16.835, "power_cpu_cv_mean_watts": 2.833, "power_sys_5v0_mean_watts": 6.751, "gpu_utilization_percent_mean": 95.449}, "timestamp": "2026-01-30T10:28:01.331608"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3626.662, "latencies_ms": [3626.662], "images_per_second": 0.276, "prompt_tokens": 1118, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on the skateboard. The background features a park with trees and a building.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15434.3, "ram_available_mb": 47406.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 15434.8, "ram_available_mb": 47406.1, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.267}, "power_stats": {"power_gpu_soc_mean_watts": 23.456, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 72.267}, "timestamp": "2026-01-30T10:28:06.995111"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6703.703, "latencies_ms": [6703.703], "images_per_second": 0.149, "prompt_tokens": 1112, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A young man wearing a black t-shirt and a blue baseball cap is skateboarding on a red and gray concrete surface in a park.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 15434.8, "ram_available_mb": 47406.1, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 13.5, "ram_used_mb": 15436.7, "ram_available_mb": 47404.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.321}, "power_stats": {"power_gpu_soc_mean_watts": 16.451, "power_cpu_cv_mean_watts": 2.374, "power_sys_5v0_mean_watts": 6.386, "gpu_utilization_percent_mean": 95.321}, "timestamp": "2026-01-30T10:28:15.716176"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3997.04, "latencies_ms": [3997.04], "images_per_second": 0.25, "prompt_tokens": 1110, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a red and gray concrete surface, with a backdrop of trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15436.7, "ram_available_mb": 47404.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 15436.3, "ram_available_mb": 47404.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.818}, "power_stats": {"power_gpu_soc_mean_watts": 21.992, "power_cpu_cv_mean_watts": 1.492, "power_sys_5v0_mean_watts": 7.661, "gpu_utilization_percent_mean": 73.818}, "timestamp": "2026-01-30T10:28:21.756505"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5710.98, "latencies_ms": [5710.98], "images_per_second": 0.175, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A white plate filled with orange carrots and green beans is placed on a kitchen counter.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15436.3, "ram_available_mb": 47404.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 15435.7, "ram_available_mb": 47405.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.021}, "power_stats": {"power_gpu_soc_mean_watts": 16.82, "power_cpu_cv_mean_watts": 2.062, "power_sys_5v0_mean_watts": 6.374, "gpu_utilization_percent_mean": 95.021}, "timestamp": "2026-01-30T10:28:29.511796"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6711.4, "latencies_ms": [6711.4], "images_per_second": 0.149, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15435.7, "ram_available_mb": 47405.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 15436.0, "ram_available_mb": 47404.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.554}, "power_stats": {"power_gpu_soc_mean_watts": 16.935, "power_cpu_cv_mean_watts": 2.124, "power_sys_5v0_mean_watts": 6.857, "gpu_utilization_percent_mean": 79.554}, "timestamp": "2026-01-30T10:28:38.254752"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7161.268, "latencies_ms": [7161.268], "images_per_second": 0.14, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The carrots are in the foreground, with the blue scissors and the white container in the background. The carrots are to the left of the scissors, and the white container is to the right of the scissors.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15436.0, "ram_available_mb": 47404.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15436.7, "ram_available_mb": 47404.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.77}, "power_stats": {"power_gpu_soc_mean_watts": 16.744, "power_cpu_cv_mean_watts": 2.547, "power_sys_5v0_mean_watts": 6.56, "gpu_utilization_percent_mean": 85.77}, "timestamp": "2026-01-30T10:28:47.471568"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4689.018, "latencies_ms": [4689.018], "images_per_second": 0.213, "prompt_tokens": 1111, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In a kitchen, a white plate is filled with fresh carrots and beets, ready to be cooked. The carrots are bright orange and the beets are a deep red, indicating they are ripe and ready to be used.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15436.7, "ram_available_mb": 47404.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15436.0, "ram_available_mb": 47404.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.026}, "power_stats": {"power_gpu_soc_mean_watts": 19.896, "power_cpu_cv_mean_watts": 1.54, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 69.026}, "timestamp": "2026-01-30T10:28:54.191266"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7522.704, "latencies_ms": [7522.704], "images_per_second": 0.133, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a white plate filled with orange carrots and green beans, placed on a kitchen counter. The lighting is bright and natural, illuminating the vibrant colors of the vegetables.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 15436.0, "ram_available_mb": 47404.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 15436.6, "ram_available_mb": 47404.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.222}, "power_stats": {"power_gpu_soc_mean_watts": 16.516, "power_cpu_cv_mean_watts": 2.498, "power_sys_5v0_mean_watts": 6.409, "gpu_utilization_percent_mean": 96.222}, "timestamp": "2026-01-30T10:29:03.752616"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3375.338, "latencies_ms": [3375.338], "images_per_second": 0.296, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a suit and tie is giving a presentation on a large screen in front of an audience.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 15436.0, "ram_available_mb": 47404.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 15438.9, "ram_available_mb": 47402.0, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.37}, "power_stats": {"power_gpu_soc_mean_watts": 22.977, "power_cpu_cv_mean_watts": 1.142, "power_sys_5v0_mean_watts": 7.869, "gpu_utilization_percent_mean": 78.37}, "timestamp": "2026-01-30T10:29:09.183600"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9453.873, "latencies_ms": [9453.873], "images_per_second": 0.106, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. head: 2\n4. neck: 1\n5. shoulder: 1\n6. arm: 1\n7. hand: 1\n8. screen: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15438.9, "ram_available_mb": 47402.0, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.7, "ram_used_mb": 15438.5, "ram_available_mb": 47402.4, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 93.241}, "power_stats": {"power_gpu_soc_mean_watts": 15.869, "power_cpu_cv_mean_watts": 2.616, "power_sys_5v0_mean_watts": 6.402, "gpu_utilization_percent_mean": 93.241}, "timestamp": "2026-01-30T10:29:20.687791"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7612.276, "latencies_ms": [7612.276], "images_per_second": 0.131, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man is standing in front of a large screen, which is positioned to the left of the image. The audience is seated in front of the screen, with their heads visible in the foreground. The stage is located in the background, with the man standing on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15438.5, "ram_available_mb": 47402.4, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 16.2, "ram_used_mb": 15459.9, "ram_available_mb": 47380.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.048}, "power_stats": {"power_gpu_soc_mean_watts": 17.21, "power_cpu_cv_mean_watts": 2.587, "power_sys_5v0_mean_watts": 6.898, "gpu_utilization_percent_mean": 96.048}, "timestamp": "2026-01-30T10:29:30.328821"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4721.709, "latencies_ms": [4721.709], "images_per_second": 0.212, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man in a suit is giving a presentation on a large screen. People are watching him from the audience.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15460.1, "ram_available_mb": 47380.8, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 15460.6, "ram_available_mb": 47380.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.897}, "power_stats": {"power_gpu_soc_mean_watts": 19.48, "power_cpu_cv_mean_watts": 1.704, "power_sys_5v0_mean_watts": 6.955, "gpu_utilization_percent_mean": 81.897}, "timestamp": "2026-01-30T10:29:37.100556"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9296.231, "latencies_ms": [9296.231], "images_per_second": 0.108, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a man in a suit and tie standing on a stage, with a large screen behind him displaying a presentation. The lighting is bright and focused on the speaker, while the audience is seated in front of the screen, with their heads visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15460.6, "ram_available_mb": 47380.3, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 15461.1, "ram_available_mb": 47379.8, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.925}, "power_stats": {"power_gpu_soc_mean_watts": 15.729, "power_cpu_cv_mean_watts": 2.888, "power_sys_5v0_mean_watts": 6.369, "gpu_utilization_percent_mean": 95.925}, "timestamp": "2026-01-30T10:29:48.416577"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3859.581, "latencies_ms": [3859.581], "images_per_second": 0.259, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " Three workers in blue uniforms are standing on a street corner, with a motorcycle parked nearby, and a billboard with Chinese text in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15461.1, "ram_available_mb": 47379.8, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15460.2, "ram_available_mb": 47380.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.71}, "power_stats": {"power_gpu_soc_mean_watts": 21.912, "power_cpu_cv_mean_watts": 1.279, "power_sys_5v0_mean_watts": 7.797, "gpu_utilization_percent_mean": 73.71}, "timestamp": "2026-01-30T10:29:54.304427"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9918.625, "latencies_ms": [9918.625], "images_per_second": 0.101, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Scooters: 3\n2. Motorcycles: 2\n3. Banners: 2\n4. Posters: 1\n5. Signboards: 2\n6. People: 3\n7. Banners: 1\n8. Banners: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15460.2, "ram_available_mb": 47380.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.4, "ram_used_mb": 15460.0, "ram_available_mb": 47380.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.542}, "power_stats": {"power_gpu_soc_mean_watts": 15.837, "power_cpu_cv_mean_watts": 2.881, "power_sys_5v0_mean_watts": 6.425, "gpu_utilization_percent_mean": 91.542}, "timestamp": "2026-01-30T10:30:06.241683"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8235.985, "latencies_ms": [8235.985], "images_per_second": 0.121, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The three men are standing on the sidewalk, with the motorcycles parked on the left side of the image. The motorcycles are positioned in the foreground, while the men are in the middle ground. The men are standing near the motorcycles, and the motorcycles are near the wall.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15460.0, "ram_available_mb": 47380.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 14.0, "ram_used_mb": 15459.7, "ram_available_mb": 47381.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.171}, "power_stats": {"power_gpu_soc_mean_watts": 16.5, "power_cpu_cv_mean_watts": 2.82, "power_sys_5v0_mean_watts": 6.644, "gpu_utilization_percent_mean": 96.171}, "timestamp": "2026-01-30T10:30:16.498075"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3749.2, "latencies_ms": [3749.2], "images_per_second": 0.267, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Three workers in blue uniforms are standing on a street corner, talking to each other.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15459.7, "ram_available_mb": 47381.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 15460.7, "ram_available_mb": 47380.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.355}, "power_stats": {"power_gpu_soc_mean_watts": 21.835, "power_cpu_cv_mean_watts": 1.744, "power_sys_5v0_mean_watts": 7.345, "gpu_utilization_percent_mean": 83.355}, "timestamp": "2026-01-30T10:30:22.293168"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8616.755, "latencies_ms": [8616.755], "images_per_second": 0.116, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image depicts a group of three individuals dressed in blue uniforms, standing on a street corner. The sky is overcast, and the lighting is natural, suggesting it is daytime. The pavement is wet, indicating recent rain.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15460.7, "ram_available_mb": 47380.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 15461.7, "ram_available_mb": 47379.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.37}, "power_stats": {"power_gpu_soc_mean_watts": 15.868, "power_cpu_cv_mean_watts": 2.897, "power_sys_5v0_mean_watts": 6.315, "gpu_utilization_percent_mean": 96.37}, "timestamp": "2026-01-30T10:30:32.950943"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4669.534, "latencies_ms": [4669.534], "images_per_second": 0.214, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A black plastic container filled with a green and yellow mixture of vegetables and meat is placed on a white paper plate, which is also holding a pile of shredded chicken.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 15461.7, "ram_available_mb": 47379.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 15463.2, "ram_available_mb": 47377.7, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.553}, "power_stats": {"power_gpu_soc_mean_watts": 23.343, "power_cpu_cv_mean_watts": 1.328, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 76.553}, "timestamp": "2026-01-30T10:30:39.668500"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9837.242, "latencies_ms": [9837.242], "images_per_second": 0.102, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. plate: 1\n2. bowl: 1\n3. fork: 1\n4. shredded chicken: 1\n5. broccoli: 1\n6. mashed potatoes: 1\n7. sauce: 1\n8. carpet: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15463.2, "ram_available_mb": 47377.7, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 15463.9, "ram_available_mb": 47377.0, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.869}, "power_stats": {"power_gpu_soc_mean_watts": 16.597, "power_cpu_cv_mean_watts": 2.317, "power_sys_5v0_mean_watts": 6.654, "gpu_utilization_percent_mean": 85.869}, "timestamp": "2026-01-30T10:30:51.532283"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10639.059, "latencies_ms": [10639.059], "images_per_second": 0.094, "prompt_tokens": 1450, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The black bowl of food is located in the upper left corner of the image, while the white plate with shredded chicken is situated in the lower right corner. The shredded chicken is placed directly in front of the bowl, and the plate is positioned slightly to the right of the bowl.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15463.9, "ram_available_mb": 47377.0, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 13.4, "ram_used_mb": 15469.3, "ram_available_mb": 47371.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.483}, "power_stats": {"power_gpu_soc_mean_watts": 16.475, "power_cpu_cv_mean_watts": 2.853, "power_sys_5v0_mean_watts": 6.54, "gpu_utilization_percent_mean": 96.483}, "timestamp": "2026-01-30T10:31:04.208835"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4157.959, "latencies_ms": [4157.959], "images_per_second": 0.241, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate with a bowl of food and a fork on it is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15469.3, "ram_available_mb": 47371.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 15470.3, "ram_available_mb": 47370.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.206}, "power_stats": {"power_gpu_soc_mean_watts": 24.536, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 86.206}, "timestamp": "2026-01-30T10:31:10.387602"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9676.421, "latencies_ms": [9676.421], "images_per_second": 0.103, "prompt_tokens": 1442, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a black plastic container filled with a green and yellow mixture of vegetables and chicken, placed on a white paper plate. The food is served on a beige carpeted floor, and the lighting is natural, coming from an unseen source.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15470.3, "ram_available_mb": 47370.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 15471.3, "ram_available_mb": 47369.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.573}, "power_stats": {"power_gpu_soc_mean_watts": 16.774, "power_cpu_cv_mean_watts": 2.701, "power_sys_5v0_mean_watts": 6.538, "gpu_utilization_percent_mean": 87.573}, "timestamp": "2026-01-30T10:31:22.080083"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6005.35, "latencies_ms": [6005.35], "images_per_second": 0.167, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man with glasses and a plaid hat is smiling in front of a building.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15471.3, "ram_available_mb": 47369.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 15472.0, "ram_available_mb": 47368.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 93.367}, "power_stats": {"power_gpu_soc_mean_watts": 16.535, "power_cpu_cv_mean_watts": 2.239, "power_sys_5v0_mean_watts": 6.278, "gpu_utilization_percent_mean": 93.367}, "timestamp": "2026-01-30T10:31:30.120001"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5534.837, "latencies_ms": [5534.837], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. glasses: 1\n3. tie: 1\n4. shirt: 1\n5. cap: 1\n6. building: 1\n7. window: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 15472.0, "ram_available_mb": 47368.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 15476.2, "ram_available_mb": 47364.7, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.174}, "power_stats": {"power_gpu_soc_mean_watts": 18.362, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 7.59, "gpu_utilization_percent_mean": 69.174}, "timestamp": "2026-01-30T10:31:37.696788"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8728.191, "latencies_ms": [8728.191], "images_per_second": 0.115, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The man is positioned in the foreground of the image, with the background consisting of a building and a pool. The man is wearing a blue shirt and a red tie, and he is also wearing a plaid hat.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15476.2, "ram_available_mb": 47364.7, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 15478.6, "ram_available_mb": 47362.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.836}, "power_stats": {"power_gpu_soc_mean_watts": 15.807, "power_cpu_cv_mean_watts": 2.551, "power_sys_5v0_mean_watts": 6.324, "gpu_utilization_percent_mean": 97.836}, "timestamp": "2026-01-30T10:31:48.467634"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3100.56, "latencies_ms": [3100.56], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing a plaid hat and glasses is standing in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15478.6, "ram_available_mb": 47362.3, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 15479.5, "ram_available_mb": 47361.4, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.32}, "power_stats": {"power_gpu_soc_mean_watts": 23.629, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 7.879, "gpu_utilization_percent_mean": 76.32}, "timestamp": "2026-01-30T10:31:53.618864"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6619.443, "latencies_ms": [6619.443], "images_per_second": 0.151, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The man is wearing a blue shirt and a red tie, and the picture was taken in bright daylight.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15479.5, "ram_available_mb": 47361.4, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 14.1, "ram_used_mb": 15480.3, "ram_available_mb": 47360.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.091}, "power_stats": {"power_gpu_soc_mean_watts": 16.623, "power_cpu_cv_mean_watts": 2.075, "power_sys_5v0_mean_watts": 6.304, "gpu_utilization_percent_mean": 98.091}, "timestamp": "2026-01-30T10:32:02.270061"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4823.907, "latencies_ms": [4823.907], "images_per_second": 0.207, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image is a collage of six photos showing different slices of pizza, with the top left photo being the most detailed and the bottom right photo being the least detailed.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15480.3, "ram_available_mb": 47360.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15480.8, "ram_available_mb": 47360.1, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.098}, "power_stats": {"power_gpu_soc_mean_watts": 23.035, "power_cpu_cv_mean_watts": 1.436, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 77.098}, "timestamp": "2026-01-30T10:32:09.139129"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6432.595, "latencies_ms": [6432.595], "images_per_second": 0.155, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " pizza: 6", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 15480.8, "ram_available_mb": 47360.1, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 15479.9, "ram_available_mb": 47361.0, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.151}, "power_stats": {"power_gpu_soc_mean_watts": 18.076, "power_cpu_cv_mean_watts": 2.047, "power_sys_5v0_mean_watts": 6.361, "gpu_utilization_percent_mean": 98.151}, "timestamp": "2026-01-30T10:32:17.587714"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7238.457, "latencies_ms": [7238.457], "images_per_second": 0.138, "prompt_tokens": 1450, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The main objects are arranged in a grid pattern, with the largest image in the top left corner and the smallest in the bottom right. The slices of pizza are positioned in a way that creates a sense of depth, with the largest slice in the top left and the smallest in the bottom right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15479.9, "ram_available_mb": 47361.0, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 15480.0, "ram_available_mb": 47360.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.933}, "power_stats": {"power_gpu_soc_mean_watts": 19.673, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 7.554, "gpu_utilization_percent_mean": 82.933}, "timestamp": "2026-01-30T10:32:26.848595"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6878.805, "latencies_ms": [6878.805], "images_per_second": 0.145, "prompt_tokens": 1444, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The image is a collage of six photos showing different slices of pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15480.0, "ram_available_mb": 47360.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15479.1, "ram_available_mb": 47361.8, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.741}, "power_stats": {"power_gpu_soc_mean_watts": 18.024, "power_cpu_cv_mean_watts": 2.348, "power_sys_5v0_mean_watts": 6.446, "gpu_utilization_percent_mean": 91.741}, "timestamp": "2026-01-30T10:32:35.759083"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5706.435, "latencies_ms": [5706.435], "images_per_second": 0.175, "prompt_tokens": 1442, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The pizza has a yellow and orange color, and the lighting is bright.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15479.1, "ram_available_mb": 47361.8, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 15479.6, "ram_available_mb": 47361.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.043}, "power_stats": {"power_gpu_soc_mean_watts": 19.719, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 6.935, "gpu_utilization_percent_mean": 96.043}, "timestamp": "2026-01-30T10:32:43.505228"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5433.585, "latencies_ms": [5433.585], "images_per_second": 0.184, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two young girls are petting a goat and a sheep in a fenced area.", "error": null, "sys_before": {"cpu_percent": 25.9, "ram_used_mb": 15479.6, "ram_available_mb": 47361.3, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 15479.9, "ram_available_mb": 47361.0, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.356}, "power_stats": {"power_gpu_soc_mean_watts": 17.767, "power_cpu_cv_mean_watts": 1.895, "power_sys_5v0_mean_watts": 6.467, "gpu_utilization_percent_mean": 88.356}, "timestamp": "2026-01-30T10:32:50.982963"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4571.434, "latencies_ms": [4571.434], "images_per_second": 0.219, "prompt_tokens": 1113, "response_tokens_est": 19, "n_tiles": 1, "output_text": " goat: 2, girl: 2, fence: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15479.9, "ram_available_mb": 47361.0, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 15480.6, "ram_available_mb": 47360.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.921}, "power_stats": {"power_gpu_soc_mean_watts": 19.478, "power_cpu_cv_mean_watts": 2.076, "power_sys_5v0_mean_watts": 6.993, "gpu_utilization_percent_mean": 94.921}, "timestamp": "2026-01-30T10:32:57.582825"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8560.141, "latencies_ms": [8560.141], "images_per_second": 0.117, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The two girls are standing on the left side of the image, with the goat in the middle and the other goat on the right side. The goat on the left is being petted by the girl in the pink dress, while the girl in the blue dress is petting the goat on the right.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15480.6, "ram_available_mb": 47360.3, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 15481.3, "ram_available_mb": 47359.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.352}, "power_stats": {"power_gpu_soc_mean_watts": 15.779, "power_cpu_cv_mean_watts": 2.104, "power_sys_5v0_mean_watts": 6.615, "gpu_utilization_percent_mean": 82.352}, "timestamp": "2026-01-30T10:33:08.157283"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6090.871, "latencies_ms": [6090.871], "images_per_second": 0.164, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two young girls are petting a goat and a sheep in a fenced area.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15481.3, "ram_available_mb": 47359.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 13.6, "ram_used_mb": 15487.2, "ram_available_mb": 47353.7, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.059}, "power_stats": {"power_gpu_soc_mean_watts": 17.018, "power_cpu_cv_mean_watts": 2.317, "power_sys_5v0_mean_watts": 6.332, "gpu_utilization_percent_mean": 98.059}, "timestamp": "2026-01-30T10:33:16.293438"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4706.216, "latencies_ms": [4706.216], "images_per_second": 0.212, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image is taken in bright daylight with a clear blue sky in the background. The girls are wearing colorful dresses, and the goats are black and white.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 15487.2, "ram_available_mb": 47353.7, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 13.1, "ram_used_mb": 15488.6, "ram_available_mb": 47352.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.45}, "power_stats": {"power_gpu_soc_mean_watts": 19.967, "power_cpu_cv_mean_watts": 3.485, "power_sys_5v0_mean_watts": 7.44, "gpu_utilization_percent_mean": 76.45}, "timestamp": "2026-01-30T10:33:23.046329"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 8106.994, "latencies_ms": [8106.994], "images_per_second": 0.123, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a nighttime scene at a street intersection, where a traffic light is illuminated by a green light, and a street sign is visible in the background, indicating the name of the street.", "error": null, "sys_before": {"cpu_percent": 28.6, "ram_used_mb": 15488.6, "ram_available_mb": 47352.3, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 13.7, "ram_used_mb": 15489.5, "ram_available_mb": 47351.4, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.794}, "power_stats": {"power_gpu_soc_mean_watts": 16.146, "power_cpu_cv_mean_watts": 2.921, "power_sys_5v0_mean_watts": 6.353, "gpu_utilization_percent_mean": 97.794}, "timestamp": "2026-01-30T10:33:33.196029"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6405.975, "latencies_ms": [6405.975], "images_per_second": 0.156, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. traffic light: 2\n2. street sign: 1\n3. street light: 1\n4. car: 1\n5. mountain: 1\n6. road: 1\n7. sky: 1\n8. road sign: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15489.5, "ram_available_mb": 47351.4, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 15488.7, "ram_available_mb": 47352.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.963}, "power_stats": {"power_gpu_soc_mean_watts": 18.341, "power_cpu_cv_mean_watts": 2.039, "power_sys_5v0_mean_watts": 7.392, "gpu_utilization_percent_mean": 80.963}, "timestamp": "2026-01-30T10:33:41.650473"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8113.148, "latencies_ms": [8113.148], "images_per_second": 0.123, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The traffic light is on the left side of the image, while the street sign is on the right side. The traffic light is closer to the viewer, while the street sign is farther away. The traffic light is in the foreground, while the street sign is in the background.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 15488.7, "ram_available_mb": 47352.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15488.2, "ram_available_mb": 47352.7, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.029}, "power_stats": {"power_gpu_soc_mean_watts": 15.732, "power_cpu_cv_mean_watts": 2.344, "power_sys_5v0_mean_watts": 6.617, "gpu_utilization_percent_mean": 80.029}, "timestamp": "2026-01-30T10:33:51.821256"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9334.907, "latencies_ms": [9334.907], "images_per_second": 0.107, "prompt_tokens": 1111, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a night scene at a street intersection, where a traffic light is illuminated by a green light, signaling vehicles to proceed. The sky is dark, suggesting it is either early morning or late evening, and the street is lined with buildings and mountains in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15488.2, "ram_available_mb": 47352.7, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 14.3, "ram_used_mb": 15491.4, "ram_available_mb": 47349.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.584}, "power_stats": {"power_gpu_soc_mean_watts": 15.627, "power_cpu_cv_mean_watts": 2.413, "power_sys_5v0_mean_watts": 6.452, "gpu_utilization_percent_mean": 96.584}, "timestamp": "2026-01-30T10:34:03.185940"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8255.001, "latencies_ms": [8255.001], "images_per_second": 0.121, "prompt_tokens": 1109, "response_tokens_est": 80, "n_tiles": 1, "output_text": " The image captures a serene night scene at a street intersection, where the sky is painted in hues of deep blue, and the moon is partially visible. The traffic lights, glowing in a soft green, stand as silent sentinels guiding the flow of vehicles. The street, bathed in the glow of streetlights, is lined with buildings and trees, their silhouettes adding depth to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15491.4, "ram_available_mb": 47349.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 11.9, "ram_used_mb": 15490.4, "ram_available_mb": 47350.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.871}, "power_stats": {"power_gpu_soc_mean_watts": 17.284, "power_cpu_cv_mean_watts": 2.403, "power_sys_5v0_mean_watts": 7.151, "gpu_utilization_percent_mean": 83.871}, "timestamp": "2026-01-30T10:34:13.453815"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3289.745, "latencies_ms": [3289.745], "images_per_second": 0.304, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman wearing a patterned dress stands in front of a building with a bunch of bananas in front of her.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15490.4, "ram_available_mb": 47350.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 15490.3, "ram_available_mb": 47350.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.223, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T10:34:18.779713"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6540.459, "latencies_ms": [6540.459], "images_per_second": 0.153, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. bananas: 2\n3. building: 1\n4. door: 1\n5. wall: 1\n6. window: 1\n7. sign: 1\n8. wall decoration: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15490.3, "ram_available_mb": 47350.6, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15488.3, "ram_available_mb": 47352.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.709}, "power_stats": {"power_gpu_soc_mean_watts": 18.19, "power_cpu_cv_mean_watts": 2.228, "power_sys_5v0_mean_watts": 7.211, "gpu_utilization_percent_mean": 83.709}, "timestamp": "2026-01-30T10:34:27.361187"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6902.245, "latencies_ms": [6902.245], "images_per_second": 0.145, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bananas are in the foreground, with the woman standing behind them. The woman is positioned to the right of the bananas, and the building is in the background.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 15489.3, "ram_available_mb": 47351.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 15502.0, "ram_available_mb": 47338.9, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.259}, "power_stats": {"power_gpu_soc_mean_watts": 16.793, "power_cpu_cv_mean_watts": 2.665, "power_sys_5v0_mean_watts": 6.505, "gpu_utilization_percent_mean": 89.259}, "timestamp": "2026-01-30T10:34:36.295159"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4847.093, "latencies_ms": [4847.093], "images_per_second": 0.206, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman is standing in front of a building with bananas on a table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15502.0, "ram_available_mb": 47338.9, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15501.5, "ram_available_mb": 47339.4, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.65}, "power_stats": {"power_gpu_soc_mean_watts": 18.245, "power_cpu_cv_mean_watts": 2.023, "power_sys_5v0_mean_watts": 6.677, "gpu_utilization_percent_mean": 95.65}, "timestamp": "2026-01-30T10:34:43.172548"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6158.675, "latencies_ms": [6158.675], "images_per_second": 0.162, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image is taken in a sunny day with a warm color tone. The woman is wearing a colorful dress and the bananas are yellow.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15501.5, "ram_available_mb": 47339.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15501.8, "ram_available_mb": 47339.1, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.392}, "power_stats": {"power_gpu_soc_mean_watts": 17.348, "power_cpu_cv_mean_watts": 2.505, "power_sys_5v0_mean_watts": 6.498, "gpu_utilization_percent_mean": 86.392}, "timestamp": "2026-01-30T10:34:51.368393"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 11632.568, "latencies_ms": [11632.568], "images_per_second": 0.086, "prompt_tokens": 1432, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image captures a vibrant urban scene, featuring a red brick building adorned with a green awning and a green fire escape. The building's facade is a canvas of graffiti, with various tags and markings adorning the shuttered windows and doors. A fire hydrant stands guard on the sidewalk, adding a touch of urban grit to the scene.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 15501.8, "ram_available_mb": 47339.1, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 15502.5, "ram_available_mb": 47338.4, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.51}, "power_stats": {"power_gpu_soc_mean_watts": 16.307, "power_cpu_cv_mean_watts": 2.918, "power_sys_5v0_mean_watts": 6.58, "gpu_utilization_percent_mean": 95.51}, "timestamp": "2026-01-30T10:35:05.075144"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5062.993, "latencies_ms": [5062.993], "images_per_second": 0.198, "prompt_tokens": 1446, "response_tokens_est": 20, "n_tiles": 1, "output_text": " fire hydrant: 1\nbike rack: 1\ngraffiti: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15502.5, "ram_available_mb": 47338.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 15502.7, "ram_available_mb": 47338.2, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.81}, "power_stats": {"power_gpu_soc_mean_watts": 21.771, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 7.453, "gpu_utilization_percent_mean": 94.81}, "timestamp": "2026-01-30T10:35:12.165670"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9307.179, "latencies_ms": [9307.179], "images_per_second": 0.107, "prompt_tokens": 1450, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The fire hydrant is located on the left side of the image, in the foreground. The building is in the background, with the sidewalk in front of it. The graffiti on the shutters is located in the middle ground, between the fire hydrant and the building.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15502.7, "ram_available_mb": 47338.2, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 15504.6, "ram_available_mb": 47336.3, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.051}, "power_stats": {"power_gpu_soc_mean_watts": 16.681, "power_cpu_cv_mean_watts": 2.264, "power_sys_5v0_mean_watts": 6.707, "gpu_utilization_percent_mean": 83.051}, "timestamp": "2026-01-30T10:35:23.506258"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 12121.372, "latencies_ms": [12121.372], "images_per_second": 0.082, "prompt_tokens": 1444, "response_tokens_est": 79, "n_tiles": 1, "output_text": " The image captures a vibrant urban scene, where a red brick building stands proudly on a city street corner. The building's green awning and shuttered windows add a splash of color to the otherwise monochrome facade. A fire hydrant, a common sight on city streets, stands guard on the sidewalk, while a tree in the background adds a touch of nature to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15504.6, "ram_available_mb": 47336.3, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15505.6, "ram_available_mb": 47335.3, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.66}, "power_stats": {"power_gpu_soc_mean_watts": 16.143, "power_cpu_cv_mean_watts": 2.885, "power_sys_5v0_mean_watts": 6.605, "gpu_utilization_percent_mean": 88.66}, "timestamp": "2026-01-30T10:35:37.652279"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9029.596, "latencies_ms": [9029.596], "images_per_second": 0.111, "prompt_tokens": 1442, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image depicts a red brick building with green shutters and a fire escape. The building is covered in graffiti, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15505.6, "ram_available_mb": 47335.3, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 11.5, "ram_used_mb": 15505.7, "ram_available_mb": 47335.2, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.803}, "power_stats": {"power_gpu_soc_mean_watts": 16.722, "power_cpu_cv_mean_watts": 2.793, "power_sys_5v0_mean_watts": 6.355, "gpu_utilization_percent_mean": 96.803}, "timestamp": "2026-01-30T10:35:48.713555"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3385.645, "latencies_ms": [3385.645], "images_per_second": 0.295, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a blue and white striped beanie is holding a yellow frisbee in his hand.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 15505.7, "ram_available_mb": 47335.2, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 15505.9, "ram_available_mb": 47335.0, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.753, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T10:35:54.141393"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9683.887, "latencies_ms": [9683.887], "images_per_second": 0.103, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. head: 1\n3. hair: 1\n4. shirt: 1\n5. hand: 1\n6. frisbee: 1\n7. ceiling: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 15505.9, "ram_available_mb": 47335.0, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.4, "ram_used_mb": 15507.1, "ram_available_mb": 47333.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.951}, "power_stats": {"power_gpu_soc_mean_watts": 15.788, "power_cpu_cv_mean_watts": 2.635, "power_sys_5v0_mean_watts": 6.376, "gpu_utilization_percent_mean": 92.951}, "timestamp": "2026-01-30T10:36:05.873064"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7049.987, "latencies_ms": [7049.987], "images_per_second": 0.142, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The man is in the foreground, holding a frisbee in his hand. The frisbee is in front of him, and the background is blurred, indicating that the focus is on the man and the frisbee.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 15507.1, "ram_available_mb": 47333.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 13.1, "ram_used_mb": 15511.8, "ram_available_mb": 47329.1, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.831}, "power_stats": {"power_gpu_soc_mean_watts": 17.362, "power_cpu_cv_mean_watts": 2.681, "power_sys_5v0_mean_watts": 6.812, "gpu_utilization_percent_mean": 95.831}, "timestamp": "2026-01-30T10:36:14.949932"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3968.224, "latencies_ms": [3968.224], "images_per_second": 0.252, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing a blue hat and a black shirt is playing frisbee in a dark room.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15511.8, "ram_available_mb": 47329.1, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 15511.3, "ram_available_mb": 47329.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.576}, "power_stats": {"power_gpu_soc_mean_watts": 21.36, "power_cpu_cv_mean_watts": 1.577, "power_sys_5v0_mean_watts": 7.357, "gpu_utilization_percent_mean": 82.576}, "timestamp": "2026-01-30T10:36:20.949306"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5581.659, "latencies_ms": [5581.659], "images_per_second": 0.179, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is a black and white photo with a blue and white striped hat. The lighting is dim, and the subject is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15511.0, "ram_available_mb": 47329.9, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 15510.0, "ram_available_mb": 47330.9, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.587}, "power_stats": {"power_gpu_soc_mean_watts": 18.16, "power_cpu_cv_mean_watts": 2.342, "power_sys_5v0_mean_watts": 6.842, "gpu_utilization_percent_mean": 95.587}, "timestamp": "2026-01-30T10:36:28.556574"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5933.411, "latencies_ms": [5933.411], "images_per_second": 0.169, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A group of people are sitting around a table with laptops and books, and they are all looking at the laptop screens.", "error": null, "sys_before": {"cpu_percent": 21.1, "ram_used_mb": 15510.0, "ram_available_mb": 47330.9, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15510.5, "ram_available_mb": 47330.4, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.653}, "power_stats": {"power_gpu_soc_mean_watts": 17.335, "power_cpu_cv_mean_watts": 2.46, "power_sys_5v0_mean_watts": 6.463, "gpu_utilization_percent_mean": 84.653}, "timestamp": "2026-01-30T10:36:36.517917"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6822.662, "latencies_ms": [6822.662], "images_per_second": 0.147, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 3, keyboard: 1, mouse: 1, cup: 1, bottle: 1, book: 1, person: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15510.5, "ram_available_mb": 47330.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 15512.3, "ram_available_mb": 47328.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.281}, "power_stats": {"power_gpu_soc_mean_watts": 16.826, "power_cpu_cv_mean_watts": 2.487, "power_sys_5v0_mean_watts": 6.547, "gpu_utilization_percent_mean": 97.281}, "timestamp": "2026-01-30T10:36:45.369146"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5855.113, "latencies_ms": [5855.113], "images_per_second": 0.171, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The laptop is on the left side of the table, the woman is on the right side of the table, and the man is in the middle of the table. The laptop is in the foreground, the woman is in the middle, and the man is in the background.", "error": null, "sys_before": {"cpu_percent": 40.0, "ram_used_mb": 15512.3, "ram_available_mb": 47328.6, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 15514.4, "ram_available_mb": 47326.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.204}, "power_stats": {"power_gpu_soc_mean_watts": 18.481, "power_cpu_cv_mean_watts": 2.043, "power_sys_5v0_mean_watts": 7.459, "gpu_utilization_percent_mean": 75.204}, "timestamp": "2026-01-30T10:36:53.270464"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5770.786, "latencies_ms": [5770.786], "images_per_second": 0.173, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant, working on their laptops.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15514.4, "ram_available_mb": 47326.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15510.6, "ram_available_mb": 47330.3, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.25}, "power_stats": {"power_gpu_soc_mean_watts": 17.364, "power_cpu_cv_mean_watts": 2.728, "power_sys_5v0_mean_watts": 6.413, "gpu_utilization_percent_mean": 92.25}, "timestamp": "2026-01-30T10:37:01.092162"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5148.697, "latencies_ms": [5148.697], "images_per_second": 0.194, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm yellow light. The people are using laptops and computers, and there are many objects on the table, including a glass of water, a cup, and a bottle of ketchup.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15510.6, "ram_available_mb": 47330.3, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 15511.4, "ram_available_mb": 47329.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.905}, "power_stats": {"power_gpu_soc_mean_watts": 19.167, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 7.632, "gpu_utilization_percent_mean": 70.905}, "timestamp": "2026-01-30T10:37:08.276540"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7853.422, "latencies_ms": [7853.422], "images_per_second": 0.127, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young girl wearing a pink jacket and blue jeans is holding a brown teddy bear and a blue umbrella.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15511.4, "ram_available_mb": 47329.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.6, "ram_used_mb": 15512.3, "ram_available_mb": 47328.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.106}, "power_stats": {"power_gpu_soc_mean_watts": 17.196, "power_cpu_cv_mean_watts": 2.688, "power_sys_5v0_mean_watts": 6.444, "gpu_utilization_percent_mean": 98.106}, "timestamp": "2026-01-30T10:37:18.181511"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8495.939, "latencies_ms": [8495.939], "images_per_second": 0.118, "prompt_tokens": 1446, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. girl: 1\n2. blue umbrella: 1\n3. girl's hand: 1\n4. girl's leg: 1\n5. girl's foot: 1\n6. girl's hand: 1\n7. girl's leg: 1\n8. girl's foot: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15512.3, "ram_available_mb": 47328.6, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 11.6, "ram_used_mb": 15513.5, "ram_available_mb": 47327.4, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.817}, "power_stats": {"power_gpu_soc_mean_watts": 18.998, "power_cpu_cv_mean_watts": 2.047, "power_sys_5v0_mean_watts": 7.311, "gpu_utilization_percent_mean": 86.817}, "timestamp": "2026-01-30T10:37:28.708526"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5845.354, "latencies_ms": [5845.354], "images_per_second": 0.171, "prompt_tokens": 1450, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The girl is standing in the foreground of the image, holding the umbrella in her right hand. The umbrella is positioned above her, providing shade.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15513.5, "ram_available_mb": 47327.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 15513.4, "ram_available_mb": 47327.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.688}, "power_stats": {"power_gpu_soc_mean_watts": 20.727, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.247, "gpu_utilization_percent_mean": 83.688}, "timestamp": "2026-01-30T10:37:36.569292"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7415.204, "latencies_ms": [7415.204], "images_per_second": 0.135, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young girl wearing a pink jacket and blue jeans is standing on a gravel surface holding a blue umbrella.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15513.4, "ram_available_mb": 47327.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 15513.4, "ram_available_mb": 47327.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.295}, "power_stats": {"power_gpu_soc_mean_watts": 17.384, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 6.479, "gpu_utilization_percent_mean": 95.295}, "timestamp": "2026-01-30T10:37:46.014571"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5200.317, "latencies_ms": [5200.317], "images_per_second": 0.192, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The girl is wearing a pink jacket and blue jeans, and the umbrella is blue. The lighting is natural and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15513.4, "ram_available_mb": 47327.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 15514.9, "ram_available_mb": 47326.0, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.279}, "power_stats": {"power_gpu_soc_mean_watts": 22.141, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 7.542, "gpu_utilization_percent_mean": 84.279}, "timestamp": "2026-01-30T10:37:53.231906"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7544.992, "latencies_ms": [7544.992], "images_per_second": 0.133, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A man in a suit stands in front of a window with a reflection of another man in it, with a desk in front of him that has a computer monitor and keyboard.", "error": null, "sys_before": {"cpu_percent": 22.7, "ram_used_mb": 15514.9, "ram_available_mb": 47326.0, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 17.6, "ram_used_mb": 15495.5, "ram_available_mb": 47345.4, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.656}, "power_stats": {"power_gpu_soc_mean_watts": 16.519, "power_cpu_cv_mean_watts": 3.222, "power_sys_5v0_mean_watts": 6.517, "gpu_utilization_percent_mean": 97.656}, "timestamp": "2026-01-30T10:38:02.819650"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4355.061, "latencies_ms": [4355.061], "images_per_second": 0.23, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " man: 1, chair: 1, computer: 2, monitor: 1, keyboard: 1, mouse: 1, tv: 1, tv screen: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15495.5, "ram_available_mb": 47345.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 15496.1, "ram_available_mb": 47344.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.946}, "power_stats": {"power_gpu_soc_mean_watts": 21.207, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 7.892, "gpu_utilization_percent_mean": 70.946}, "timestamp": "2026-01-30T10:38:09.219867"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8003.57, "latencies_ms": [8003.57], "images_per_second": 0.125, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The man is standing to the left of the desk, which is in the foreground of the image. The desk is positioned in front of a window, which is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15496.1, "ram_available_mb": 47344.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 16.4, "ram_used_mb": 15506.8, "ram_available_mb": 47334.1, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.97}, "power_stats": {"power_gpu_soc_mean_watts": 16.409, "power_cpu_cv_mean_watts": 2.899, "power_sys_5v0_mean_watts": 6.492, "gpu_utilization_percent_mean": 96.97}, "timestamp": "2026-01-30T10:38:19.278484"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3291.341, "latencies_ms": [3291.341], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man in a suit is standing in front of a window with a computer setup on a desk.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15506.5, "ram_available_mb": 47334.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 15511.1, "ram_available_mb": 47329.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.741}, "power_stats": {"power_gpu_soc_mean_watts": 23.171, "power_cpu_cv_mean_watts": 1.172, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 77.741}, "timestamp": "2026-01-30T10:38:24.604497"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6746.697, "latencies_ms": [6746.697], "images_per_second": 0.148, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from a window. The man is wearing a black suit and tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15511.1, "ram_available_mb": 47329.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 14.6, "ram_used_mb": 15542.1, "ram_available_mb": 47298.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.912}, "power_stats": {"power_gpu_soc_mean_watts": 16.745, "power_cpu_cv_mean_watts": 2.846, "power_sys_5v0_mean_watts": 6.389, "gpu_utilization_percent_mean": 97.912}, "timestamp": "2026-01-30T10:38:33.390204"}
